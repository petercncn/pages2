中文摘要 _ 基于N-gram语义的文本摘要评价指标
文本摘要是自然语言处理中的一项重要任务，已在许多实际场景中得到应用。近年来，随着深度学习的不断发展，基于语义理解的抽象文本摘要引起了很多关注。抽象文本摘要模型很可能会生成原始文本中不存在，但语义相近的词。传统评估指标很少考虑语义信息，因而并不适合评估基于深度学习的抽象文本摘要模型的质量。此外，影响评估结果的超词表问题（OOV）尚未得到很好的解决。为了解决这些问题，我们提出了一种新颖的文本摘要评价模型（简称 ENMS），使用语义来增强现有的基于 N-gram 的评估指标。具体来说，我们提出了两种类型的改进方法：基于 N-gram 的语义匹配方法（简称NSM）和基于 N-gram 的语义相似匹配方法（简称NSS），来改进包括 ROUGE、BLEU 在内的几种广泛使用的文本摘要评估指标。本文还提出了一种N-gram 表示机制，探索N-gram（包括skip-gram）的向量表示，该机制被用作ENMS模型的基础，利用一些简单但有效的集成方法来有效地解决 OOV 问题。在TAC AESOP数据集上的实验结果表明，我们的方法改进后的评估指标与人类判断有很好的相关性，能够更合理有效地评估抽象文本摘要模型。
研究背景
抽象文本摘要通常使用深度学习模型来进行语义建模，并基于全文的语义来生成文本摘要。与抽取式的文本摘要不同，抽象文本摘要融合了全文的语义，因此在摘要中很可能生成原文中不存在但语义相近的词汇。当前工作在评价摘要质量时，通常使用基于召回的指标如ROUGE，或基于精准率的指标如BLEU。但这些指标都使用硬匹配，即字符串的绝对匹配来计算生成摘要与参考摘要之间的相似性分数。在评估抽象式摘要时，遇到语义相近的描述，尽管在人类判断下摘要是合格的，但这些硬匹配指标会给予这类摘要一个很低的相似性分数，这使得评估结果并不能客观地反应文本摘要的质量。
目的
本文旨在研究一种更好的方式来评估抽象式摘要。为了弥补硬匹配指标不能客观反应抽象文本摘要质量的缺陷，本文努力研究一些改进的指标，使之可以从语义层面评价文本摘要质量。此外，由于评价文本摘要通常需要使用N-gram，本文还要研究一种能精确表示N-gram语义信息的机制。
新冠肺炎防控
本文提出两种改进基于N-gram的摘要评价指标的方法，分别是基于N-gram的语义匹配方法（简称NSM）和基于N-gram的语义相似方法（简称NSS）。以ROUGE-N，BLEU，ROUGE-SU4为例，用NSM所改进的指标计算方式为：其中R表示所有的参考摘要所构成的集合，r表示其中一个参考摘要，c表示一个候选摘要，gn 表示候选摘要c的一个N-gram词，NG(r)返回所有出现在参考摘要r中的N-gram,COUNT(r)计算参考摘要r中N-gram词的总数量。本文用算法1详细描述NSM方法。算法中get_embedding方法，返回N-gram的语义向量，它是N-gram词汇的一种语义表示。基于BLUE指标的改进指标NSM-BL计算方式如下：其中BP是惩罚系数，它使机器翻译的长度接近原文，在文本摘要场景下，可以将BP设为1；wn是长度为n的N-gram的重要性权重，一般场景下，用均匀分布wn=1/N来设置该权重。基于ROUGE-SU4的改进指标NSM-RSU4计算方式如下：其中c为候选摘要，r为长度为l的参考摘要，gsk为候选摘要的skip-gram，SKG(r)表示参考摘要的所有skip-gram，WORD(r)表示出现在参考摘要中的所有词，C(l,2)是从l中任选2个的所有组合的数量。本文所提出的第二类摘要评价指标改进方法为基于N-gram的语义相似方法（NSS）。以ROUGE-N，BLEU，ROUGE-SU4为例，计算公式只需要将NSM改进的指标中的NSM方法，替换为NSS方法即可，算法2详细描述NSS方法。对于ROUGE-L指标，本文也提出一种考虑语义的改进方式S-RL，其计算方式为：其中ls是参考摘要包含的句子数量，si是参考摘要第i个句子，c是候选摘要，l为参考摘要包含的词的数量，LSS函数计算两个句子的最长相似子序列长度。本文将最长相似子序列定义如下：给定两个序列a和b，假定sa是序列a的一个子序列，sb是序列b的一个子序列，并且sa与sb是等长的，当且仅当sa与sb每个对应位置i上的元素sai、sbi都使相似度cos(sai,sbi)>t时，称sai与sbi为最长相似子序列，其中t为相似度阈值。
结果
本文在TAC 2011 AESOP数据集上进行了一系列实验，AESOP 2011数据集包含44个话题，每个话题包含10个文档集。每个文档中有4个人类摘要和51个机器摘要，本文将人类摘要作为参考摘要，将自动摘要作为候选摘要。为了衡量评价指标的评估结果的客观性，本文将计算评价指标的结果与人类评分结果的皮尔逊相关系数。图1结果显示，NSM与NSS指标在基于回归的指标ROUGE上，均有更高的相关性分数。然而图d和图f显示BLEU在Pyramid和Responsiveness分数的相关性上，NSM和NSS指标低于硬匹配指标。分析原因发现：BLEU是基于精准率的指标，它将候选摘要的N-gram当成分母，因此它难以衡量候选摘要和参考摘要信息的符合程度。Pyramid和Responsiveness分数都是基于内容的评估分数，因此基于BLEU的改进指标出现了略低的相关性。图1 ROUGE和BLEU上的对比实验结果
结论
本文结合语义信息，提出了对基于N-gram的摘要文本评估指标的两类增强方法，即基于N-gram的语义匹配方法(NSM)和基于N-gram的语义相似方法(NSS)。本文在AESOP数据集上验证了所提出方法改进后的指标与人类评分具有更高的相关性，表明改进的评估指标可以更合理有效地评估抽象文本摘要。由于缺乏更多的数据集验证摘要评估指标，本文仅在一个相对较小的数据集上测试了提出的改进指标，未来将在更多数据集上测试改进指标的有效性。此外，本文目前主要在语义方面增强了文本摘要的评估指标，未来将探索在可读性等其他方面的增强方式，还将尝试将所提方法应用于基于评论文本的推荐等更多场景。

