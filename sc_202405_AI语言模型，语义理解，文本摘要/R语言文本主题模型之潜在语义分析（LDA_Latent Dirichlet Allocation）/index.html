
            <!DOCTYPE html>
            <html lang="en">
            <head>
                <meta charset="UTF-8">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                <meta name="description" content="文本分析：主题建模library(tidyverse">
                <meta name="keywords" content="R语言文本主题模型之潜在语义分析（LDA_Latent Dirichlet Allocation）, 文本分析：主题建模library(tidyverse">
                <meta property="og:title" content="R语言文本主题模型之潜在语义分析（LDA:Latent Dirichlet Allocation）">
                <title>R语言文本主题模型之潜在语义分析（LDA_Latent Dirichlet Allocation）</title>
                <style>.hidden{visibility:hidden;font-size:1px;}</style>
            </head>
            <body>
                <div class="rich_media_wrp" id="img-content">
<h1 class="rich_media_title" id="activity-name">
            
R语言文本主题模型之潜在语义分析（LDA:Latent Dirichlet Allocation）
          </h1>

<div class="rich_media_content js_underline_content" id="js_content" style="visibility: visible;"><h3 style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">原文：http://tecdat.cn/?p=3897</h3><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"> </p><h1 style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">文本分析：主题建模</h1><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li></ul><pre class="code-snippet__js"><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">library(tidyverse)</span></code><code><span class="code-snippet_outer">theme_set( theme_bw())</span></code></pre></section><h1 style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"> <br/></h1><h1 style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">目标</h1><ul class="list-paddingleft-2" style="list-style-type: none;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"><li><p>定义主题建模</p></li><li><p>解释Latent Dirichlet以及此过程的工作原理</p></li><li><p>演示如何使用LDA从一组已知主题中找到主题结构</p></li><li><p>演示如何使用LDA从一组未知主题中找到主题结构</p></li><li><p>确定k</p></li><li><p>选择适当参数的方法</p></li></ul><h1 style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">主题建模</h1><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"> </p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">通常，当我们在线搜索信息时，有两种主要方法：</p><ol class="list-paddingleft-2" style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"><li><p>关键字 - 使用搜索引擎并输入与我们想要查找的内容相关的单词</p></li><li><p>链接。链接的页面可能共享相似或相关的内容。</p></li></ol><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">另一种方法是通过主题搜索和探索文档。广泛的主题可能与文章中的各个部分（国家事务，体育）有关，但这些部分内或之间可能存在特定主题。</p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">为此，我们需要有关每篇文章主题的详细信息。对该语料库进行手工编码将非常耗时，更不用说在开始编码之前需要知道文档的主题结构。</p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">因此，我们可以使用概率主题模型，分析原始文本文档中的单词的统计算法来揭示语料库和单个文档本身的主题结构。在分析之前，它们不需要对文档进行任何手工编码或标记 - 相反，算法来自对文本的分析。</p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"><br/></p><h1 style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">潜在的Dirichlet分配</h1><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">LDA假定语料库中的每个文档都包含在整个语料库中的混合主题。主题结构是隐藏的 - 我们只能观察文档和文字，而不是主题本身。因为结构是隐藏的（也称为潜在的），所以该方法试图在给定已知单词和文档的情况下推断主题结构。</p><h1 style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">食物和动物</h1><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">假设您有以下句子：</p><ol class="list-paddingleft-2" style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"><li><p>我早餐吃了香蕉和菠菜。</p></li><li><p>我喜欢吃西兰花和香蕉。</p></li><li><p>龙猫和小猫很可爱。</p></li><li><p>我姐姐昨天收养了一只小猫。</p></li><li><p>看看这只可爱的仓鼠嚼着一块西兰花。</p></li></ol><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">Latent Dirichlet分配是一种自动发现这些句子所包含的主题的方法。例如，给定这些句子并询问2个主题，LDA可能会产生类似的东西</p><ul class="list-paddingleft-2" style="list-style-type: none;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"><li><p>句子1和2：100％主题A.</p></li><li><p>句子3和4：100％主题B.</p></li><li><p>句子5：60％主题A，40％主题B.</p></li><li><p>主题A：30％西兰花，15％香蕉，10％早餐，10％咀嚼，......</p></li><li><p>主题B：20％龙猫，20％小猫，20％可爱，15％仓鼠，......</p></li></ul><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">您可以推断出主题A是关于食物的主题，主题B是关于可爱动物的主题。但是，LDA没有以这种方式明确地确定主题。它所能做的就是告诉你特定单词与主题相关的概率。</p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"><br/></p><h1 style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">LDA文档结构</h1><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">LDA将文档表示为以某些概率单词的主题组合。它假设文档以下列方式生成：在编写每个文档时，您</p><ul class="list-paddingleft-2" style="list-style-type: none;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"><li><p>确定单词数N.</p></li><li><p>为文档选择主题（根据K个主题）</p></li><li><p>例如，假设我们上面有两个食物和可爱的动物主题。</p></li><li><p>通过以下方式生成文档中的每个单词：</p></li><li><p>首先选择一个主题（根据您在上面采样的分配;例如，您可以选择1/3概率的食物主题和2/3概率的可爱动物主题）。</p></li><li><p>然后使用主题生成单词本身（根据主题分配）。例如，食物主题可能输出概率为30％的“西兰花”，概率为15％的“香蕉”，依此类推。</p></li></ul><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"> </p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">我们怎么能在前面的例子中生成句子？生成文档D时：</p><ul class="list-paddingleft-2" style="list-style-type: none;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"><li><p>D 将是一半关于食物和一半关于可爱动物。</p></li><li><p>选择5为D的单词数</p></li><li><p>从食物主题中选择第一个词，然后给出“西兰花”这个词。</p></li><li><p>选择第二个词来自可爱的动物主题，如“熊猫”。</p></li><li><p>选择第三个词来自可爱的动物主题，如“可爱”。</p></li><li><p>选择第四个词来源于食物主题，如“樱桃”。</p></li><li><p>从食物主题中选出第五个词，如“吃”。</p></li></ul><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">因此，在LDA模型下生成的文件将是“可爱的熊猫吃樱桃和西兰花”（LDA使用的是词袋模型）。</p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"><br/></p><h1 style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">通过LDA学习主题模型</h1><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">现在假设您有一组文档。你选择了一些固定数量的K.</p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">ķ是要发现的主题，我们希望使用LDA来学习每个文档的主题表示以及与每个主题相关联的单词。怎么做到这一点？一种方式（称为吉布斯采样）如下：</p><ul class="list-paddingleft-2" style="list-style-type: none;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"><li><p>浏览每个文档，并将文档中的每个单词随机分配给K中的一个ķ 主题</p></li><li><p>但由于它是随机的，这不是一个非常准确的结构。</p></li><li><p>换句话说，在这一步中，我们假设除了当前单词之外的所有主题分配都是正确的，然后使用我们的文档生成模型更新当前单词的赋值。</p></li><li><p>重复上一步骤很多次，你最终会达到一个大致稳定的状态</p></li><li><p>您可以使用这些分配来估计两件事：</p></li></ul><ol class="list-paddingleft-2" style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"><li><p>每个文档的主题（通过计算分配给该文档中每个主题的单词的比例）</p></li><li><p>与每个主题相关的单词（通过计算分配给每个主题的单词的比例）</p></li></ol><h1 style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">具有已知主题结构的LDA</h1><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">如果先验地知道一组文档的主题结构，LDA可能是有用的。</p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">我们可以使用LDA和主题建模来发现章节与不同主题（即书籍）的关系。</p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">作为预处理，我们将这些分为章节，使用tidytext unnest_tokens将它们分成单词，然后删除stop_words。我们将每一章都视为一个单独的“文档” 。</p><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="http"><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">by_chapter &lt;- books %&gt;%</span></code><code><span class="code-snippet_outer">group_by(title) %&gt;%</span></code><code><span class="code-snippet_outer">mutate(chapter = cumsum( str_detect(text, regex("^chapter ", ignore_case = TRUE)))) %&gt;%</span></code><code><span class="code-snippet_outer">ungroup() %&gt;%</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">count(title_chapter, word, sort = TRUE) %&gt;%</span></code><code><span class="code-snippet_outer">ungroup()</span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># Joining, by = "word"</span></span></code><code><span class="code-snippet_outer">word_counts</span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># # A tibble: 104,721 × 3</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># title_chapter word n</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># &lt;chr&gt; &lt;chr&gt; &lt;int&gt;</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 1 Great Expectations_57 joe 88</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 2 Great Expectations_7 joe 70</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 3 Great Expectations_17 biddy 63</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 4 Great Expectations_27 joe 58</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 5 Great Expectations_38 estella 58</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 6 Great Expectations_2 joe 56</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 7 Great Expectations_23 pocket 53</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 8 Great Expectations_15 joe 50</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 9 Great Expectations_18 joe 50</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 10 The War of the Worlds_16 brother 50</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># # ... with 104,711 more rows</span></span></code><code><span class="code-snippet_outer"><br/></span></code></pre></section><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"> <br/></p><h1 style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">潜在狄利克雷分配(latnet Dirichlet allocation, LDA)模型</h1><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">topicmodels包需要一个DocumentTermMatrix（来自tm包）。我们可以用cast_dtm函数转换为DocumentTermMatrix：</p><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="shell"><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">chapters_dtm</span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># &lt;&lt;DocumentTermMatrix (documents: 193, terms: 18215)&gt;&gt;</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># Non-/sparse entries: 104721/3410774</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># Sparsity : 97%</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># Maximal term length: 19</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># Weighting : term frequency (tf)</span></span></code><code><span class="code-snippet_outer"> </span></code></pre></section><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">现在我们准备创建一个四主题LDA模型。</p><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="http"><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">chapters_lda <span class="code-snippet__tag">&lt;<span class="code-snippet__name">-</span> <span class="code-snippet__attr">LDA</span>(<span class="code-snippet__attr">chapters_dtm</span>, <span class="code-snippet__attr">k</span> = <span class="code-snippet__string">4,</span> <span class="code-snippet__attr">control</span> = <span class="code-snippet__string">list(seed</span> = <span class="code-snippet__string">1234))</span></span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__attr">chapters_lda</span></span></code><code><span class="code-snippet_outer">## 四主题<span class="code-snippet__attr">LDA</span>模型。</span></code><code><span class="code-snippet_outer"><br/></span></code></pre></section><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"><br/></p><ul class="list-paddingleft-2"><li><p>在这种情况下，我们知道有四个主题，因为有四本书; 这是了解潜在主题结构的价值</p></li><li><p>seed = 1234设置随机迭代过程的起点。如果我们没有设置种子，那么每次运行脚本时我们都可以估算出略有不同的模型</p></li></ul><p><br/></p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">我们从动词开始。</p><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="shell"><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">library(tidytext)</span></code><code><span class="code-snippet_outer">chapters_lda_td &lt;- tidy(chapters_lda)</span></code><code><span class="code-snippet_outer">chapters_lda_td</span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># # A tibble: 72,860 × 3</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># topic term beta</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># &lt;int&gt; &lt;chr&gt; &lt;dbl&gt;</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 1 1 joe 5.830326e-17</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 2 2 joe 3.194447e-57</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 3 3 joe 4.162676e-24</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 4 4 joe 1.445030e-02</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 5 1 biddy 7.846976e-27</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 6 2 biddy 4.672244e-69</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 7 3 biddy 2.259711e-46</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 8 4 biddy 4.767972e-03</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 9 1 estella 3.827272e-06</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 10 2 estella 5.316964e-65</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># # ... with 72,850 more rows</span></span></code><code><span class="code-snippet_outer"> </span></code><code><span class="code-snippet_outer"> </span></code></pre></section><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">我们可以使用dplyr's top_n来查找每个主题中的前5个词：</p><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="http"><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">top_n(5, beta) %&gt;%</span></code><code><span class="code-snippet_outer">ungroup() %&gt;%</span></code><code><span class="code-snippet_outer">arrange(topic, -beta)</span></code><code><span class="code-snippet_outer">top_terms</span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># # A tibble: 20 × 3</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># topic term beta</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># &lt;int&gt; &lt;chr&gt; &lt;dbl&gt;</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 1 1 elizabeth 0.014107538</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 2 1 darcy 0.008814258</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 3 1 miss 0.008706741</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 4 1 bennet 0.006947431</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 5 1 jane 0.006497512</span></span></code></pre></section><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"> <br/></p><h1 style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">可视化</h1><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="http"><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">ggplot( aes(term, beta, fill = factor(topic))) +</span></code><code><span class="code-snippet_outer">geom_bar(alpha = 0.8, <span class="code-snippet__built_in">stat</span></span></code></pre></section><h1 style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"> <br/></h1><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"><img data-backh="556" data-backw="650" data-ratio="0.8571428571428571" data-src="https://mmbiz.qpic.cn/mmbiz_png/1fdBqQicF8pLFrvGGWjKduicO1wgkFx1HHC91sJsicNHoWia7pl0XuAJNzbfN9kooxxcfevk2wib49DI70uuKwnfqdA/640?wx_fmt=png" data-type="png" data-w="1344" src="20240525_032303_0.jpeg" style="border-width: 0px;border-style: initial;border-color: initial;max-width: 650px;width: 100%;height: auto;"/></p><ul class="list-paddingleft-2" style="list-style-type: none;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"><li><p>这些主题与四本书非常明显相关</p></li><li><p>“nemo”，“sea”和“nautilus”属于海底两万里</p></li><li><p>“jane”，“darcy”和“elizabeth”属于傲慢与偏见</p></li></ul><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">另请注意，LDA()不会为每个主题分配任何标签。它们只是主题1,2,3和4. 我们可以推断这些与每本书有关，但它仅仅是我们的推论。</p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"><br/></p><h1 style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">按文档分类</h1><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">每一章都是本分析中的“文件”。因此，我们可能想知道哪些主题与每个文档相关联。我们可以把这些章节放回正确的书中吗？</p><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="shell"><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">chapters_lda_gamma</span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># # A tibble: 772 × 3</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># document topic gamma</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># &lt;chr&gt; &lt;int&gt; &lt;dbl&gt;</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 1 Great Expectations_57 1 1.351886e-05</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 2 Great Expectations_7 1 1.470726e-05</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 3 Great Expectations_17 1 2.117127e-05</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 4 Great Expectations_27 1 1.919746e-05</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 5 Great Expectations_38 1 3.544403e-01</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 6 Great Expectations_2 1 1.723723e-05</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 7 Great Expectations_23 1 5.507241e-01</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 8 Great Expectations_15 1 1.682503e-02</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 9 Great Expectations_18 1 1.272044e-05</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 10 The War of the Worlds_16 1 1.084337e-05</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># # ... with 762 more rows</span></span></code></pre></section><p> </p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">每行每个主题一个文档。现在我们已经有了这些文档分类，我们可以看到我们的无监督学习在区分四本书方面做得如何。<br/></p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">首先，我们将文档名称重新分为标题和章节：</p><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="shell"><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">chapters_lda_gamma &lt;- chapters_lda_gamma %&gt;%</span></code><code><span class="code-snippet_outer">separate(document, c("title", "chapter"), sep = "_", convert = TRUE)</span></code><code><span class="code-snippet_outer">chapters_lda_gamma</span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># # A tibble: 772 × 4</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># title chapter topic gamma</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># * &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 1 Great Expectations 57 1 1.351886e-05</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 2 Great Expectations 7 1 1.470726e-05</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 3 Great Expectations 17 1 2.117127e-05</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 4 Great Expectations 27 1 1.919746e-05</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 5 Great Expectations 38 1 3.544403e-01</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 6 Great Expectations 2 1 1.723723e-05</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 7 Great Expectations 23 1 5.507241e-01</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 8 Great Expectations 15 1 1.682503e-02</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 9 Great Expectations 18 1 1.272044e-05</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 10 The War of the Worlds 16 1 1.084337e-05</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># # ... with 762 more rows</span></span></code></pre></section><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">然后我们检查每个章节的正确部分：</p><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="http"><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">ggplot(chapters_lda_gamma, aes(gamma, fill = factor(topic))) +</span></code><code><span class="code-snippet_outer">geom_histogram() +</span></code><code><span class="code-snippet_outer">facet_wrap(~ title, nrow = <span class="code-snippet__number">2</span>)</span></code><code><span class="code-snippet_outer">## <span class="code-snippet__string">`stat_bin()`</span> using <span class="code-snippet__string">`bins = 30`</span>. Pick better value <span class="code-snippet__keyword">with</span> <span class="code-snippet__string">`binwidth`</span>.</span></code></pre></section><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"> <br/></p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"><img data-backh="487" data-backw="650" data-ratio="0.75" data-src="https://mmbiz.qpic.cn/mmbiz_png/1fdBqQicF8pLFrvGGWjKduicO1wgkFx1HHmJwuWIORT7aibgDKgezUcxibSyqmBxcMSfMcbWYrbWNsNbKC2uSsmyzA/640?wx_fmt=png" data-type="png" data-w="1536" src="20240525_032304_1.jpeg" style="border-width: 0px;border-style: initial;border-color: initial;max-width: 650px;width: 100%;height: auto;"/></p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">我们注意到，几乎所有来自“ 傲慢与偏见”，“世界大战 ”和“ 海底两万里 ”的章节都被确定为一个章节。</p><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="shell"><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">chapter_classifications &lt;- chapters_lda_gamma %&gt;%</span></code><code><span class="code-snippet_outer">group_by(title, chapter) %&gt;%</span></code><code><span class="code-snippet_outer">top_n(1, gamma) %&gt;%</span></code><code><span class="code-snippet_outer">ungroup() %&gt;%</span></code><code><span class="code-snippet_outer">arrange(gamma)</span></code><code><span class="code-snippet_outer">chapter_classifications</span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># # A tibble: 193 × 4</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># title chapter topic gamma</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 1 Great Expectations 54 3 0.4803234</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 2 Great Expectations 22 4 0.5356506</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 3 Great Expectations 31 4 0.5464851</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 4 Great Expectations 23 1 0.5507241</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 5 Great Expectations 33 4 0.5700737</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 6 Great Expectations 47 4 0.5802089</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 7 Great Expectations 56 4 0.5984806</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 8 Great Expectations 38 4 0.6455341</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 9 Great Expectations 11 4 0.6689600</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># 10 Great Expectations 44 4 0.6777974</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># # ... with 183 more rows</span></span></code></pre></section><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"> <br/></p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">主题建模期望最大化算法中的一个重要步骤是将每个文档中的每个单词分配给一个主题。文档中的单词越多分配给该主题，通常，权重（gamma）将在该文档主题分类上。</p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"> </p><h1 style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">具有未知主题结构的LDA</h1><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">通常在使用LDA时，您实际上并不知道文档的基础主题结构。通常，这就是您首先使用LDA分析文本的原因。</p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"><br/></p><h1 style="color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">美联社文章</h1><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">数据是1992年发布的文章样本的文档术语矩阵。让我们将它们加载到R中并转换为整齐格式。</p><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="shell"><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 1 1 adding 1</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 2 1 adult 2</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 3 1 ago 1</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 4 1 alcohol 1</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 5 1 allegedly 1</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 6 1 allen 1</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 7 1 apparently 2</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 8 1 appeared 1</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 9 1 arrested 1</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 10 1 assault 1</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># # ... with 302,021 more rows</span></span></code></pre></section><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">为什么要先整理一下？因为原始的dtm包含停用词 - 我们想在建模数据之前删除它们。然后将数据转换回文档矩阵。</p><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="http"><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># Sparsity : 99%</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># Maximal term length: 18</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># Weighting : term frequency (tf)</span></span></code></pre></section><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">每个主题的顶级词是什么样的？</p><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="http"><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"> </span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">group_by(topic) %&gt;%</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">top_n(5, beta) %&gt;%</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">ungroup() %&gt;%</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">arrange(topic, -beta)</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">top_terms</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># # A tibble: 20 × 3</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># topic term beta</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># &lt;int&gt; &lt;chr&gt; &lt;dbl&gt;</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 1 1 soviet 0.009502197</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 2 1 government 0.009198486</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 3 1 president 0.007046753</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 4 1 united 0.006507324</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 5 1 people 0.005402784</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 6 2 people 0.007454587</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 7 2 police 0.006433472</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 8 2 city 0.003996852</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 9 2 time 0.003369658</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 10 2 school 0.003058213</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 11 3 court 0.006850723</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 12 3 bush 0.006510244</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 13 3 president 0.005777216</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 14 3 federal 0.005512805</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 15 3 house 0.004657550</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 16 4 percent 0.023766679</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 17 4 million 0.012489935</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 18 4 billion 0.009864418</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 19 4 market 0.008402463</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 20 4 prices 0.006693626</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">top_terms %&gt;%</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">) +</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">coord_flip()</span></code></pre></section><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"><img data-backh="464" data-backw="650" data-ratio="0.7142857142857143" data-src="https://mmbiz.qpic.cn/mmbiz_png/1fdBqQicF8pLFrvGGWjKduicO1wgkFx1HHyTb2oKia5h0zWWUOxDV5tdgjfia2poXxboGjfJsib5R5jrnibVrw5qlYgA/640?wx_fmt=png" data-type="png" data-w="1344" src="20240525_032305_2.jpeg" style="border-width: 0px;border-style: initial;border-color: initial;max-width: 650px;width: 100%;height: auto;"/><br/></p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">这四个主题通常用于描述：</p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"><img data-ratio="1.1418439716312057" data-src="https://mmbiz.qpic.cn/mmbiz_png/1fdBqQicF8pLFrvGGWjKduicO1wgkFx1HH0vqNUo1M6E8CYaw5EgErFlfvHQfCzSTaPNX964yngmHyEno7omr3Aw/640?wx_fmt=png" data-type="png" data-w="141" height="161" src="20240525_032306_3.jpeg" style="border-width: 0px;border-style: initial;border-color: initial;" width="141"/></p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">如果我们设置k=12</p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">我们的结果如何变化？</p><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="shell"><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">group_by(topic) %&gt;%</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">top_n(5, beta) %&gt;%</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">ungroup() %&gt;%</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">arrange(topic, -beta)</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">top_terms</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># # A tibble: 60 × 3</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># topic term beta</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># &lt;int&gt; &lt;chr&gt; &lt;dbl&gt;</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 1 1 military 0.011691176</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 2 1 united 0.011598436</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 3 1 iraq 0.010618221</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 4 1 president 0.009498227</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 5 1 american 0.008253379</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 6 2 dukakis 0.009819260</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 7 2 bush 0.007300830</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 8 2 campaign 0.006366915</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 9 2 people 0.006098596</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 10 2 school 0.005208529</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># # ... with 50 more rows</span></span></code><code><span class="code-snippet_outer"> </span></code></pre></section><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"><img data-backh="464" data-backw="650" data-ratio="0.7142857142857143" data-src="https://mmbiz.qpic.cn/mmbiz_png/1fdBqQicF8pLFrvGGWjKduicO1wgkFx1HHZOkYdde9eATph5VHPzJDbCF4qq19u5gPR4E6LVHVZiarfRqdDTI1QmA/640?wx_fmt=png" data-type="png" data-w="1344" src="20240525_032307_4.jpeg" style="border-width: 0px;border-style: initial;border-color: initial;max-width: 650px;width: 100%;height: auto;"/><br/></p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"> 嗯，这些主题似乎更具体，但不易理解。</p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"><img data-ratio="3.007936507936508" data-src="https://mmbiz.qpic.cn/mmbiz_png/1fdBqQicF8pLFrvGGWjKduicO1wgkFx1HHBSX9cT2YeO3OHwCgFLnaHKJ2o1jX3e6GQY5ScAiaibMzr91PX9Ehlq5w/640?wx_fmt=png" data-type="png" data-w="126" height="379" src="20240525_032308_5.jpeg" style="border-width: 0px;border-style: initial;border-color: initial;" width="126"/></p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">等。</p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">LDA的某些方面是由直觉思维驱动的。但是我们可以提供辅助方法。</p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">困惑度是概率模型预测样本的程度的统计量度。你估计LDA模型。然后给出由主题表示的理论单词分配，将其与实际主题或文档中单词的分配进行比较。</p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">perplexity为给定模型计算该值的函数。</p><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="shell"><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">perplexity(ap_lda)</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># [1] 2301.814</span></span></code></pre></section><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">但是，统计数据本身有点无意义。这种统计数据的好处在于比较不同模型的不同k的困惑度。具有最低困惑度的模型通常被认为是“最佳”。<br/></p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">让我们估算美联社数据集上的一系列LDA模型。</p><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="cpp"><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">n_topics &lt;- c(<span class="code-snippet__number">2</span>, <span class="code-snippet__number">4</span>, <span class="code-snippet__number">10</span>, <span class="code-snippet__number">20</span>, <span class="code-snippet__number">50</span>, <span class="code-snippet__number">100</span>)</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">ap_lda_compare &lt;- n_topics %&gt;%</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet__built_in">map</span>(LDA, x = ap_dtm, control = <span class="code-snippet__built_in">list</span>(seed = <span class="code-snippet__number">1109</span>))</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">geom_point() +</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">y = <span class="code-snippet__string">"Perplexity"</span>)</span></code></pre></section><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"><img data-backh="464" data-backw="650" data-ratio="0.7142857142857143" data-src="https://mmbiz.qpic.cn/mmbiz_png/1fdBqQicF8pLFrvGGWjKduicO1wgkFx1HH3gsTq3f0xUVbFicMIficYUcytZOfH2T1Cknyue3NBcpRj4OeY1rQclTw/640?wx_fmt=png" data-type="png" data-w="1344" src="20240525_032310_6.jpeg" style="border-width: 0px;border-style: initial;border-color: initial;max-width: 650px;width: 100%;height: auto;"/><br/></p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">看起来100主题模型具有最低的困惑分数。这会产生什么样的主题？让我们看一下模型产生的前12个主题：</p><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="shell"><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">ap_lda_td &lt;- tidy(ap_lda_compare[[6]])</span></code><code><span class="code-snippet_outer">top_terms &lt;- ap_l</span></code><code><span class="code-snippet_outer">ungroup() %&gt;%</span></code><code><span class="code-snippet_outer">arrange(topic, -beta)</span></code><code><span class="code-snippet_outer">top_terms</span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">#</span><span class="code-snippet__comment"># # A tibble: 502 × 3</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># topic term beta</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># &lt;int&gt; &lt;chr&gt; &lt;dbl&gt;</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 1 1 party 0.020029039</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 2 1 communist 0.013810107</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 3 1 government 0.013221069</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 4 1 news 0.013036980</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet_outer">#</span><span class="code-snippet__comment"># 5 1 soviet 0.011512086</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">ggplot(aes(term, beta, fill = factor(topic))) +</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">facet_wrap(~ topic, scales = "free", ncol = 3) +</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">coord_flip()</span></code></pre></section><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"><img data-backh="464" data-backw="650" data-ratio="0.7142857142857143" data-src="https://mmbiz.qpic.cn/mmbiz_png/1fdBqQicF8pLFrvGGWjKduicO1wgkFx1HHIbiaam74eicj8frdA61pJ3GsAuibHaSrFFY2sBNly36Qwg1PeEvWntjAw/640?wx_fmt=png" data-type="png" data-w="1344" src="20240525_032311_7.jpeg" style="border-width: 0px;border-style: initial;border-color: initial;max-width: 650px;width: 100%;height: auto;"/><br/></p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">我们现在正在获得更具体的主题。问题是我们如何呈现这些结果并以信息方式使用它们。</p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);">同样，这也是您作为研究人员时直觉和领域知识非常重要的地方。您可以使用困惑作为决策过程中的一个数据点，但很多时候它只是简单地查看主题本身以及与每个主题相关联的最高概率词来确定结构是否有意义。如果您有一个已知的主题结构，您可以将其与之比较（例如上面的书籍示例），这也很有用。</p><p style="padding-top: 4px;padding-bottom: 4px;color: rgb(0, 0, 0);font-family: Arial, Helvetica, sans-serif;font-size: 14px;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);"> </p><section style="background-repeat: repeat;background-position: left top;background-size: auto;box-sizing: border-box;"><section style="margin-top: 10px;white-space: normal;"><section><section style="padding-right: 0.5em;padding-left: 0.5em;display: inline-block;vertical-align: top;height: 2em;line-height: 2em;background-color: rgb(243, 243, 243);text-align: center;color: rgb(34, 75, 20);box-sizing: border-box;"><p style="text-align: left;"><span style="color: rgb(5, 28, 44);"><strong>点击标题查阅往期内容</strong></span></p></section><section style="display: inline-block;vertical-align: top;border-left: 0.5em solid rgb(243, 243, 243);border-bottom: 1em solid rgb(243, 243, 243);line-height: 0;border-right: 0.5em solid transparent !important;border-top: 1em solid transparent !important;box-sizing: border-box;"><section style="line-height: 0;width: 0px;"><svg style="vertical-align:top;" viewbox="0 0 1 1"></svg></section></section></section></section><section style="margin-bottom: 5px;white-space: normal;"><section style="padding-top: 10px;padding-bottom: 10px;display: inline-block;width: 8888px;vertical-align: top;background-color: rgb(243, 243, 243);box-sizing: border-box;"><section><section style="display: inline-block;vertical-align: top;width: 888888px;"><section><a data-itemshowtype="11" data-linktype="2" href="#" style="font-size: 15px;" tab="innerlink" target="_blank"><span style="font-size: 15px;">文本挖掘：LDA模型对公号文章主题分析案例报告</span></a></section><section><a data-itemshowtype="11" data-linktype="2" href="#" style="font-size: 15px;" tab="innerlink" target="_blank"><span style="font-size: 15px;">主题模型(LDA)案例：挖掘人民网留言板文本数据</span></a></section><section><a data-itemshowtype="11" data-linktype="2" href="#" style="font-size: 15px;" tab="innerlink" target="_blank"><span style="font-size: 15px;">文本挖掘：twitter推特LDA主题情感分析</span></a></section><section><a data-itemshowtype="0" data-linktype="2" href="#" style="font-size: 15px;" tab="innerlink" target="_blank"><span style="font-size: 15px;">基于LDA主题模型聚类的商品评论文本挖掘</span></a></section><section><a data-itemshowtype="11" data-linktype="2" href="#" style="font-size: 15px;" tab="innerlink" target="_blank"><span style="font-size: 15px;">LDA主题模型分析网购数据</span></a></section><section><a data-itemshowtype="0" data-linktype="2" href="#" style="font-size: 15px;" tab="innerlink" target="_blank"><span style="font-size: 15px;">R语言中对文本数据进行主题模型topic modeling分析</span></a></section><section><a data-itemshowtype="11" data-linktype="2" href="#" style="font-size: 15px;" tab="innerlink" target="_blank"><span style="font-size: 15px;">主题模型(LDA)案例：分析人民网留言板数据</span></a></section><section><a data-itemshowtype="0" data-linktype="2" href="#" style="font-size: 15px;" tab="innerlink" target="_blank"><span style="font-size: 15px;">python主题LDA建模和t-SNE可视化</span></a></section><section><a data-itemshowtype="0" data-linktype="2" href="#" style="font-size: 15px;" tab="innerlink" target="_blank"><span style="font-size: 15px;">Python之LDA主题模型算法应用</span></a></section><section><a data-itemshowtype="0" data-linktype="2" href="#" style="font-size: 15px;" tab="innerlink" target="_blank"><span style="font-size: 15px;">R语言社区主题检测算法应用案例</span></a></section><section><a data-itemshowtype="0" data-linktype="2" href="#" style="font-size: 15px;" tab="innerlink" target="_blank"><span style="font-size: 15px;">R语言文本挖掘NASA数据网络分析，tf-idf和主题建模</span></a></section><section><a data-itemshowtype="0" data-linktype="2" href="#" style="font-size: 15px;" tab="innerlink" target="_blank"><span style="font-size: 15px;">R语言文本挖掘tf-idf,主题建模，情感分析,n-gram建模研究</span></a></section><section><a data-itemshowtype="0" data-linktype="2" href="#" style="font-size: 15px;" tab="innerlink" target="_blank"><span style="font-size: 15px;">python主题建模可视化LDA和T-SNE交互式可视化</span></a></section><section><a data-itemshowtype="11" data-linktype="2" href="#" style="font-size: 15px;" tab="innerlink" target="_blank"><span style="font-size: 15px;">主题模型及文本情感分析疫情新闻数据</span></a></section><section><a data-itemshowtype="0" data-linktype="2" href="#" style="font-size: 15px;" tab="innerlink" target="_blank"><span style="font-size: 15px;">python爬虫进行Web抓取LDA主题语义数据分析报告</span></a><span style="font-size: 15px;"> </span></section></section></section></section></section><p><br/></p></section><section><p style='margin-right: 8px;margin-left: 8px;max-width: 100%;min-height: 1em;font-family: -apple-system-font, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;color: rgb(62, 62, 62);font-size: 16px;line-height: 25.6px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;'><span style="letter-spacing: 0.544px;max-width: 100%;color: rgb(136, 136, 136);font-size: 14px;line-height: 1.6;box-sizing: border-box !important;overflow-wrap: break-word !important;"><span style="max-width: 100%;line-height: 25.6px;box-sizing: border-box !important;overflow-wrap: break-word !important;">更多内容，请点击左下角“</span><span style="max-width: 100%;color: rgb(62, 62, 62);box-sizing: border-box !important;overflow-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);box-sizing: border-box !important;overflow-wrap: break-word !important;">阅读原文</span></strong></span><span style="max-width: 100%;line-height: 25.6px;box-sizing: border-box !important;overflow-wrap: break-word !important;">”查看</span></span><span style="letter-spacing: 0.544px;color: rgb(136, 136, 136);font-size: 14px;max-width: 100%;line-height: 25.6px;box-sizing: border-box !important;overflow-wrap: break-word !important;">报告全文</span><br/></p><p><br/></p><p style='margin-right: 8px;margin-left: 8px;max-width: 100%;min-height: 1em;font-family: -apple-system-font, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;color: rgb(62, 62, 62);font-size: 16px;line-height: 25.6px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;'><img class="__bg_gif" data-ratio="1" data-src="https://mmbiz.qpic.cn/mmbiz/8fbA6bMTCeKrMibRg8TBXns5IMUo3o5ga1BdZRMcYTImvDfx74aJibT15IwwNEZg0SeXLmlxIrpgOxRO401MWHhw/640?wx_fmt=gif" data-type="gif" data-w="30" src="20240525_032312_8.jpeg" style="margin-right: auto;margin-left: auto;font-family: 微软雅黑;line-height: 25.6px;font-size: 14px;vertical-align: middle;display: inline-block;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible !important;width: 30px !important;" width="30px"/><br/></p><p style='margin-right: 8px;margin-bottom: 16px;margin-left: 8px;max-width: 100%;min-height: 1em;font-family: -apple-system-font, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);text-align: center;box-sizing: border-box !important;overflow-wrap: break-word !important;'><img data-ratio="0.1565217391304348" data-src="https://mmbiz.qpic.cn/mmbiz/wyice8kFQhf5geQK3gu2FUugjB8iaSGpjOr2rQfaPHylpACk5OBfB8icdq1Opbkl8zNu6icqFIacIwOhnA76n3cskg/640?wx_fmt=png" data-type="png" data-w="115" src="20240525_032313_9.jpeg" style="margin-right: auto;margin-left: auto;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible !important;width: 115px !important;" width="60px"/></p><p style='margin-right: 8px;margin-left: 8px;max-width: 100%;min-height: 1em;font-family: -apple-system-font, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);text-align: center;box-sizing: border-box !important;overflow-wrap: break-word !important;'><img data-ratio="0.05776173285198556" data-src="https://mmbiz.qpic.cn/mmbiz/hHKEjSiaCUpmEgib9OdqeJPhW9rkibJyibzeQqD6g6341e3aaF5A4S9DmzWb2c255MA4B4SZ4pZZgwZn2Cic9SJUabw/640?wx_fmt=jpeg" data-type="jpeg" data-w="554" height="29" src="20240525_032314_10.jpeg" style="line-height: 25.6px;color: rgb(63, 63, 63);box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible !important;width: 505.99px !important;" width="506px"/><br style="max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;"/></p><p style='margin-right: 8px;margin-left: 8px;max-width: 100%;min-height: 1em;font-family: -apple-system-font, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);text-align: center;box-sizing: border-box !important;overflow-wrap: break-word !important;'><br style="max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;"/></p><p style='margin-right: 8px;margin-left: 8px;max-width: 100%;min-height: 1em;font-family: -apple-system-font, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);text-align: center;box-sizing: border-box !important;overflow-wrap: break-word !important;'><strong style="max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;"><span style="max-width: 100%;font-size: 14px;white-space: pre-wrap;line-height: 1.6;color: rgb(136, 136, 136);box-sizing: border-box !important;overflow-wrap: break-word !important;">关注我们<br style="max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;"/></span></strong></p><p style='margin-right: 8px;margin-left: 8px;max-width: 100%;min-height: 1em;font-family: -apple-system-font, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);text-align: center;box-sizing: border-box !important;overflow-wrap: break-word !important;'><span style="max-width: 100%;font-size: 14px;color: rgb(136, 136, 136);box-sizing: border-box !important;overflow-wrap: break-word !important;">案例精选、技术干货 第一时间与您分享</span></p><p style='margin-right: 8px;margin-left: 8px;max-width: 100%;min-height: 1em;font-family: -apple-system-font, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);text-align: center;box-sizing: border-box !important;overflow-wrap: break-word !important;'><img data-cropselx1="1" data-cropselx2="268" data-cropsely1="0" data-cropsely2="269" data-ratio="1" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/1fdBqQicF8pLjWDMdYUJbbLgyU31NPmicTGLGRXzNOFEnmyw0iaiamwqfOezCiayRQ9XFDYEXicLjJ4VG58017egdJQA/640?wx_fmt=jpeg" data-type="jpeg" data-w="258" src="20240525_032315_11.jpeg" style="box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible !important;width: 269px !important;"/></p><p style='margin-right: 8px;margin-left: 8px;max-width: 100%;min-height: 1em;font-family: -apple-system-font, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);text-align: center;box-sizing: border-box !important;overflow-wrap: break-word !important;'><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 14px;line-height: 1.6;box-sizing: border-box !important;overflow-wrap: break-word !important;">长按二维码加关注</span></p><p style='margin-right: 8px;margin-left: 8px;max-width: 100%;min-height: 1em;font-family: -apple-system-font, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;color: rgb(62, 62, 62);font-size: 16px;line-height: 25.6px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;'><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 14px;line-height: 1.6;box-sizing: border-box !important;overflow-wrap: break-word !important;"><span style="max-width: 100%;line-height: 25.6px;box-sizing: border-box !important;overflow-wrap: break-word !important;"></span></span></p><p style='margin-right: 8px;margin-left: 8px;white-space: normal;max-width: 100%;min-height: 1em;font-family: -apple-system-font, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;letter-spacing: 0.544px;color: rgb(62, 62, 62);font-size: 16px;line-height: 25.6px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;'><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 14px;line-height: 1.6;box-sizing: border-box !important;overflow-wrap: break-word !important;"><span style="max-width: 100%;line-height: 25.6px;box-sizing: border-box !important;overflow-wrap: break-word !important;">更多内容，请点击左下角“</span><span style="max-width: 100%;color: rgb(62, 62, 62);box-sizing: border-box !important;overflow-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);box-sizing: border-box !important;overflow-wrap: break-word !important;">阅读原文</span></strong></span><span style="max-width: 100%;line-height: 25.6px;box-sizing: border-box !important;overflow-wrap: break-word !important;">”查看</span></span><span style="color: rgb(136, 136, 136);font-size: 14px;max-width: 100%;line-height: 25.6px;box-sizing: border-box !important;overflow-wrap: break-word !important;">报告全文</span></p><p><br/></p><p style='margin-right: 8px;margin-left: 8px;max-width: 100%;min-height: 1em;font-family: -apple-system-font, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;color: rgb(62, 62, 62);font-size: 16px;line-height: 25.6px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;'><br/></p></section><p><br/></p></div>

</div>
                <p></p>
                <p></p>
                <div>本文由“公众号文章抓取器”生成，请忽略上文所有联系方式或指引式信息。有问题可以联系：五人工作室，官网：www.Wuren.Work，QQ微信同号1976.424.585 </div>
                <div  class="hidden">本文由“公众号文章抓取器”生成，请忽略上文所有联系方式或指引式信息。有问题可以联系：五人工作室，官网：www.Wuren.Work，QQ微信同号1976.424.585 <br><p class="hidden">code/s?__biz=MzU4NTA1MDk4MA==&mid=2247491694&idx=2&sn=621cbbf553ab7b6fadc73e102f51d6da&chksm=fd92de65cae55773ccad40cd5d546558fd5e705f13abf669b0ac2d21291764d8f65e5cbaa20d#rd </p></div>
            </body>
            </html>
            