


            
大型语言模型：解析文本的未来
          




大型语言模型如何工作大型语言模型是将文本映射到文本的函数。给定一个输入文本字符串，大型语言模型会预测接下来应该出现的文本。大型语言模型的神奇之处在于，通过训练以最小化大量文本的预测误差，模型最终会学习对这些预测有用的概念。例如，他们学习：怎么拼语法是如何运作的如何转述如何回答问题如何进行对话如何用多种语言写作如何编码ETC。这些能力都不是明确编程的——它们都是训练的结果。GPT-3 为数百种软件产品提供支持，包括生产力应用程序、教育应用程序、游戏等。如何控制大型语言模型在大型语言模型的所有输入中，迄今为止影响最大的是文本提示。可以通过几种方式提示大型语言模型产生输出：说明：告诉模型你想要什么Completion : 指导模型完成你想要的任务演示：通过以下任一方式向模型展示您想要的内容：提示中的几个示例微调训练数据集中的数百或数千个示例下面显示了每个的示例。指令提示遵循指令的模型（例如，text-davinci-003或任何以 开头的模型text-）是专门为遵循指令而设计的。将您的指令写在提示的顶部（或底部，或两者），模型将尽力遵循指令，然后停止。说明可以很详细，因此不要害怕写一段明确详细说明您想要的输出。指令提示示例：从下面的引文中提取作者姓名。“一些人类认为，智慧物种在扩展到外太空之前就已经灭绝了。 如果他们是对的，那么夜空的寂静就是墓地的寂静。”——特德·蒋，《呼气》输出：特德·蒋完成提示示例完成式提示利用了大型语言模型尝试编写它们认为接下来最有可能出现的文本的大小。要引导模型，请尝试开始一个模式或句子，该模式或句子将由您想要看到的输出完成。相对于直接指令，这种引导大型语言模型的模式可以更加谨慎和实验。此外，模型不一定知道在哪里停止，因此您通常需要停止序列或后处理来截断生成的超出所需输出的文本。完成提示示例：“一些人类认为，智慧物种在扩展到外太空之前就已经灭绝了。 如果他们是对的，那么夜空的寂静就是墓地的寂静。”——特德·蒋，《呼气》这句话的作者是输出： 特德·蒋演示提示示例（few-shot学习）与完成式提示类似，演示可以向模型展示您希望它执行的操作。这种方法有时称为小样本学习，因为模型从提示中提供的几个示例中学习。示例演示提示：引用：“当推理思维被迫一次又一次地面对不可能的事情时，它别无选择，只能适应。”——N.K. 杰米辛，第五季作者：N.K. 杰米辛引用：“一些人类认为，智慧物种在扩展到外太空之前就已经灭绝了。 如果他们是对的，那么夜空的寂静就是墓地的寂静。”——特德·蒋，《呼气》作者：输出：特德·蒋微调提示示例有了足够的训练示例，您就可以微调自定义模型。在这种情况下，指令就变得不必要了，因为模型可以从提供的训练数据中学习任务。但是，包含分隔符序列（例如，->或###或任何通常不会出现在输入中的字符串）来告诉模型提示词何时结束，并且输出会很有帮助。如果没有分隔符序列，模型可能会继续详细说明输入文本，而不是从您想要看到的答案开始。微调提示示例（对于已在类似提示-完成对上进行自定义训练的模型）：“一些人类认为，智慧物种在扩展到外太空之前就已经灭绝了。 如果他们是对的，那么夜空的寂静就是墓地的寂静。”——特德·蒋，《呼气》###输出：特德·蒋更多的建议一般来说，输入提示是改进模型输出的最佳杠杆。您可以尝试以下技巧：给予更明确的指示。例如，如果您希望输出为逗号分隔列表，请要求它返回逗号分隔列表。如果您希望它在不知道答案时说“我不知道”，请告诉它“如果您不知道答案，请说“我不知道”。”提供更好的例子。如果您在提示中演示示例，请确保您的示例多样化且高质量。让模型像专家一样回答。明确要求模型产生高质量的输出或输出，就好像它是由专家编写的一样，可以促使模型给出它认为专家会编写的更高质量的答案。例如，“以下答案是正确的、高质量的，并且由专家撰写。”提示模型写下解释其推理的一系列步骤。例如，在你的答案前加上“让我们一步一步思考”之类的内容。在给出最终答案之前提示模型对其推理进行解释可以增加其最终答案一致和正确的可能性。




