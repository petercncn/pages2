
            <!DOCTYPE html>
            <html lang="en">
            <head>
                <meta charset="UTF-8">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                <meta name="description" content="【AI 绘画工具】最好的开源文本到图像模型，语义理解和图像质量最佳，Stable Cascade模型">
                <meta name="keywords" content="【AI 绘画工具】最好的开源文本到图像模型，语义理解和图像质量最佳，Stable Cascade模型, 【AI 绘画工具】最好的开源文本到图像模型，语义理解和图像质量最佳，Stable Cascade模型">
                <meta property="og:title" content="【AI 绘画工具】最好的开源文本到图像模型，语义理解和图像质量最佳，Stable Cascade模型">
                <title>【AI 绘画工具】最好的开源文本到图像模型，语义理解和图像质量最佳，Stable Cascade模型</title>
                <style>.hidden{visibility:hidden;font-size:1px;}</style>
            </head>
            <body>
                <div class="rich_media_wrp" id="img-content">
<h1 class="rich_media_title" id="activity-name">
            
【AI 绘画工具】最好的开源文本到图像模型，语义理解和图像质量最佳，Stable Cascade模型
          </h1>

<div class="rich_media_content js_underline_content autoTypeSetting24psection" id="js_content" style="visibility: visible;"><p>Stable Diffusion 系列模型仍然是开源文本到图像模型的王者。</p><p>今天分享由 stability.ai 发布的另一个开源文本到图像模型，语义理解和图像质量都要好于Stable Diffusion 系列模型，是目前最好的开源文本到图像模型，Stable Cascade。</p><p><img class="rich_pages wxw-img" data-height="390" data-imgfileid="100001294" data-ratio="0.5416666666666666" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/gnQt5CH21zxXBUdg3UBhMoVSiajVprxxY0ySlwlar96FgFGib3Bro1s3EOFIGQmeMsdvjrjNIdUgAiaa4Cib52hiblw/640?wx_fmt=jpeg&amp;from=appmsg" data-type="jpeg" data-w="720" data-width="720" src="20240525_031035_0.jpeg"/></p><p>项目代码地址：https://github.com/Stability-AI/StableCascade</p><p>项目报告地址：https://arxiv.org/pdf/2306.00637.pdf</p><p>项目演示地址：https://stability.ai/news/introducing-stable-cascade</p><p><strong>一、Stable </strong><strong>Cascade</strong><strong>模型介绍</strong></p><p>Stable Cascade模型建立在 Würstchen 架构之上，它与 Stable Diffusion 等其他模型的主要区别在于它的工作潜在空间要小得多。</p><p>为什么这很重要？潜在空间越小，运行推理的速度就越快，训练成本就越低。</p><p>潜伏空间有多小？Stable Diffusion 使用压缩因子 8，从而将 1024x1024 图像编码为 128x128。Stable Cascade 实现了 42 的压缩系数，这意味着可以将 1024x1024 图像编码为 24x24，同时保持清晰的重建。然后，在高度压缩的潜在空间中训练文本条件模型。与 Stable Diffusion 1.5 相比，该架构的早期版本实现了 16 倍的成本降低。</p><p>因此，这种模型非常适合效率很重要的用途。此外，所有已知的扩展，如微调、LoRA、ControlNet、IP-Adapter、LCM 等，也可以通过这种方法实现。其中一些已经在训练和推理部分提供（微调、ControlNet、LoRA）。</p><p><img class="rich_pages wxw-img" data-height="288" data-imgfileid="100001293" data-ratio="0.4" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/gnQt5CH21zxXBUdg3UBhMoVSiajVprxxYCz4vj3dlQYqmz98zh8xc4Q72iaowu8NrVFDLqaibLE4fCvsrkFlgVy4g/640?wx_fmt=jpeg&amp;from=appmsg" data-type="jpeg" data-w="720" data-width="720" src="20240525_031036_1.jpeg"/></p><p><strong>二、Stable </strong><strong>Cascade</strong><strong>模型的技术框架和主要技术细节</strong></p><p><img class="rich_pages wxw-img" data-height="459" data-imgfileid="100001292" data-ratio="0.6375" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/gnQt5CH21zxXBUdg3UBhMoVSiajVprxxYzMAMImQstUbNCVU8viaiaPyHjt3h4xzhdk9tYpTibiaCia7nYUVziaBhE9Lg/640?wx_fmt=jpeg&amp;from=appmsg" data-type="jpeg" data-w="720" data-width="720" src="20240525_031037_2.jpeg"/></p><p>Stable Cascade模型的技术框架是一个三阶段的文本到图像合成模型，旨在通过高效的潜在空间处理来减少计算需求，同时保持图像生成的质量。以下是主要技术细节：</p><p>1、阶段A（Stage A）：</p><p>使用Vector Quantized Generative Adversarial Network (VQGAN) 进行图像编码，将高分辨率图像压缩到一个低维度的潜在空间。</p><p>VQGAN由编码器和解码器组成，编码器将图像映射到一个离散的潜在空间，而解码器则从这个潜在空间重构图像。</p><p>在训练阶段A时，VQGAN被训练以重建输入图像，同时在训练过程中随机丢弃量化步骤，以适应后续的潜在空间变化。</p><p><img class="rich_pages wxw-img" data-height="254" data-imgfileid="100001296" data-ratio="0.3527777777777778" data-src="https://mmbiz.qpic.cn/mmbiz_png/gnQt5CH21zxXBUdg3UBhMoVSiajVprxxYvjfzo4Dj7RNtorqzcFar6bLtVGqzjQH4bJwHNC22bggicrwia8Noe0sg/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="720" data-width="720" src="20240525_031038_3.jpeg"/></p><p>2、阶段B（Stage B）：</p><p>在阶段A的基础上，训练一个条件潜在扩散模型（LDM），该模型在阶段A的潜在空间内进行操作。</p><p>使用一个称为Semantic Compressor的编码器，以非常高的空间压缩率创建潜在表示，这些表示用于指导扩散过程。</p><p>阶段B的模型在文本嵌入和Semantic Compressor的输出的条件下，通过扩散过程重建阶段A建立的潜在空间。</p><p><img class="rich_pages wxw-img" data-height="278" data-imgfileid="100001295" data-ratio="0.3861111111111111" data-src="https://mmbiz.qpic.cn/mmbiz_png/gnQt5CH21zxXBUdg3UBhMoVSiajVprxxYGoCL3vs2sYz6nw4dQfxGhqm5iciazdGm48MopN8qsUvkDiaicNjI91ezZw/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="720" data-width="720" src="20240525_031039_4.jpeg"/></p><p>3、阶段C（Stage C）：</p><p>在阶段B训练完成后，开始训练文本条件的LDM，该模型在Semantic Compressor产生的强压缩潜在表示上操作。</p><p>阶段C的模型通过扩散过程从随机噪声生成图像的潜在表示，这些表示随后被用于条件文本生成。</p><p>阶段C的模型使用ConvNeXt块构建，不进行下采样，通过交叉注意力机制进行文本和时间步长的条件。</p><p><img class="rich_pages wxw-img" data-height="288" data-imgfileid="100001297" data-ratio="0.4" data-src="https://mmbiz.qpic.cn/mmbiz_png/gnQt5CH21zxXBUdg3UBhMoVSiajVprxxYicLiaE4AUBrp1UIVy4ujqhuN8cqdrSwC0RjeibCXxF3dcxylHeeClv28Q/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="720" data-width="720" src="20240525_031040_5.jpeg"/></p><p>4、训练过程：</p><p>训练是按照逆序进行的，首先训练阶段A，然后是阶段B，最后是阶段C。</p><p>阶段A的训练使用VQGAN创建潜在空间，阶段B在阶段A的潜在空间内进行扩散模型训练，阶段C则在Semantic Compressor的潜在表示上进行训练。</p><p><img class="rich_pages wxw-img" data-height="392" data-imgfileid="100001298" data-ratio="0.5444444444444444" data-src="https://mmbiz.qpic.cn/mmbiz_png/gnQt5CH21zxXBUdg3UBhMoVSiajVprxxYicOCENOAHqkWuU0pX4W2TRGRswOjictKzPFehxYux6Qaf463aZYCuLiag/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="720" data-width="720" src="20240525_031041_6.jpeg"/></p><p>5、文本条件：</p><p>在阶段C中，使用CLIP-H（一个未池化的CLIP模型）进行文本条件，以确保生成的图像与文本描述相匹配。</p><p><img class="rich_pages wxw-img" data-height="279" data-imgfileid="100001300" data-ratio="0.3875" data-src="https://mmbiz.qpic.cn/mmbiz_png/gnQt5CH21zxXBUdg3UBhMoVSiajVprxxYodrm80aqY135rgVwM48e221AfW9O8lo6lNS0GibRUkC0JlJwcyjkIBA/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="720" data-width="720" src="20240525_031043_7.jpeg"/></p><p>6、图像生成（采样）：</p><p>生成过程从阶段C开始，使用DDPM算法采样Semantic Compressor的潜在表示，然后传递给阶段B，最后通过VQGAN的解码器重构图像。</p><p><img class="rich_pages wxw-img" data-height="224" data-imgfileid="100001299" data-ratio="0.3111111111111111" data-src="https://mmbiz.qpic.cn/mmbiz_png/gnQt5CH21zxXBUdg3UBhMoVSiajVprxxYTO7uHhiaVibzHe6FDzuq9lSCaXB7ECr7DZTxlxx1Sk7PqAxX4zfboHpQ/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="720" data-width="720" src="20240525_031044_8.jpeg"/></p><p>7、模型决策：</p><p>Semantic Compressor使用ImageNet预训练的EfficientV2 (S)作为骨干网络，因为它结合了高压缩率和良好的特征表示。</p><p>阶段C放弃了U-Net的标准架构，因为图像已经被压缩了42倍，进一步压缩可能会损害模型质量。</p><p><img class="rich_pages wxw-img" data-height="303" data-imgfileid="100001301" data-ratio="0.42083333333333334" data-src="https://mmbiz.qpic.cn/mmbiz_png/gnQt5CH21zxXBUdg3UBhMoVSiajVprxxYyTEHDPjcrAzZSjXbBKrjoV84enpia79HGxaOAoVjwDv2uZ8vJYACJow/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="720" data-width="720" src="20240525_031045_9.jpeg"/></p><p><strong>三、Stable Cascade模型与其他的比较结果</strong></p><p>Stable Cascade 在视觉和评估方面都取得了令人印象深刻的结果。</p><p>根据我们的评估，在几乎所有比较中，Stable Cascade 在快速对齐和美学质量方面都表现最佳。</p><p><img class="rich_pages wxw-img" data-height="369" data-imgfileid="100001303" data-ratio="0.5125" data-src="https://mmbiz.qpic.cn/mmbiz_png/gnQt5CH21zxXBUdg3UBhMoVSiajVprxxYezxZqbCdicG4DGGpeT4kxgeITUmqicbCvdemINZewXCQsia3Fv5PDFhzA/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="720" data-width="720" src="20240525_031046_10.jpeg"/></p><p>上图显示了使用部分提示（链接）和美学提示混合进行的人工评估的结果。</p><p>具体而言，将 Stable Cascade（30 个推理步骤）与 Playground v2（50 个推理步骤）、SDXL（50 个推理步骤）、SDXL Turbo（1 个推理步骤）和 Würstchen v2（30 个推理步骤）进行了比较。</p><p>Stable Cascade 对效率的关注通过其架构和更高压缩的潜在空间得到了证明。尽管最大的模型比 Stable Diffusion XL 多包含 14 亿个参数，但它仍然具有更快的推理时间，如下图所示。</p><p><img class="rich_pages wxw-img" data-height="462" data-imgfileid="100001302" data-ratio="0.6416666666666667" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/gnQt5CH21zxXBUdg3UBhMoVSiajVprxxY28nANvChFuLnibfgbqs5ibCt2XjUQKuOTlytjDj6q7Z64kTbiaSLXxfqg/640?wx_fmt=jpeg&amp;from=appmsg" data-type="jpeg" data-w="720" data-width="720" src="20240525_031047_11.jpeg"/></p><p><span data-lark-record-format="docx/record">我是：</span></p><p><span data-lark-record-format="docx/record"><span style='color: rgb(90, 92, 102);font-family: "PingFang SC", Tahoma, Helvetica, Arial, "Hiragino Sans GB", "Microsoft YaHei", "Heiti SC", "WenQuanYi Micro Hei", sans-serif;font-size: 14px;letter-spacing: normal;white-space: pre-wrap;background-color: rgb(255, 255, 255);'>三万人社群——AI破局俱乐部初创合伙人（需要社群资源，来链接我）
小冰数字人合作伙伴（小冰数字人产品一手货源，<span style='color: rgb(90, 92, 102);font-family: "PingFang SC", Tahoma, Helvetica, Arial, "Hiragino Sans GB", "Microsoft YaHei", "Heiti SC", "WenQuanYi Micro Hei", sans-serif;font-size: 14px;letter-spacing: normal;white-space: pre-wrap;background-color: rgb(255, 255, 255);'>来链接我</span>）
正致力于人工智能技术在B，C端应用的技术支持和咨询服务（需要企业培训、行业解决方案，来链接我）</span></span></p><p><img class="rich_pages wxw-img" data-imgfileid="100000821" data-ratio="0.9680851063829787" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/gnQt5CH21zyL8XfWTNib6UuS0ic7HKbaIoj7icrr6OS3x5zcyGTCfRVY90erZiaJ98bkeCKJ6A8icaIAu3MccAAtfdA/640?wx_fmt=jpeg&amp;from=appmsg" data-type="jpeg" data-w="752" src="20240525_031048_12.jpeg" style=""/></p><p><span style="font-size: var(--articleFontsize);letter-spacing: 0.034em;"></span></p><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div>

</div>
                <p></p>
                <p></p>
                <div>本文由“公众号文章抓取器”生成，请忽略上文所有联系方式或指引式信息。有问题可以联系：五人工作室，官网：www.Wuren.Work，QQ微信同号1976.424.585 </div>
                <div  class="hidden">本文由“公众号文章抓取器”生成，请忽略上文所有联系方式或指引式信息。有问题可以联系：五人工作室，官网：www.Wuren.Work，QQ微信同号1976.424.585 <br><p class="hidden">code/s?__biz=Mzg2NDk3ODc1OA==&mid=2247484956&idx=1&sn=2ade376b021def7e0714ef3b38c54c22&chksm=ce605435f917dd2368217594a514beb560ee27e91e7416c3dd0db391fc44655c0d5d8499fbad#rd </p></div>
            </body>
            </html>
            