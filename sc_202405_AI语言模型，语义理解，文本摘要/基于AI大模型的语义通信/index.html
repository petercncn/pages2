
            <!DOCTYPE html>
            <html lang="en">
            <head>
                <meta charset="UTF-8">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                <meta name="description" content="">
                <meta name="keywords" content="基于AI大模型的语义通信, ">
                <meta property="og:title" content="基于AI大模型的语义通信">
                <title>基于AI大模型的语义通信</title>
                <style>.hidden{visibility:hidden;font-size:1px;}</style>
            </head>
            <body>
                <div class="rich_media_wrp" id="img-content">
<h1 class="rich_media_title" id="activity-name">
            
基于AI大模型的语义通信
          </h1>

<div class="rich_media_content js_underline_content autoTypeSetting24psection" id="js_content" style="visibility: visible;"><section style="font-size: 16px;"><section powered-by="xiumi.us" style="text-align: center;justify-content: center;display: flex;flex-flow: row;margin-top: 10px;margin-bottom: 10px;"><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 0 0 auto;min-width: 5%;height: auto;"><section powered-by="xiumi.us" style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;"><section style="display: inline-block;width: auto;vertical-align: top;align-self: flex-start;flex: 0 0 auto;min-width: 5%;height: auto;line-height: 0;padding-right: 3px;padding-bottom: 3px;padding-left: 8px;border-style: solid;border-width: 0px 2px 2px 0px;border-color: rgb(95, 151, 250) rgb(109, 181, 236) rgb(109, 181, 236) rgb(95, 151, 250);"><section powered-by="xiumi.us" style="text-align: center;"><section style="display: inline-block;width: 28px;height: 8px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 0px 1px 1px 0px;border-color: rgb(95, 151, 250) rgb(109, 181, 236) rgb(109, 181, 236) rgb(95, 151, 250);"><section powered-by="xiumi.us" style="text-align: justify;color: rgb(62, 62, 62);"><p style="text-wrap: wrap;"><br/></p></section></section></section></section></section></section><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 0 0 auto;min-width: 5%;height: auto;padding-right: 7px;padding-left: 7px;"><section powered-by="xiumi.us" style="text-align: justify;font-size: 19px;color: rgb(34, 108, 164);"><p style="text-align: center;text-wrap: wrap;"><strong>论文分享</strong></p></section><section powered-by="xiumi.us" style="margin-top: -5px;"><section style="text-align: justify;font-size: 12px;color: rgb(255, 255, 255);"><p style="text-align: center;text-wrap: wrap;"><span style="background-color: rgb(109, 181, 236);"> GenAINet通信大模型 </span></p></section></section></section><section style="display: inline-block;vertical-align: middle;width: auto;align-self: center;flex: 0 0 auto;min-width: 5%;height: auto;"><section powered-by="xiumi.us" style="transform: perspective(0px);transform-style: flat;"><section style="text-align: left;justify-content: flex-start;display: flex;flex-flow: row;transform: rotateY(180deg);"><section style="display: inline-block;width: auto;vertical-align: top;align-self: flex-start;flex: 0 0 auto;min-width: 5%;height: auto;line-height: 0;padding-right: 3px;padding-bottom: 3px;padding-left: 8px;border-style: solid;border-width: 0px 2px 2px 0px;border-color: rgb(95, 151, 250) rgb(109, 181, 236) rgb(109, 181, 236) rgb(95, 151, 250);"><section powered-by="xiumi.us" style="text-align: center;"><section style="display: inline-block;width: 28px;height: 8px;vertical-align: top;overflow: hidden;border-style: solid;border-width: 0px 1px 1px 0px;border-color: rgb(95, 151, 250) rgb(109, 181, 236) rgb(109, 181, 236) rgb(95, 151, 250);"><section powered-by="xiumi.us" style="text-align: justify;"><p style="text-wrap: wrap;"><br/></p></section></section></section></section></section></section></section></section></section><p style="margin-bottom: 8px;letter-spacing: 0.578px;text-wrap: wrap;font-size: 16px;"><span style="font-size: 14px;">语义通信(SC)是一种新兴的智能范式，为未来的各种应用提供了解决方案，如元宇宙、混合现实和万物互联。现今<span style="letter-spacing: 0.034em;">大多数AI驱动的语义通信系统模型都以设计高效的通信模型为中心，这些模型严重依赖于语义通信的编码器和解码器来提取和解释语义。</span><span style="letter-spacing: 0.034em;">尽管这些方法能够从非结构化数据源中提取语义信息，但它们并没有充分利用知识库的潜在好处。<span style="letter-spacing: 0.578px;"></span></span></span></p><p style="margin-bottom: 8px;letter-spacing: 0.578px;text-wrap: wrap;font-size: 16px;"><span style="font-size: 14px;"><span style="letter-spacing: 0.578px;">为了解决上述问题，</span>江沸菠教授团队提出了一个专用于图像数据的基于AI大模型的语义通信框架(LAM-SC)。设计了基于SAM的知识库(SKB)，并提出了一种基于注意力的语义集成(attention-based semantic integration, ASI)方法和一种自适应语义压缩(adaptive semantic compression, ASC)编码方法。<span style="font-size: 14px;letter-spacing: 0.578px;text-wrap: wrap;">LAM-SC框架展示</span>了基于AI大模型的知识库开发在未来语义通信中的重要性。</span></p><section powered-by="xiumi.us" style="margin-top: 10px;margin-bottom: 10px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;text-align: left;justify-content: flex-start;display: flex;flex-flow: row;"><section style="display: inline-block;width: 578px;vertical-align: top;align-self: flex-start;flex: 0 0 auto;border-style: solid;border-width: 0px 0px 0px 3px;border-color: rgb(143, 182, 249);"><section powered-by="xiumi.us" style="margin-top: 10px;margin-bottom: 10px;justify-content: flex-start;display: flex;flex-flow: row;"><section style="padding: 22px;display: inline-block;width: 575.143px;vertical-align: top;align-self: flex-start;flex: 0 0 auto;background-color: rgb(241, 246, 255);"><section powered-by="xiumi.us" style="margin-top: 10px;margin-bottom: 20px;text-align: center;justify-content: center;display: flex;flex-flow: row;"><section style="padding: 8px;display: inline-block;width: auto;vertical-align: top;align-self: flex-start;flex: 0 0 auto;border-style: solid;border-width: 1px;min-width: 5%;height: auto;box-shadow: rgb(69, 119, 218) 6px 6px 0px 0px;"><section powered-by="xiumi.us" style="text-align: left;"><section style="text-align: justify;font-size: 17px;"><p style="text-align: left;"><strong><span style="font-size: 16px;"><span lang="EN-US" style='font-family: "Times New Roman", serif;'>Large AI Model-Based Semantic Communications</span></span></strong></p></section></section></section></section><section powered-by="xiumi.us" style="font-size: 14px;text-align: justify;color: rgb(0, 0, 0);"><p>Feibo Jiang<sup style="font-size: 11px;">1</sup>, Yubo Peng<sup style="font-size: 11px;">2</sup>, Li Dong<sup style="font-size: 11px;">3</sup>, Kezhi Wang<sup style="font-size: 11px;">4</sup>, Kun Yang<sup style="font-size: 11px;">5</sup>, Cunhua Pan<sup style="font-size: 11px;">6</sup>, Xiaohu You<sup style="font-size: 11px;">6,7,8</sup><sup style="font-size: 11px;"></sup></p><p><sup style="font-size: 11px;"><br/></sup></p></section><section powered-by="xiumi.us" style="text-align: justify;"><p style="text-align: left;"><sup style="font-size: 11px;">1</sup><span style='font-family: "Times New Roman", serif;color: rgb(0, 82, 255);font-size: 12px;'>Hunan Provincial Key Laboratory of Intelligent Computing and Language Information Processing, Hunan Normal University</span></p><p style="font-size: 14px;text-align: left;"><span style="font-size: 12px;"><sup style="font-size: 11px;">2</sup></span><span style="font-size: 12px;"><sup style="font-size: 11px;"><span style='letter-spacing: 0.578px;color: rgb(0, 82, 255);font-size: 12px;font-family: "Times New Roman", serif;'>School of Information Science and Engineering, Hunan Normal University</span></sup></span></p><p style="font-size: 14px;text-align: left;"><span style="font-size: 12px;"><sup style="font-size: 11px;">3</sup></span><span style="font-size: 12px;"><sup style="font-size: 11px;"><span style='letter-spacing: 0.578px;color: rgb(0, 82, 255);font-size: 12px;font-family: "Times New Roman", serif;'>Changsha Social Laboratory of Artificial Intelligence, Hunan University of Technology and Business</span></sup></span></p><p style="font-size: 14px;text-align: left;"><span style="font-size: 12px;"><sup style="font-size: 11px;">4</sup></span><span style="font-size: 12px;"><sup style="font-size: 11px;"><span style='letter-spacing: 0.578px;color: rgb(0, 82, 255);font-size: 12px;font-family: "Times New Roman", serif;'>Department of Computer Science, Brunel University London</span></sup></span></p><p style="font-size: 14px;text-align: left;"><span style="font-size: 12px;"><sup style="font-size: 11px;">5</sup></span><span style="font-size: 12px;"><sup style="font-size: 11px;"><span style='letter-spacing: 0.578px;color: rgb(0, 82, 255);font-size: 12px;font-family: "Times New Roman", serif;'>School of Computer Science and Electronic Engineering, University of Essex</span></sup></span></p><p style="font-size: 14px;text-align: left;"><span style="font-size: 12px;"><sup style="font-size: 11px;">6</sup></span><span style="font-size: 12px;"><sup style="font-size: 11px;"><span style='letter-spacing: 0.578px;color: rgb(0, 82, 255);font-size: 12px;font-family: "Times New Roman", serif;'>National Mobile Communications Research Laboratory, Southeast University</span></sup></span></p><p style="font-size: 14px;text-align: left;"><span style="font-size: 12px;"><sup style="font-size: 11px;">7</sup></span><span style="font-size: 12px;"><sup style="font-size: 11px;"><span style='letter-spacing: 0.578px;color: rgb(0, 82, 255);font-size: 12px;font-family: "Times New Roman", serif;'>Frontiers Science Center for Mobile Information Communication and Security, Southeast University</span></sup></span></p><p style="font-size: 14px;text-align: left;"><span style="font-size: 12px;"><sup style="font-size: 11px;">8</sup></span><span style="font-size: 12px;"><sup style="font-size: 11px;"><span style='letter-spacing: 0.578px;color: rgb(0, 82, 255);font-size: 12px;font-family: "Times New Roman", serif;'>Purple Mountain Laboratories</span></sup></span></p><p style="font-size: 14px;"><br/></p></section><section powered-by="xiumi.us" style="text-align: justify;"><p><strong><span style="font-size: 14px;">原文链接</span></strong><span style="font-size: 14px;">：</span><span style="font-size: 14px;letter-spacing: 0.034em;">https://arxiv.org/abs/2307.03492</span><span style="font-size: 14px;letter-spacing: 0.034em;"></span></p></section></section></section><section powered-by="xiumi.us" style="text-align: right;justify-content: flex-end;display: flex;flex-flow: row;"><section style="display: inline-block;width: 316.321px;vertical-align: top;align-self: flex-start;flex: 0 0 auto;height: auto;"><section powered-by="xiumi.us" style="text-align: center;"><section style="background-color: rgb(139, 219, 199);height: 3px;"><svg style="float:left;line-height:0;width:0;vertical-align:top;" viewbox="0 0 1 1"></svg></section></section></section></section></section></section><p style="margin-bottom: 0px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 0.578px;"><br/></span></p><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="color: rgb(2, 30, 170);"><strong>1. 背景：</strong></span></p><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;">语义通信作为一种新的智能范式，近年来受到了广泛的关注。与传统的通信方法不同，语义通信侧重于确保传输比特或符号的准确性，它优先考虑用最少的数据传递预期的含义。语义通信系统通常包含下列组件：语义编码器（Semantic encoder）、 信道编码器 (Channel encoder)、 信道解码器 (Channel decoder)、 语义解码器 (Semantic decoder)、 知识库 (Knowledge base)。 上述组件可通过应用具有优越的自学习和特征提取能力的深度神经网络（DNNs）来实现。</span></p><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;"><strong style="color: rgb(2, 30, 170);letter-spacing: 0.578px;">1.1 语义通信系统中通用知识库的组成</strong></span></p><section style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;">知识库是语义通信区别于传统通信系统的关键所在，因为它具有理解和推断语义信息的能力。可以通过学习大量的世界知识来建立一个通用知识库，它是语义通信系统的核心。通用知识库由两部分组成：</span></section><section style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;">1）先验知识：通过先验知识，语义通信定义了语义表示的结构和实体之间的关系。例如，在图像理解方面，语义信息可以用三元组形式表示，由三部分组成，即目标、属性和关系。</span></section><section style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;">2）背景知识：语义信息不仅仅是显性信息，还涉及上下文、隐含意义和常见事实。语义通信也涉及发送方和接收方之间的背景知识交流，如用户身份、兴趣偏好和用户环境。</span></section><section style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><strong style="font-size: 14px;letter-spacing: 0.578px;color: rgb(2, 30, 170);">1.2 语义通信系统中当前知识库方案存在的问题</strong></section><section style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;">目前语义通信中的知识库方案是基于成熟的深度学习技术，这是一个数据驱动的学习过</span><span style="font-size: 14px;">程。然而，复杂和耗时的学习过程会导致下列问题。</span></section><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;">1）有限的知识表示：传统的语义通信系统，通常使用DNNs或KGs作为知识库，通过监督学习从环境中学习。然而，知识库的层次和参数是受限的，并且从环境中收集的标记数据成本高昂。</span></p><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;">2）频繁的知识更新：当前的知识库方案需要在环境中知识领域发生变化时，通过训练和共享不断更新知识。这些更新通常会产生巨大的能源和资源成本，从而进一步降低知识库的效率。</span></p><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;">3）不安全的知识共享：为避免语义错误，需要分享知识库并确保发送者和接收者在语义上对齐，这需要在不同用户之间频繁传输知识模型。这些知识模型可能包含一些高度敏感的与人类相关的信息，这引入了潜在的隐私和安全风险。</span></p><section style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;"><strong style="color: rgb(2, 30, 170);font-size: 16px;letter-spacing: 0.578px;">2. 语义通信系统中基于AI大模型的知识库：</strong></span></section><section style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;">近年来，AI大模型近年来在自然语言处理、图像识别和语音识别等领域取得了重大进展。它具有准确的知识表示、丰富的先验/背景知识和低成本的知识更新等诸多优势，从而为解决上述问题和增强语义通信系统提供了新的机遇。</span></section><section style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><strong style="font-size: 14px;letter-spacing: 0.578px;color: rgb(2, 30, 170);">2.1 基于AI大模型的知识库的优势</strong></section><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;">1）准确的知识表示：当前的AI大模型，具有数百千亿个参数，能够从带有多头注意力机制的Transformer模型中学习复杂的知识表示。例如，在AI大模型中，“苹果公司”和“苹果汽水”中的“苹果”一词将被表示为不同的特征。</span></p><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;">2）丰富的显眼/背景知识：AI大模型在广泛的数据集上进行预训练，使其能够从各个领域的大量信息中学习，并存储丰富的先验/背景知识，展现出卓越的泛化能力。</span></p><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;">3）低成本的知识更新：AI大模型通常具有预训练的权重，并且可以通过仅使用少量示例进行提示或使用少量标记数据进行微调，减轻了频繁知识更新和不安全知识共享的担忧。</span></p><section style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><strong style="font-size: 14px;letter-spacing: 0.578px;color: rgb(2, 30, 170);">2.2 语义通信系统中AI大模型的设计建议</strong></section><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;">本文针对不同类型的语义通信系统（如文本、图像、音频等）提出了几种设计方案，允许将AI大模型无缝集成到知识库创建中，如图1所示。</span></p><section style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><img class="rich_pages wxw-img" data-imgfileid="100000285" data-ratio="0.36184971098265895" data-src="https://mmbiz.qpic.cn/mmbiz_png/HIrMQuKFwN1tHP81WnBPxj4slF6wZT5o1IRmrSrpkmu6nUrRgVV84bQqCauYH0ySBuEEX7mpcNL3vU4SC5cia1A/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="865" src="20240525_031256_0.jpeg"/></section><section style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;text-align: center;"><strong><span style="font-size: 12px;"><em>图1.  基于AI大模型的知识库在不同语义通信模型中的实现</em></span></strong></section><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><strong><span style="font-size: 14px;">1）基于GPT的知识库：</span></strong><span style="font-size: 14px;">针对基于文本的语义通信系统，知识库应能够理解文本的内容，并识别各种主题、属性和关系。近年来出现了大规模语言模型，如ChatGPT，它可以作为文本数据的语义知识库。</span></p><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><strong><span style="font-size: 14px;">2）基于SAM的知识库：</span></strong><span style="font-size: 14px;">对于基于图像的语义通信系统，知识库应能够对图像中的各种目标进行分割，并识别它们各自的类别和相互关系。在这里可以应用的一种有前景的AI模型是由Meta AI提出的Segment Anything Model（SAM）。</span></p><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><strong><span style="font-size: 14px;">3）基于WavLM的知识库：</span></strong><span style="font-size: 14px;">为了使语义通信系统适用于音频，知识库应能够执行多种音频任务，包括自动语音识别、说话人识别和语音分离。这确保原始音频数据可以被有效地分析并提取语义信息。微软亚洲研究院提出的大规模音频模型WavLM可以成为此应用的潜在解决方案之一。</span></p><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="color: rgb(2, 30, 170);"><strong>3. 本文所提LAM-SC框架架构：</strong></span><br/></p><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;">将AI大模型引入到语义通信系统中是在基于图像的语义通信系统中实现更精确的语义感知和通用知识库的一种有前景的解决方案。本文提出了LAM-SC框架，将SAM模型纳入到语义通信系统中，工作流程如图2所示。</span></p><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;"><img class="rich_pages wxw-img" data-imgfileid="100000283" data-ratio="0.3040462427745665" data-src="https://mmbiz.qpic.cn/mmbiz_png/HIrMQuKFwN1tHP81WnBPxj4slF6wZT5o4gRMQRon7Nv8Qr2MEHKCs5MWJsF9yW3V03yZ2ayKOpJWPqzOqiaB3Kg/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="865" src="20240525_031258_1.jpeg"/></span></p><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;text-align: center;"><span style="font-size: 14px;"><strong style="font-size: 16px;letter-spacing: 0.578px;"><span style="font-size: 12px;"><em>图</em></span></strong></span><span style="font-size: 14px;"><strong style="font-size: 16px;letter-spacing: 0.578px;"><span style="font-size: 12px;"><em>2.  LAM-SC框架的流程</em></span></strong></span></p><p style="margin-bottom: 0px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="color: rgb(2, 30, 170);font-size: 14px;"><strong>3.1 LAM-SC框架简介</strong></span><span style="font-size: 14px;letter-spacing: 0.034em;"></span></p><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><strong><span style="font-size: 14px;">1）知识库构建和语义分割: </span></strong><span style="font-size: 14px;">为了实现对没有经过训练的知识库的任何原始图像进行语义分割，可以应用SKB来实现对输入图像中每个语义目标的识别和分割。</span></p><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><strong><span style="font-size: 14px;">2）基于注意力的语义整合: </span></strong><span style="font-size: 14px;">ASI可以通过信道注意力和空间注意力模拟人类的感知，选择最值得关注的语义片段。此外，还提供了一种人类提示的方式，可以直接选择感兴趣的语义片段。选择的片段可以合并成一个新的具有语义感知的图像。</span></p><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><strong><span style="font-size: 14px;">3) 语义自适应编码和信道编码：</span></strong><span style="font-size: 14px;">语义感知图像通过语义编码器转换为语义特征。在这里，语义编码器是基于卷积神经网络（CNNs）构建的，其具有出色的图像特征提取能力。基于多层感知机（MLP）构建的信道编码器可以用于对物理信道进行信号编码和调制。</span></p><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><strong><span style="font-size: 14px;">4) 信道解码和语义解码: </span></strong><span style="font-size: 14px;">在这些模块中，当传输的信号通过物理信道到达接收端时，信道解码器进行信号解调和解码，然后获得语义特征。信道解码器采用MLP架构。接下来，由反卷积层组成的语义解码器对语义特征进行解码，从而恢复图像数据。</span><strong style="letter-spacing: 0.578px;"><span style="font-size: 12px;"></span></strong></p><section style="margin-bottom: 0px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="color: rgb(2, 30, 170);font-size: 14px;"><strong>3.2 SKB</strong></span></section><section style="margin-bottom: 0px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="color: rgb(2, 30, 170);font-size: 14px;"></span></section><section style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;"></span><span style="font-size: 14px;letter-spacing: 0.578px;">为了在没有特定训练的情况下实现对任意输入图像的精确图像语义分割，在提出的LAM-SC框架中采用了SAM作为知识库，即SKB，如图2所示，它处理图像语义分割过程。</span><span style="font-size: 14px;letter-spacing: 0.578px;">本文利用SKB自动实现客观目标的分离，产生多个语义片段供进一步分析和处理。</span><span style="font-size: 14px;letter-spacing: 0.578px;">SKB具有足够的先验/背景知识和强大的</span><span style="font-size: 14px;letter-spacing: 0.578px;">语义表示能力，可以在原始图像数据上准确执行语义分割，从而确保语义通信系统中知识库的普适性。</span></section><p style="margin-bottom: 0px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="color: rgb(2, 30, 170);font-size: 14px;"><strong>3.3 ASI</strong></span></p><section style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;"></span><span style="font-size: 14px;"></span></section><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;letter-spacing: 0.578px;">ASI引入了注意力机制来识别和加权图像中重要目标，它由两部分组成:</span></p><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;letter-spacing: 0.578px;">1) 信道注意力网络: 使用信道注意力网络，可以从语义分割中提取低层语义。每个分割被视为一个信道，并进行全局池化和均值池化操作。然后将结果输入到MLP网络中来评估信道的重要性。将MLP的输出结合起来确定语义的重要程度，然后将其与语义分割相乘，得到低层语义。</span></p><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;letter-spacing: 0.578px;">2) 空间注意网络:每个低层语义表示单个分割，无法充分捕捉整个图像的语义。为了解决这个问题，使用空间注意力网络来合并低层语义，得到高层语义表示。具体地，分别对低层语义进行全局池化和均值池化，并沿图像通道维度进行连接，然后应用CNN将所有低层语义集成为高层语义感知图像。</span></p><p style="margin-bottom: 0px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><strong style="color: rgb(2, 30, 170);font-size: 14px;letter-spacing: 0.578px;">3.4 ASC</strong></p><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;letter-spacing: 0.578px;">本文提出了ASC方法，该方法从语义级别自适应地屏蔽传输的语义特征，有效地减少了冗余数据，并显著降低了通信开销。如图2所示，本文利用一个可学习的掩码网络生成掩码矩阵，从而消除了编码的语义特征中的不重要数据。在传输过程中，编码的语义特征被输入到掩码网络中，该网络输出一个相应的由0或1组成的掩码矩阵。然后将语义特征与掩码矩阵相乘，将一部分不重要的特征置为0，从而得到屏蔽后的语义特征。</span></p><section style="margin-bottom: 16px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;letter-spacing: 0.578px;">通过将ASC应用于语义传输过程，可以保留重要的语义特征，同时移除多余的语义特征，从而大大减少通信开销。</span></section><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="color: rgb(2, 30, 170);"><strong>4. LAM-SC框架的训练：</strong></span><br/></p><p style="margin-bottom: 16px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;letter-spacing: 0.578px;">本文提出的LAM-SC框架的训练过程如图3所示。简要描述如下：</span><o:p></o:p></p><p style="margin-bottom: 16px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;letter-spacing: 0.578px;">1) 基于人类经验的ASI训练：本文记录人类感兴趣的语义作为经验，构建了一个经验库。通过对经验数据库的监督学习，注意网络可以有效地适应人类行为，并做出与人类感知非常相似的决策。</span></p><p style="margin-bottom: 16px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;letter-spacing: 0.578px;">2) 基于交叉的语义通信</span><span style="font-size: 14px;letter-spacing: 0.578px;">编码器和</span><span style="font-size: 14px;letter-spacing: 0.578px;">解码器训练：实施一个交叉训练策略，首先训练通道模型，然后冻结其参数，然后训练语义模型。之后冻结语义模型参数并再次训练通道模型。这个过程可以重复，直到整个SC模型达到收敛。</span></p><p style="margin-bottom: 16px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;letter-spacing: 0.578px;">3) ASC训练: 为了生成准确反映语义特征重要性的掩码数组，本文提出了一种掩码网络和语义通信模型（即信道/语义编码器/解码器）的联合训练方法，其中语义通信模型和注意力网络的参数被冻结。首先，原始的和经过掩码的语义特征都被传输。然后，这两组语义特征分别进行解码。接下来，使用原始语义和掩码语义的恢复图像之间的差异被用作掩码网络的损失函数，使其能够学习如何产生能够最小化该差异的最优掩码矩阵。</span></p><p style="margin-bottom: 0px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;"><img class="rich_pages wxw-img" data-imgfileid="100000284" data-ratio="0.5745664739884393" data-src="https://mmbiz.qpic.cn/mmbiz_png/HIrMQuKFwN1tHP81WnBPxj4slF6wZT5oPuCK8BcCf4YeBw7QqPclWTmfZXEKaic5gHcAv5XBJuCibUhRYWG7kSyw/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="865" src="20240525_031259_2.jpeg"/></span></p><p style="margin-bottom: 16px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;text-align: center;"><span style="letter-spacing: 0.578px;font-size: 14px;"><strong style="font-size: 16px;letter-spacing: 0.578px;"><span style="font-size: 12px;"><em>图3.  LAM-SC框架的训练过程</em></span></strong></span></p><section style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="color: rgb(2, 30, 170);"><strong>5. 实验验证：</strong></span><span style="font-size: 14px;letter-spacing: 0.034em;"></span></section><p style="margin-bottom: 16px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;letter-spacing: 0.578px;">本文用VOC2012数据集进行实验验证，比较了LAM-SC方法和传统SC方法。传统的语义通信模型被用作基准，其仅包括语义编解码器，以及信道编解码器。此外，传统的语义通信模型不利用SKB在传输之前分割原始图像。本文使用三个关键指标来评估性能:损失值、峰值信噪比（PSNR）和结构相似性（SSIM）。</span></p><p style="margin-bottom: 16px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;letter-spacing: 0.578px;">模拟结果如图4所示。图4（a）表明在相同的信噪比条件下，与传统的语义通信方案相比，LAM-SC具有更好的收敛结果。图4（b）表明使用LAM-SC传输的图像获得更高的PSNR值，这意味着LAM-SC在传输过程中有效地减小了图像的失真。图4（c）证明LAM-SC保持了传输图像的结构一致性，从而获取了更高的SSIM值。</span></p><section style="margin-bottom: 0px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;letter-spacing: 0.578px;"></span></section><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;text-align: center;"><strong style="letter-spacing: 0.578px;"><span style="font-size: 12px;"><em>图4. LAM-SC的仿真结果。(a) 损失与迭代次数。(b)PSNR与信噪比。(c)SSIM与信噪比。</em></span></strong><br/></p><p style="margin-bottom: 8px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="letter-spacing: 0.034em;"><strong style="color: rgb(2, 30, 170);letter-spacing: 0.578px;">6. 结论：</strong></span></p><p style="margin-bottom: 16px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;"><span style="font-size: 14px;letter-spacing: 0.578px;">本文介绍了知识库的重要性和组成，并讨论了当前语义通信系统中知识库方案存在的问题。为了解决这些问题，本文提出引入AI大模型构建知识库，并探讨了几种基于AI大模型的方案，以实现不同语义通信系统中的知识库。然后，提出了一个以图像数据为重点的LAM-SC框架，在其中将SAM模型应用于知识库，实现高质量的语义分割，并提出了ASI作为一种新的语义感知源，用于集成分割的语义。此外，还提出了ASC来减少语义传输中的通信开销。最后，进行了仿真实验，以证明所提出的LAM-SC框架的有效性。</span></p><section style="margin-bottom: 0px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;outline: 0px;visibility: visible;"><section powered-by="xiumi.us" style="outline: 0px;text-align: center;"><section style="outline: 0px;visibility: visible;"><section powered-by="xiumi.us" style="margin-top: 10px;margin-bottom: 20px;outline: 0px;justify-content: center;display: flex;flex-flow: row;"><section class="js_darkmode__67" data-style="padding: 23px; outline: 0px; background-color: rgb(234, 234, 234); border-color: rgb(36, 81, 135); display: inline-block; width: 663.45px; vertical-align: top; align-self: flex-start; flex: 0 0 auto; border-style: solid; border-width: 1px; height: auto; box-shadow: rgb(90, 98, 173) 6px 6px 0px 0px; color: rgb(205, 205, 205) !important;" style="padding: 23px;outline: 0px;border-color: rgb(36, 81, 135);background-color: rgb(234, 234, 234);display: inline-block;width: 663.45px;vertical-align: top;align-self: flex-start;flex: 0 0 auto;border-style: solid;border-width: 1px;height: auto;box-shadow: rgb(90, 98, 173) 6px 6px 0px 0px;color: rgb(205, 205, 205) !important;"><section powered-by="xiumi.us" style="margin-top: 10px;margin-bottom: 10px;outline: 0px;"><section class="js_darkmode__68" data-style="padding-bottom: 2px; outline: 0px; border-bottom: 2px solid rgb(40, 85, 140); display: inline-block; vertical-align: top;" style="padding-bottom: 2px;outline: 0px;border-bottom: 2px solid rgb(40, 85, 140);display: inline-block;vertical-align: top;"><section class="js_darkmode__69" data-style="outline: 0px; border-bottom: 1px dashed rgb(40, 85, 140); color: rgb(36, 81, 135); font-size: 14px;" style="outline: 0px;border-bottom: 1px dashed rgb(40, 85, 140);color: rgb(36, 81, 135);font-size: 14px;"><p style="outline: 0px;"><span style="outline: 0px;font-size: 12px;"><strong style="outline: 0px;">GenAINet公众号简介</strong></span></p></section></section></section><section class="js_darkmode__70" data-style="outline: 0px; color: rgb(36, 81, 135); text-align: justify; font-size: 14px; line-height: 2;" powered-by="xiumi.us" style="outline: 0px;color: rgb(36, 81, 135);text-align: justify;font-size: 14px;line-height: 2;"><p style="outline: 0px;"><span style="outline: 0px;font-size: 12px;">GenAINet公众号由IEEE Large Generative AI Models in Telecom (GenAINet) ETI成立，由GenAINet公众号运营团队负责维护并运行。</span></p><p style="margin-top: 8px;margin-bottom: 8px;outline: 0px;"><span style="outline: 0px;font-size: 12px;">GenAINet公众号运营团队：</span></p><p style="outline: 0px;"><span style="outline: 0px;font-size: 12px;"><strong style="outline: 0px;">孙黎，彭程晖 （华为技术有限公司）</strong></span></p><p style="outline: 0px;"><span style="outline: 0px;font-size: 12px;"><strong style="outline: 0px;">杜清河，肖玉权，张朝阳，赫小萱 （西安交通大学）<br style="outline: 0px;"/></strong></span></p><p style="outline: 0px;"><span style="outline: 0px;font-size: 12px;"><strong style="outline: 0px;">王锦光，俸萍 （鹏城实验室）</strong></span></p></section></section></section></section></section></section><p class="js_darkmode__65" data-style='margin-bottom: 0px; letter-spacing: 0.578px; text-align: right; text-wrap: wrap; outline: 0px; background-color: rgb(255, 255, 255); color: rgb(53, 53, 53); font-family: "Helvetica Neue", "Hiragino Sans GB", "Microsoft YaHei", 黑体, Arial, sans-serif; font-size: 16px;' style='margin-bottom: 0px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(53, 53, 53);text-align: right;font-family: "Helvetica Neue", "Hiragino Sans GB", "Microsoft YaHei", 黑体, Arial, sans-serif;'><span style="outline: 0px;font-size: 12px;color: rgb(106, 106, 106);"><span style="outline: 0px;display: inline-block;text-indent: initial;">编</span><span style="outline: 0px;display: inline-block;text-indent: initial;">辑</span><span style="outline: 0px;display: inline-block;text-indent: initial;">：张朝阳</span><br style="outline: 0px;letter-spacing: 0.578px;"/></span></p><p class="js_darkmode__66" data-style='margin-bottom: 0px; letter-spacing: 0.578px; text-align: right; text-wrap: wrap; outline: 0px; background-color: rgb(255, 255, 255); color: rgb(53, 53, 53); font-family: "Helvetica Neue", "Hiragino Sans GB", "Microsoft YaHei", 黑体, Arial, sans-serif; font-size: 16px;' style='margin-bottom: 0px;font-size: 16px;letter-spacing: 0.578px;text-wrap: wrap;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(53, 53, 53);text-align: right;font-family: "Helvetica Neue", "Hiragino Sans GB", "Microsoft YaHei", 黑体, Arial, sans-serif;'><span style="outline: 0px;font-size: 12px;color: rgb(106, 106, 106);"><span style="outline: 0px;display: inline-block;text-indent: initial;">校</span><span style="outline: 0px;display: inline-block;text-indent: initial;">对</span><span style="outline: 0px;display: inline-block;text-indent: initial;">：肖玉权</span></span></p><p style="margin-bottom: 0px;"><br/></p><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div>

</div>
                <p></p>
                <p></p>
                <div>本文由“公众号文章抓取器”生成，请忽略上文所有联系方式或指引式信息。有问题可以联系：五人工作室，官网：www.Wuren.Work，QQ微信同号1976.424.585 </div>
                <div  class="hidden">本文由“公众号文章抓取器”生成，请忽略上文所有联系方式或指引式信息。有问题可以联系：五人工作室，官网：www.Wuren.Work，QQ微信同号1976.424.585 <br><p class="hidden">code/s?__biz=MzkxMTYzOTYzNw==&mid=2247483938&idx=1&sn=defe2e3a237db736ba4eeb20739549e1&chksm=c1185718f66fde0e47fb3614bf8b56cca897239502c7b8844d1b0d1599c5b2de5c074778ce80#rd </p></div>
            </body>
            </html>
            