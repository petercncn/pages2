


            
语义文本相似度（STS）的模型和数据
          




最近几周在如何优化现有模型在STS数据集上的结果方面遇到了瓶颈。因此针对现有的数据集和一些模型进行了分析。首先贴上STS数据集在构建过程中的衡量标准：两句话的相似程度标注标准5分两句话完全等价4分基本等价，部分细节可以不同3分大致等价，有重要细节不同2分不等价，有共同之处1分不等价，主题一致0分主题不一致simCSE和PromptBERT的结果分析针对sts数据中1-4分的句子，对比学习无法准确判断其相似程度。如下面两句话：a man is carrying a canoe with a dog .a dog is carrying a man in a canoe .simCSE和PromptBERT都给了相当高的相似度，但是答案中的相似度仅为1.8。猜测原因可能是，对于基于对比学习的方法，由于使用基于语言模型的dropout作正例，因此无法判断句子不同成分的重要程度（对于上面的句子，主语是man还是dog对语义的影响很大）。实验进展前两周为了看看在对比学习框架下，不同的句子提取方式（不同于CLS和词向量平均），以及不同的损失函数对句子表示的影响，做了一些实验，比如用交叉注意力提取句子向量，以及使用二范数代替余弦相似度等实验，但效果都一般。分析了STS数据集的评价指标后，考虑在句子向量的提取过程中，利用句法的信息，给不同的词向量不同的权重，以满足不同相似程度的识别工作。当前完成了利用依存句法分析对词向量的加权工作，效果也并不显著，感觉和权重的确定方式有关。后续可能会使用词性的信息再做一次验证。最后就是，基于词向量的方式很难将权重融入损失函数里，最后反映到训练过程中，都是稍微改变对应词向量的更新速度，因此打算详细分析一下，并直接对更新速度做优化。




