沉浸式玩家体验秘诀，看《梦三国2》游戏AI智能体！
点击卡片 立即关注
▼▼

近几年，全世界都见证了大模型和 AIGC 技术的爆发式增长，游戏行业也在全面拥抱 AI 。从游戏研发到游戏发行、运营的各个环节，AI 技术在游戏行业的落地应用逐步走向大众的视野，亦为游戏体验带来革命性颠覆。
《梦三国2》大家应该都不会陌生，它是杭州电魂网络科技股份有限公司自主研发并推出的一款融合了实时战略（RTS）元素的角色扮演游戏（RPG），该游戏自 2015 年 3 月 26 日起正式投入运营。早在 2021 年，《梦三国2》凭借其卓越的游戏品质和广泛的玩家基础，入选为第 19 届亚洲运动会的电子竞技比赛项目，标志着其在电子竞技领域的重要地位和影响力。接下来，我们谈谈为什么要在《梦三国2》加入 AI 智能体？在游戏领域中，AI 智能体扮演着至关重要的角色，它们不仅仅是技术的展现，更是提升游戏玩家体验的关键因素。对于新手玩家而言，相对于传统的行为树机器人，AI 智能体以其卓越的技巧和协作能力，能够更有效地帮助玩家快速提升游戏水平。无论是作为并肩作战的强力伙伴还是充满挑战的对手，它都能为玩家带来前所未有的游戏体验，极大地增加了游戏的多元性和挑战性。在保证游戏公平竞技方面，AI 智能体同样发挥着不可或缺的作用。它们能够填补玩家数量的不足，确保每场比赛的公平性，同时根据玩家的实力水平匹配相应难度的 AI，增强了游戏的竞争性和公正性。此外，AI 智能体还能优化冷门时段的匹配体验，通过智能填充，缩短玩家在玩家数量较少时段的匹配时间，为玩家提供更加流畅和愉快的游戏体验。在日常生活中，玩儿游戏时，相信在座的游戏人都希望自己可以把把赢，如果遇到“逆风局”，五连败会造成很差的游戏体验，对于经历连败的玩家，AI 智能体的引入同样具有积极意义。它们不仅能够提升连败玩家的游戏体验，还能有效提升用户留存率，确保每位玩家都能在游戏中找到属于自己的乐趣和成就感。可见，AI 智能体的价值在于它们不仅提升了游戏的技术层面，更在玩家体验和游戏社区的建设上发挥了重要作用。而模仿学习技术对 AI 智能体有着关键作用，通过模仿学习技术，AI 智能体可以学习从人类行为中获取知识和技能，并将其应用到不同的情境中。模仿学习技术通过精准捕捉并解析真人玩家的游戏操作，赋予 AI 模型以高度的拟人化特性。这一过程主要依赖于对线上高水平玩家比赛录像的深入分析，从中提取关键的游戏状态和相应的动作决策。在这里，"状态"描绘了玩家所处的游戏环境和当前游戏状态的描述，而"动作"则记录了玩家在该状态下的具体操作。通过游戏的标准化接口，我们能够捕获这些数据，进而训练出能够模拟人类玩家行为的 AI，提升游戏的互动性和真实感。前段时间，美国 GDC 大会的机器学习峰会上，网易数智游戏行业部 CTO 陶建容的精彩分享《为“街球全明星”训练高拟人和高强度的篮球 AI 智能体》中，也为游戏开发者展示了 AI 智能体从设计、训练到实际部署的完整过程，并向全球游戏开发者展示了如何将游戏 AI 技术成功应用于实际场景。详情可以查看以下视频👇今天，小智带大家从游戏 AI 算法专家李浩的视角，跟大家以《梦三国2》AI 智能体模仿学习技术方案角度切入，从数据集构建流程、状态动作定义、游戏场景定义、意图定义、数据分析、模型训练、模型部署、效果评估这 8 大方面来向大家详细介绍《梦三国2》AI 智能体模仿学习技术方案，一起谈谈 AI 技术是怎么为游戏行业创新和变革赋能，换言之，来看看游戏公司们如何为陪玩 AI 注入“灵魂”。（👇全文长约 8000 字，阅读大约需要 15 分钟）01数据集构建流程这一部分，小智将向大家介绍，包含录像到训练数据的处理全流程。1.录像下载及信息存储游戏方将录像定期推送到 FTP 上，我们会定期从 FTP 中拉取录像，并存入对象存储中，并在数据库中记录录像信息。2.录像信息解析过滤在进行模仿学习时，为了保证模型的效果，需要筛选特定角色的、高段位的、表现较好的录像使用，所以通过游戏方提供的录像过滤工具，可以获取每场录像的筛选映射信息，我们可通过该映射信息进行录像筛选，具体筛选信息字段示例如下：matchidscore/rankhero_idKDAgame_result比赛唯一id能力分/段位角色id比赛表现比赛结果3.录像解析 proto 数据在过滤得到所需录像之后，我们通过录像解析工具，将一局比赛解析处理成多个 proto 数据，每个 proto 数据表示一帧游戏数据，proto 中包含了我们训练所需的所有数据。之后我们把 proto 数据同样存放到对象存储中，并在mysql 中记录下这场比赛对应的 proto 及录像信息。如下图为 proto 的示例，其中包含了游戏某一帧状态和录像动作两部分主要信息，状态又分为比赛通用信息和各个玩家的状态信息两部分，通过 proto 数据，我们就可以构建状态-动作数据样本。4. proto 数据处理为训练数据集有了 proto 数据之后，我们开发 python 脚本用于处理并将一场比赛的 proto 数据转换为一个 parquet 文件，然后通过 redis 我们实现了多机多进程分布式处理，可批量将大规模的 proto，短时间内处理完成。之所以使用 parquet 作为训练数据格式，因为 pqt 文件可压缩节省空间，在得到 pqt 文件之后将其直接上传到 hdfs，通过关联 Hive 表，可进行相关数据统计和分析，pqt 文件可只用于后续训练（训练框架是基于ray开发）。02状态动作定义状态包含：全局特征、玩家特征、Unit 特征、其他特征、全局 map 以及局部 map 共 6 类特征。其中前 4 类特征很好理解，都是通过 proto 获取到对应的数据，进行计算处理之后，构建成对应的向量特征。对于全局 map 对应的是小地图信息，局部 map 对应的是玩家游戏中局部视野的信息，全局/局部 map 特征由多个二维矩阵构成，在《梦三国2》中，各 map 共使用地形、全量建筑物、我方建筑物、全部英雄、我方英雄、全部小兵、我方小兵、野怪共八个二维矩阵。每个二维矩阵中数值表示该位置有没有相关信息，如全局 map 中我方英雄的二维矩阵表示小地图中我方英雄所在的位置映射信息。Global map 将小地图转换为544x544的矩阵，然后 sum-pool 成 32*32 的矩阵(如定义映射位置存在多个，为具体单位的累加和)，Local map 是在 544x544 的小地图上直接针对主英雄所在的位置截取出 36*36 的矩阵。我们采用分层的动作结构，其中第一层为主动作，包括移动、停止、普攻、tp、技能 1~4、道具 1~9 共 17 个主动作。移动距离和移动方向作为移动的具体参数，其中：移动方向离散为 16 维度，移动距离离散为[50, 250, 500, 750, 1000, 1250, 1500, 1750, 2000, 2500, 3000]11个距离，统计玩家的移动距离得到。技能/道具距离和方向作为技能和道具（非指向性）具体参数，其中：方向离散为 16 维度，距离离散为[50, 200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000] 11 个距离，统计玩家的放技能、道具距离得到。对于距离和方向定义使用如下扇形方式定义，其中以原点出发的射线代表方向，以原点为中心的半径不同的圆为距离，射线和圆的交点就作为具体移动、释放技能的位置：指向目标用于普攻、技能和道具（指向性）的目标参数，不足的 padding 处理，括号里面代表的数量：自身（1）、友方英雄（4）、敌方英雄（5）、我方建筑（18）、敌方建筑（18）、我方小兵（20）、敌方小兵（20）、野怪（40）、召唤物（5）、Boss（2）、信使（6）、孔明灯（10）等。tp 目标用于使用回城令：友方的外塔、高地塔和基地共 10 个目标，宏观和微观意图只是作为辅助任务，不作为 AI 动作的任何参数。03游戏场景定义游戏场景（scene）实现了对数据集进行具体场景的归类，通过标记主英雄的重要动作节点赋予操作的目的性。具体而言，按照动作优先级排序，可以将游戏场景分为以下五大类：1、推塔/守塔我方英雄和己方小兵处于敌方防御塔一定范围内即定义为推塔；我方英雄位于我方防御塔内且该范围内同时存在敌方小兵/英雄时为守塔；我方英雄位于我方基地 3200 范围内且该范围内同时存在敌方小兵/英雄时为守基地；我方英雄和己方小兵处于敌方基地 3200 范围内即定义为推基地。2、对抗只要敌我英雄距离过近，我们就认为发生对抗。对抗按照参与人数进一步划分为solo、gank /被 gank、小型团战和大型团战；如果我方至少参战两位英雄，且敌方只有一位英雄，这时定义 gank，被 gank 同理；如果双方均至少参与两位英雄且有一方不足四人，我们认为是发生了一场小型团战；如果交战双方均参与四人及以上，我们认为是发生了大型团战；如果是一对一，定义为 solo。3、清线发育如果我方英雄绕过防御塔提前清掉兵线，那么划分为断线,其他情况下清线则为正常发育。4、野区发育主英雄在攻击野怪被划分为打野发育。如果攻击目标为我方野怪，划分为打自家野；如果攻击目标为敌方野怪，划分为反野；如果攻击目标为中立 Boss，划分为打 Boss。5、寻路以上所有事件如果均未发生，那么统一标为寻路环节。为了进一步对数据集进行更细致的划分，根据下一个游戏场景的变动，将寻路拆分为以下游戏场景：去推塔/去守塔；去 solo /去 gank /去小型团战/去大型团战；去清线/去断线；去打野/去反野/去打 Boss；去泡泉水/泡泉水（泉水恢复/泉水购物）；去野外购物/去插眼/去排眼/去控符/死亡等。04意图定义前面我们定义了详细的场景，首先对于一局比赛，找到符合场景的帧，如上图中 T1 泡泉水、T3 清线等（图中的 T1、T2 不代表连续帧，仅用于示例），那么有个这些有场景定义的帧之后，就可以对一局进行场景划分，对于两个场景帧中的剩余帧，定义为"去"下一个场景，如 T2 帧没有找到符合的场景，由于 T3 为清线，那么 T2 定义为去清线。经过上述操作后，每帧都会赋予一个场景的定义。在每一帧都有场景定义之后我们再来构建 scene intent，分为 global scene、global intent、local scene 和 local intent，其中 scene 表示的意图（干什么）信息，intent 表示的是位置（在哪里干）信息。local scene, 假设当前帧为非寻路场景，即不包含“去xxx”，那么该帧local scene 为当前场景一致，比如当前帧为泡泉水，那么 local scene 也为泡泉水。如当前帧为寻路场景，那么该帧 local scene 为最近的下一个非寻路场景，如当前场景为 T2 去清线，那么 local scene 为清线。local intent，假设当前帧为非寻路场景，即不包含“去xxx”，那么该帧 local intent 为当前场景结束所对应的位置，把小地图映射为 544x544 的二维矩阵，然后把该位置映射到二维矩阵上，然后把 544x544 的矩阵 pool 成 16x16 的矩阵，位置在 16x16 矩阵中的 index 作为 local intent，比如当前帧为泡泉水，那么 local intent 也为T1泡泉水结束对应位置。如当前帧为寻路场景，那么该帧 local intent 为最近的下一个非寻路场景开始的位置，如当前场景为 T2 去清线，那么 local intent 为 T3 清线开始对应的位置。global scene，定义为当前帧往后找，直到下一个非寻路场景作为当前帧的global scene，如上图中 T1 的场景为泡泉水，往后找，可能经过多个泡泉水帧，直到找到 T3 帧为清线场景，那么 T1 帧的 global scene 为清线。global intent，假设当前帧为非寻路场景，即不包含“去xxx”，那么该帧 global intent 为下一个非寻路场景开始所对应的位置，同理映射到 16x16 的矩阵中，对应的 index 作为 global intent，比如当前帧为泡泉水，那么 global intent 也为 T3 清线开始位置。如当前帧为寻路场景，那么该帧global intent 为最近的下一个非寻路场景结束的位置，如当前场景为 T2 去清线，那么 global intent 为 T3 清线场景结束对应的位置。current scene，代表玩家的当前帧状态下所处的场景。以上的五个定义也会作为我们在训练模型时候的五个辅助任务，帮助我们的模型更好的学习和掌握真人玩家数据中的宏观策略。在完成 scene intent 的定义之后，我们构建了一个 render，一方面可以校验我们的一些基础数据是否合理，也可以观察我们构建的辅助任务 scene intent 是否合理。render 由四张子图构成，分别表示全局地图、主英雄视角（局部地图）、local intent 位置和 global intent 位置示意图。第一个为 544*544 的全局地图，显示游戏内基本信息。蓝色阴影是游戏内地形；红蓝双方建筑处对应颜色的矩形表示塔；大圆形（有黑线描边）表示英雄，主英雄填充色为绿色，其他英雄填充对应阵容的颜色（红/蓝）；小圆形（无黑线描边）表示小兵，填充对应阵容的颜色（红/蓝）；橙色三角形表示野怪。第二个是以主英雄为视角中心的小地图，维度是 36*36。在小地图里面不仅包含了全局地图在该区域显示的所有信息，还额外加入了其他与战斗有关的数据。在该区域内的英雄和小兵会按照百分比血量填充颜色表示当前帧的状态，主英雄在攻击时会有黑色箭头指向对应单位，其中紫色框表示第六部分中介绍的 current intent 位置。第三个、第四个图同样为 544*544 的全局地图，其中紫色方框表示第六部分介绍的 local intent 和 global intent 的位置。同时在对应图片上还会显示current scene、local scene 和 global scene。05数据分析我们做了详细的数据分析工作。如下为不同定位英雄，多局比赛的地图位置的热力图分析，能明显看出中路、下路和游走在热力图上的区别，同时为了解决 AI 插侦察眼的问题，我们也分析了真人玩家插眼的位置热力图，同时统计出一些常见的位置，用于 AI 插眼。根据我们设计的主动作类型，我们会发现，不同主动作类型的样本存在较为严重的不平衡现象，同时对于不同定位的英雄，主动作的分布也是不一样的。如游戏场景定义所述，针对一局比赛我们实现了 21 个"干什么"的场景，如守塔、控符等，及对应的 21 个"去干什么"的场景，针对这些场景我们也同时做了不同英雄的统计，发现同样存在不同定位的英雄，场景占比也不一样。06模型训练1.网络结构2.模型输出主动作、移动方向、移动距离、道具/技能方向、道具/技能距离、目标、TP 目标，这些参数会用于控制 AI 动作，具体可参考动作空间。同时还会预测我们在第六部分中构建的四个 scene intent 的标签，并且这四个输出会与 sharelayerFC 的输出拼接，用于上述七个动作头的输入，即在预测 AI 的动作的时候会加入场景意图信息。3.模型输入主英雄、我方英雄、敌方英雄、我方建筑、敌方建筑、我方小兵、敌方小兵、野怪、Boss、眼、信使、召唤物、符文、AOE、特效、全局信息、Global map、Local map 组成输入，具体定义及组成可参考状态信息，与网络结构中的多输入头对应。如模型输出中所述在预测七个动作头时，会加入 scene intent 的信息，在训练时 scene intent 是提前知道的，所以在预测该七个动作头时，使用的真实的 scene intent 输入信息。同时模型预测的 scene intent 信息也会计算 loss 进行学习（在部署时，预测七个动作头使用的就是模型 scene intent 输出头预测的信息了）。4.损失函数所有输出头都使用 CrossEntropyLoss 总的 loss 为各个输出头 loss 的加和5.训练技巧多任务学习，除了动作头之外，设计了多个辅助任务头，最终通过 weighted sum 整个各个损失，并将多任务的总损失用于网络优化，从而实现各子任务目标的同步优化；根据主动作屏蔽无关动作头的 loss 回传，如主动作为移动，那么除了移动坐标的输出头之外的其他二级动作头都屏蔽 loss 回传；样本训练前置加权，针对每个英雄主动作不平衡及场景的不平衡，对样本进行场景-主动作类型组合维度的加权，通过加权提升模型的相关效果。样本训练后置加权，针对已训练的模型，发现该模型在某些情况下表现较差，比如不会打 Boss等，可挑选该类场景下的样本加权，进行加训迭代；多英雄数据融合，为了提升模型的泛化性，减少部署使用时的成本，最开始是一个英雄的数据训练一个模型，后来我们把多个英雄的数据合并起来，训练一个模型。相比于只使用一个英雄的数据，合并数据的效果反而更好。6.难度分级1）难度分级实现输入干扰针对模型的一些关键输入做一些扰动，比如敌方英雄的血量、蓝量扰动，位置扰动，用来模仿真人玩家对于血量位置把握不准确的情况。输出干扰针对模型的一些关键输出参数做扰动，比如技能/道具释放的方向和位置，用来模仿真人玩家技能道具释放不准确的情况或失误等。规则干扰，如 AI 的反应时间、AI 使用技能的概率、AI 使用道具的概率、AI 普攻的频率、AI 出装的正确程度等，这些可通过规则实现。最终我们针对《梦三国2》设计了如下七个难度分级维度，通过这七个维度共生成六个难度，其中技能使用概率、道具使用概率、补刀攻击概率、反应时间、出装速度为规则干扰；技能使用准确率为输出干扰；技能躲避概率为输入干扰，主要干扰输入状态中技能特效及 AOE 的信息。针对各个维度配置了一套开放的参数，参数调整之后，会进行自动对战测试，保证各个难度的水平、胜率、数据符合要求。2）动态难度调整为了提升玩家的游戏体验并确保每场对局的挑战性和公平性，我们采用了动态难度调整机制。在《梦三国2》中，我们根据玩家的能力分和连败情况，在匹配开局时初始化敌我双方 AI 的难度级别。此外，我们还设计了局内剧本，能够根据对局的实时状态调整不同英雄 AI 的难度，以适应比赛的发展。近期了解到，网易数智正在开发中的实时胜率预测模型将进一步提升这一机制的精准度。该模型能够根据当前比赛的状况输出两边的实时胜率，并以此作为调整 AI 难度的依据。网易数智的目标是创造一个温暖的匹配环境，让真人玩家的胜率能够逐渐提升，同时对于陪玩或掉线的情况，我们希望保持真人玩家的胜率在 40% 至 60% 的范围内。根据实时胜率，将相应地提高或降低 AI 的难度，确保玩家在每场对局中都能体验到适当的挑战。通过这种局内动态难度调整，我们旨在让玩家在比赛中达到心流状态，从而极大地增强游戏的吸引力和留存率。小智相信，AI 智能体投放的精确控制将为玩家带来更加丰富和满足的游戏体验。3）风格多样训练多风格模型：设计一些与风格相关的统计特征，针对每局比赛统计特征，区分同一英雄(位置)的多个风格的数据；根据玩家的状态-操作数据，对玩家的行为序列做 embedding，针对行为序列做聚类，尝试通过聚类找出不同风格操作的玩家数据；有个不同风格的数据之后，每种区分度高的风格训练一个模型。规则多风格方案：模型中一些重要的输入的改变都会影响 AI 的决策风格，比如敌人的血量、自身的血量等，可针对风格设定（激进、谨慎等）使用相关的规则实现 AI 在已有模型上的决策风格改变。07模型部署整个数据流如上图所示，在游戏逻辑中嵌入 SDK，SDK 主要完成模型所需状态的收集，然后通过 proto（与数据离线采集的 proto 类似，不过这里仅对应当前需要推理的一帧的状态数据）进行序列化以 TCP 网络通信的形式，发送给 AI 智能体后端服务，AI 智能体后端返回动作，通过协议中约定的字段及 SDK 暴露的 callback 函数完成异步的 AI 动作执行。AI 智能体后端服务又是由代理服务和 AI 服务构成，代理服务用于接受来自游戏服务器的请求，并进行相关调用量统计、限流、鉴权等功能的实现，代理服务会紧接着将 proto 的序列化数据发送给 AI 服务。通过 flask+gunicorn 开发的 AI 服务将 onnx 模型实现了服务化，该服务包含了模型的特征构建、模型推理、legal action 逻辑等功能。整体的服务部署架构如图所示，我们采用游戏这边提供的机器，基于 docker 实现了私有化部署，整个线上部署实现了如下功能：异步流程，不影响游戏逻辑分布式部署，可增减机器AI 开局数量、历史调用量及 AI 参与对局的表现可感知部署集群资源占用情况可感知08效果评估在我们训练得到模型之后，我们会先进行离线自动测试，通过自动对战 GameCore 同时多开对局，让我们的 AI 与行为树对战，两边为镜像阵容，通过行为树来验证我们模型强度是否达标，如下图为 15 个英雄各自进行近 40 场对战后，该英雄的 KDA 及其他指标的情况。当我们发现对战行为树指标还不错之后，我们会将 AI 模型，部署到 AI 测试服，游戏策划、测试等同学都可以在测试服上体验最新版本的 AI，跟 AI 进行实时对抗。如下图是列出的对于 AI 不能出现或者只能接受偶现的一些行为，同时，在 AI 测试服中会对下列的每一条内容进行验收，除了下列行为外，在 AI测试服实时对抗中，还可根据游戏体验提出一系列反馈问题，我们也会根据反馈问题进行 AI 行为的迭代，从来不断来提高 AI 的拟人性。本次的分享先到这里，我们共同探讨了《梦三国2》中 AI 机器人的模仿学习技术，揭示了如何通过精细的算法和数据分析，赋予 AI 以接近真人玩家的操作水平和策略，这是一次对游戏智能化深度的探索，也是对未来游戏体验提升的一次大胆预测。而在下一期的内容中，小智将转向实战领域，带来《梦三国2》的客户案例篇，将为大家分享 AI 技术如何在真实世界中发挥作用，改善玩家的游戏体验，并推动游戏社区的共同成长，各位敬请期待！▼点击“阅读原文”，立即咨询“游戏AI智能体解决方案”。
▼好的内容值得分享，在看、点赞、一键转发~

