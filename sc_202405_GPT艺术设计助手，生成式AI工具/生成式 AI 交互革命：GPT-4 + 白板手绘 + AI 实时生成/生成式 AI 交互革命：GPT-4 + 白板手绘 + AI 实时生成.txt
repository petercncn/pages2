


            
生成式 AI 交互革命：GPT-4 + 白板手绘 + AI 实时生成
          




Image by lencx via ChatGPTOpenAI DevDay （OpenAI 开发者大会速览：GPTs 和模型 API）上推出的 GPT-4V（vision）[1] 是一款能够处理图像输入的模型 API。该模型不仅能完成基本的图像识别任务（如：识别热狗，总结图片内容等），还能处理更复杂的请求（如：发送一张棋盘照片，询问下一步棋的最佳走法；问为什么《纽约客》杂志的漫画很有趣等）。DevDay 结束后不久，Figma 工程师 Sawyer Hood 在 X 平台发了一个视频，展示他如何利用 tldraw[2] 生成可交互的网页代码（项目源码：draw-a-ui[3]）。成为继 Vercel 代码生成器 v0[4] 后的又一编程领域热门话题。最近，另一个名为 excalidraw[5] 的开源手绘白板也加入了一系列 AI 功能（图表和代码生成），似乎是在对标 tldraw，竞争越来越激烈了！白板手绘tldraw关于 tldraw + AI 目前有两个方向，make-real 从手绘稿生成网站代码，draw-fast 则是手绘稿通过 AI 实时生成图像。make-realmake-real[6]：是 tldraw 官方 fork draw-a-ui 后正在二次开发的项目。其原理是使用 tldraw[7] 画布绘制 SVG 图案，转成 PNG 图片后发送到 GPT-4V，然后会返回一个由 TailwindCSS 构成的 HTML 代码，通过 iframe 实时渲染在画板中（了解更多：make real, the story so far[8]）。以下是多个示例合集，有各种小游戏生成，表单创建，响应式布局等。注：GPT 讨厌你在它们的自画像上画胡子！draw-fastdraw-fast[9]：基于 fal.ai[10] 构建的一个 AI 实时推理应用，它可以将手绘图实时生成图像（图像生成时间低于 120 毫秒/帧），负责实时渲染的 fal 服务使用到的技术是潜在一致性模型（LCMs）（了解更多：Building Applications with Real-Time Stable Diffusion APIs[11]）。在线体验：drawfast.tldraw.com[12]以下视频演示是多个示例合集：📌 LCMs & LDMs潜在一致性模型（LCMs）与潜在扩散模型（LDMs）的主要区别在于效率和推理步骤。LDMs 通过在像素空间中操作并顺序应用去噪自编码器来合成高分辨率图像，这一过程虽然能达到高保真度，但通常需要大量的计算资源和时间。相比之下，LCMs 是对 LDMs 的一个改进，它通过直接在潜在空间中预测增强概率流常微分方程的解（PF-ODE），从而显著减少了迭代次数，使得在任何预训练的 LDM 上实现快速、少步骤的推理成为可能。这种方法不仅大大提高了生成速度，还保持了高图像质量，特别适用于需要快速合成高分辨率图像的场景。去噪自编码器（Denoising Autoencoders）：去噪自编码器是一种神经网络，设计用来从损坏的输入数据（例如加入噪声的图像）中恢复或重构出清晰、未损坏的数据。这些模型通常由两部分组成：编码器（将数据转换为更紧凑的表示）和解码器（从紧凑表示重构数据）。在图像处理的背景下，去噪自编码器可以用来改进图像的质量，通过去除噪声或恢复损坏的部分。PF-ODE（Probability Flow Ordinary Differential Equation）：这是概率流常微分方程的缩写。在机器学习中，特别是在扩散模型的背景下，PF-ODE 通常用于描述一个随时间连续变化的概率分布。扩散模型通过这种方式模拟了数据（如图像）的生成过程，从一种高熵（无序）状态（例如随机噪声）逐步转化为低熵（有序）状态（例如清晰图像）。PF-ODE 是这个连续过程的数学表达。参考论文：Latent Consistency Models: Synthesizing High-Resolution Images with Few-Step Inference[13]High-Resolution Image Synthesis with Latent Diffusion Models[14]Excalidraw在 Excalidraw 中有两种模式：文字转图表（Text to diagram）：免费限额使用，每天可以发起 10 次请求。线框到代码（Wireframe to Code）：需要使用自己的 OpenAI Key。视频演示：SDXL Turbo上面提到了 LCMs，就不得不提昨天刚发布的 SDXL Turbo[15]，它是一种新的实时文本到图像生成模型，采用对抗性扩散蒸馏（ADD）技术，能够在一步内生成高质量图像，显著减少了处理步骤（将所需步骤从 50 步减少到仅 1 步）。这种模型结合了对抗性训练和分数蒸馏，优化了图像生成过程，降低了人工痕迹和模糊度。SDXL Turbo 在多个模型比较测试中表现优异，超越了多步骤的模型，并大幅提高了推理速度。目前，该模型以非商业研究许可证在 Hugging Face（stabilityai/sdxl-turbo[16]）上提供，并可以在 Stability AI 的 Clipdrop[17] 平台上进行实时图像生成的测试。尽管有显著的技术进步，但 SDXL Turbo 目前仍不适用于商业用途。相关论文：Adversarial Diffusion Distillation[18]。为了测试 SDXL Turbo，这里比较了多个不同的模型变体（StyleGAN-T++、OpenMUSE、IF-XL、SDXL 和 LCM-XL），使用相同的提示生成输出。然后，人类评估员随机展示两个输出，并被要求挑选出最符合提示方向的输出。接下来，使用相同的方法完成了图像质量的额外测试。在这些盲测中，SDXL Turbo 能够以一步击败 LCM-XL 的 4 步配置，以及以 4 步击败 SDXL 的 50 步配置。通过这些结果，我们可以看到 SDXL Turbo 在显著降低计算需求的同时，仍然保持图像质量，超越了最先进的多步模型。此外，SDXL Turbo 在推理速度方面也有显著提升。在 A100 上，SDXL Turbo 生成 512x512 图像仅需 207 毫秒（提示编码 + 单次去噪步骤 + 解码，fp16），其中 67 毫秒由单次 UNet 前向评估占据。交互革命GPT-4 + 白板手绘 + 实时 AI 生成在我看来将是一次新的交互革命（不亚于 ChatGPT 的出现）。通过 GPT-4 的推理能力，结合手绘白板的直观创作方式，用户可以以前所未有的自然和直接的方式与 AI 互动。这意味着从简单的文本命令到复杂的创意表达，都可以被快速、准确地转化成视觉图像，或工程代码。实时 AI 生成进一步增强了这种互动的即时性和动态性。用户所绘制的每一个笔触都可以实时转换成精确的图像输出，使得创作过程变得更加流畅和富有创造力。这种即时反馈机制不仅加速了创作过程，也极大地提高了用户的参与感和创造体验。设想一下，在教育、设计、艺术和娱乐等多个领域，这种新的交互方式都将打开无限的可能性。例如，在教育中，教师可以利用这项技术将抽象概念直观地展示给学生；在设计领域，设计师能够快速将想法转化为视觉原型；而艺术家则可以通过这种方式探索新的创作方法。References[1]GPT-4V（vision）: https://platform.openai.com/docs/guides/vision[2]tldraw: https://github.com/tldraw/tldraw[3]draw-a-ui: https://github.com/SawyerHood/draw-a-ui[4]v0: https://v0.dev[5]excalidraw: https://github.com/excalidraw/excalidraw[6]make-real: https://github.com/tldraw/make-real[7]tldraw: https://github.com/tldraw/tldraw[8]make real, the story so far: https://tldraw.substack.com/p/make-real-the-story-so-far[9]draw-fast: https://github.com/tldraw/draw-fast[10]fal.ai: https://www.fal.ai[11]Building Applications with Real-Time Stable Diffusion APIs: https://blog.fal.ai/building-applications-with-real-time-stable-diffusion-apis[12]drawfast.tldraw.com: https://drawfast.tldraw.com[13]Latent Consistency Models: Synthesizing High-Resolution Images with Few-Step Inference: https://arxiv.org/abs/2310.04378[14]High-Resolution Image Synthesis with Latent Diffusion Models: https://arxiv.org/abs/2112.10752[15]SDXL Turbo: https://stability.ai/news/stability-ai-sdxl-turbo[16]stabilityai/sdxl-turbo: https://huggingface.co/stabilityai/sdxl-turbo[17]Clipdrop: https://clipdrop.co/stable-diffusion-turbo[18]Adversarial Diffusion Distillation: https://stability.ai/research/adversarial-diffusion-distillation




