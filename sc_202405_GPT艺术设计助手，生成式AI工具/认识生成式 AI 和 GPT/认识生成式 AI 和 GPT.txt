


            
认识生成式 AI 和 GPT
          




序2022 年 11 月 30 日，OpenAI 发布了 ChatGPT，你输入的几乎任何问题，它都能回答，如此强大的能力使其成为有史以来增长最快的应用，2 个月时间累积了 1 个亿的月活用户。盖茨把 GPT 称之为“自图形用户界面（GUI）之后，最重要的技术进步”，英伟达的黄仁勋称 ChatGPT 为 “iPhone时刻”。图：不同产品达到1亿用户花费时间[19]其实，去年底 ChatGPT 发布后，我就有第一时间试用，后来也一直在体验各种新产品，包括 Midjourney、Notion AI、Pi 等等。同时，也有持续关注大模型、AI相关的新闻。但我发现一个问题，如果你只是每天不停地输入，不做整理和输出，你会发现每天吸收到的信息是非常零散的、是漂浮的，这些信息很容易就被忘记，更难形成知识体系。所以希望能通过记录，有意识地整理信息，将它们结构化地沉淀下来。第一章：认识生成式 AI 和 GPT在 ChatGPT 掀起的这波人工智能热潮中，不管是文生文、还是文生图，或是其他更强的生成能力，其背后采用的算法都可以统称为「生成式 AI（Generative AI, Gen AI）」。虽然每天媒体都在疯狂报道国内外 AI 行业的最新进展、各种黑科技、融资八卦等等，但没找到有文章把“生成式 AI 是什么”、“生成式 AI 和机器学习、深度学习是什么关系” 、“GPT 是什么” 等这些问题讲清楚。这些内容又很基础，是准确理解复杂事物的基本知识。因此第一篇文章，希望先理清概念和关系。主要内容1. 什么是人工智能、机器学习、深度学习和生成式 AI2. 上述这些概念之间，相互是什么关系3. 什么是 GPT 和大语言模型正文（也可跳到文末，直接看结论）什么是人工智能（Artificial Intelligence, AI）一些权威解释？维基百科的解释：“人工智能（AI）是机器或软件的智能，而不是人类或动物的智能。”Google 定义为：“人工智能是一个构建能够推理、学习和行动的计算机和机器的科学领域，这种推理、学习和行动通常需要人类智力，或者超出人类分析能力的数据规模。”说白了，人工智能就是让机器拥有人类同等的或超越人类的学习、推理等能力。这是一个很伟大的目标，因为它对生产力的解放有着很大的空间。就像马化腾说的 “我们最开始以为（人工智能）是互联网十年不遇的机会，但是越想越觉得，这是几百年不遇的、类似发明电的工业革命一样的机遇。” 人工智能的起源要追溯到 1956 年夏天举办的达特茅斯会议。这场会议是由达特茅斯大学数学教授约翰·麦卡锡（John McCarthy）、贝尔电话实验室数学家克劳德·香农（Claude Shannon）等4人发起的，当时的发起书标题是“达特茅斯夏季人工智能研究项目提案”，这次会议明确了讨论主题就是“人工智能”，并围绕以下 7 个议题进行：自动计算机如何对计算机进行编程以使用语言神经网络计算规模理论自我改进抽象随机性与创造性虽然最终参会人没有达成共识，但这次会议标志着人工智能元年的开启。图：达特茅斯会议的参会人合影什么是机器学习（Machine Learning, ML）机器学习是人工智能领域里的一个子集，是指让系统通过输入大量数据，进行自主学习和改进，而不需要明确编程。机器学习不是某种特定的算法，而是一类算法的总称，包括如决策树，贝叶斯、深度学习等。机器学习的模型，按训练方法大致可分为3大类：监督学习（Supervised learning）、无监督学习（Unsupervised learning）、强化学习（Reinforcement Learning）监督学习，算法使用有标签数据学习，实现对新的、未标签的数据进行预测或分类。无监督学习，算法使用无标签的数据训练，学习潜在的结构或模式，对数据进行聚类。强化学习，算法关注智能体与环境的交互中学习，以获得最大的累积奖励为目标，不断优化行动。此外，也衍生出一种同时结合监督学习和无监督学习的方法，叫做半监督学习（Semi-supervised learning），会使用大量的未标记数据和少量的标记数据来训练模型。什么是深度学习（Deep Learning, DL）深度学习是机器学习的一个子集，是利用深度神经网络进行学习，能比传统的机器学习模型，学到更复杂的模式和结构。来源: https://www.cloudskillsboost.google/course_templates/536深度神经网络通常有非常多层和参数，以 2012 年获得 ImageNet 比赛冠军的 AlexNet 模型为例，它采用了深度卷积神经网络结构，它的输入是 227x227x3 的图像，输出是 1000 维的概率向量，每个维度表示属于每个图像类别的概率（ImageNet 数据集包含了1000 个类别的大约 1400 万张图像）。AlexNet 的网络结构包含了 5 个卷积层，3 个全连接层， 参数量为 6000 万。图：AlexNet 模型的参数量计算[6]深度学习或者机器学习模型，一般分为两类：判别式（Discriminative）和生成式（Generative）判别式模型：用来分类或预测，学习训练数据的特征和标签之间的关系（直接学习条件概率分布P(X|Y)）生成式模型：用来产生新数据，学习已有数据的概率分布（先学习联合概率分布P(X,Y)，再计算条件概率分布P(X|Y)）来源: https://www.cloudskillsboost.google/course_templates/536什么是生成式AI（Generative AI, GenAI）生成式 AI 是深度学习的一个子集，它可以根据用户的输入，生成新内容。输入和输出可以是文本、图像、声音、动画等各类型数据。来源: https://www.cloudskillsboost.google/course_templates/536生成式 AI，是通过使用有标签和无标签数据先训练一个基础模型（Foundation Model），有了基础模型后，通过输入提示词（Prompt），预测可能的回答，生成新的内容。常见的基础模型，如 GPT、PALM、DALL·E 等。来源: https://www.cloudskillsboost.google/course_templates/536什么是 GPT（Generative Pre-trained Transformer, GPT）GPT 就是生成式 AI 中最具代表的一个模型了。GPT 翻译过来叫做 “生成式预训练 Transformer 模型”，这里边有 3 个关键词「生成式、预训练、 Transformer」。我们从这 3 个词入手，尝试简单理解下它：生成式，表明是生成式模型，可生成新内容。预训练，是指预训练模型（Pre-trained Model），一般基于大规模数据训练得到的通用模型。如果有明确任务，可以再通过微调（Fine-tuning）的方法，使用标注数据，对预训练模型二次调整。Transformer，是Google在2017年提出的模型，由编码器（Encoder）和解码器（Decoder）两部分构成。首先，将输入内容转为计算机理解的向量语言（Embedding）。之后，将向量输入编码器进行编码，得到输出向量。再传入解码器内解码，将解码后的向量再做映射，就产生了输出内容。图：Transformer 模型的基本结构因此一句话理解，GPT 就是以 Transformer 算法为基础，通过预训练得到的一个生成式模型。什么是大语言模型（Large Language Model，LLM）大语言模型是语言模型的一种，其特点是参数量巨大，通常参数量在10亿以上被认为是大语言模型。其与小模型的主要区别在于增加模型大小、训练数据和计算资源。对比小模型，大语言模型会出现“涌现能力”(Emergent Ability)，包括上下文学习、指令遵循、逐步推理等。大语言模型是一类基础模型，通过大规模的文本数据进行训练。比如GPT（OpenAI 的大语言模型）、LLaMA（Meta 的大语言模型）、PALM（Google 的大语言模型）。图：大语言模型的演化历史[18]结论人工智能（AI）是让机器拥有人类同等的或超越人类的学习、推理等能力。机器学习是 AI 的子集。通过数据训练，让机器自主学习和改进。深度学习是机器学习的子集。使用了深度神经网络，能够学习更复杂的模式。生成式 AI 是深度学习的子集。使用大量数据训练一个基础模型，后续每次输入提示词（Prompt），生成新的内容。GPT 是一个生成式模型。可以根据输入，生成新的内容。GPT 也是一个大语言模型。具备上下文学习、指令遵循、逐步推理等能力。参考链接[1] 人工智能时代已经开始 | 盖茨笔记 https://mp.weixin.qq.com/s/pYjY_LT8I33YqCn415AUAA[2] Wikipedia: Artificial intelligence https://en.wikipedia.org/wiki/Artificial_intelligence[3] 什么是人工智能 (AI)？ https://cloud.google.com/learn/what-is-artificial-intelligence?hl=zh-cn[4] 人工智能简史 01：达特茅斯会议—人工智能的缘起 https://www.163.com/dy/article/FC4L6BK10522NNHF.html[5] 什么是机器学习？https://cloud.google.com/learn/what-is-machine-learning?hl=zh-cn[6] 神经网络参数量、计量、参数换算MB https://zhuanlan.zhihu.com/p/387349200[7] 深度学习-经典网络——归纳总结 https://zhuanlan.zhihu.com/p/468283682[8]Introductionto Generative AI https://www.cloudskillsboost.google/course_templates/536  [9] 生成式人工智能：它是什么以及它如何工作？https://www.nvidia.com/en-us/glossary/data-science/generative-ai/  [10] Generative AI Models Explained https://www.altexsoft.com/blog/generative-ai/ [11] 从CHAT-GPT到生成式AI（Generative AI）：人工智能新范式，重新定义生产力https://cloud.tencent.com/developer/article/2222549[12] 请问深度学习中预训练模型是指什么？如何得到？https://www.zhihu.com/question/327642286[13] 十分钟理解Transformer https://zhuanlan.zhihu.com/p/82312421[14] Attention Is All You Need https://arxiv.org/pdf/1706.03762.pdf[15] 零基础理解为什么是Transformer？什么是Transformer?  https://juejin.cn/post/7082683591653589029[16] 通向AGI之路：大型语言模型（LLM）技术精要 https://zhuanlan.zhihu.com/p/597586623[17] Wikipedia: 大型语言模型 https://zh.wikipedia.org/zh-hans/大型语言模型[18] 大语言模型综述 https://arxiv.org/abs/2303.18223[19] ChatGPT crosses 100 million active users, sets record for fastest-growing user base, says study https://www.cnbctv18.com/technology/chatgpt-sets-record-for-fastest-growing-user-base-says-study-15840751.htm




