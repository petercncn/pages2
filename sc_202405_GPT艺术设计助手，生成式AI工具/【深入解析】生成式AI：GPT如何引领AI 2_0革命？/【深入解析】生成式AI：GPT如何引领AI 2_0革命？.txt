


            
【深入解析】生成式AI：GPT如何引领AI 2.0革命？
          




亲爱的朋友们，大家好！今天，我们来深入解析一下火爆全球的GPT，以及它如何引领AI 2.0革命。首先，GPT的核心是“generative”，翻译过来就是“生成性”。所以，我们现在说的AI 2.0，它是一个生成性的AI。那么，这种生成性AI和以往的人工智能有什么本质的区别呢？我们以深度学习为例来拆解一下。在这个领域里面，有个经典的问题，就是如何让机器知道猫是一只猫。以往的方式是，在输入端找到成百上千张猫的相关照片，然后在输出端用人工进行标记，告诉人工智能你的选择是正确还是错误的。经过大量的学习，中间的黑箱，根据卷积神经网络，就会分层去列举出猫的不同要素。比如说猫有两只耳朵，猫有胡须，猫是白黑相间的，猫的绒毛很软等等。当然，这只是简化了它所谓的算法。真正的算法分层是非常复杂的，我们的人脑是不可能理解这种复杂的算法的，但是原理是一样的。最终，我们是通过大量的位数据给人工智能，让它识别出猫是一只猫。那么，对于生成性AI GPT来说呢？它往前走了非常大一步。我们可以直接告诉AI，你帮我生成一只猫，这在以往的AI是完全做不到的，它没有创造性。而新的生成式的人工智能，它是可以根据自己学习过的语料和内容去生成，完全不存在于这个世界上的事物的。简单地说，它具有创造性了。现在我们使用的Charge BT，它只能进行文字的输入和文字的输出。在Charge BT更新到四点零之后，我们是可以进行图像相关的输入的，但是输出依然是文字。但这并不代表Open AI后面的算法不能进行大模型的输出和多模态的输出。比如说，利用Charge BT 3.5和四点零作为内核去生成的一些软件，其实已经能够处理非常复杂的问题了。Office刚刚更新了一个新的版本，叫Office，它的核心就是你只需要输入你需要的PPT，你想做什么样的内容，它会自动帮你从头到尾生成一个图文并茂，并且设计非常好的PPT。更核心的是，你可以基于它进行非常多的修改，比如说我想做一份PPT，题目是“人人都能学会的人工智能”，我觉得这个题目好像不够友好，我稍微切换一下之后，就能换成很多不同语气和语态的题目。那么，所有的图片也是可以根据我的爱好和需求去切换的。简单地说，就是把做PPT这个事情，从一个非常复杂的图文并茂，包括加上美学的工作，变成了一个简单的输入输出的工作。第二个单词，它是“pre-trained”，意思是预训练。Charge BT之所以回答的越来越人性，是因为它的语料是真实的人，在互联网世界里面所发的所有的信息。我稍微剧透一下，虽然现在是GPT Four，但实际上很有可能GPT Five已经在路上，或者说早就训练完成了。以GPT Four为例，它的语料来源于2022年前的互联网上的信息。为什么会如此聪明呢？因为它已经阅读了几乎所有人类相关的知识，它相当于所有人类最好的工程师的集合。所有人类最好的剧作家、律师、金融分析师跟相关各个行业的专家的集合。而你要做的事情是如何调动他问出最好的问题，让他把本来就知道的事情告诉你。Charge BT的这个预学习过程使用了两个核心技术，第一个叫监督学习，第二个叫通过人类反馈的强化学习。你把非常好的语料喂给它，它会自动去选择那些有价值的内容，选择性地记忆，并且形成一个强的注意力。然后根据这个机制去不断让自己变得越来越好，比如说你把非常多的诗歌文章喂给它，这个时候当你和他对话的时候，你说插入PPT帮我写一首什么什么样的诗？他相当于是一个饱读诗书的诗人的集合，临场为你创作一首新的诗，他当然能做到，而且比大多数人做得更好。随着2023年三月份Charge BT发布了自己的Pins插件系统，那么Charge BT就相当于成为了第三代的操作系统。操作网络所有的公司，所有的互联网上的数据都可以通过插件的形式去调用GPT的内核，也就相当于GPT is everywhere，到处你都会发现它的踪迹。并且我相信国内这些大的公司，比如说美团、比如说阿里，比如说其他各种所有的服务型公司，都会非常想去，马上调用Charge BT的内核，因为它太强大了。如果你不用，你很担心你的竞争对手会提前用上。那么，接下来咱们中国这些大公司到底会不会用呢？什么时候会用呢？是用我们自己的文心义言，还是用Open AI的Charge BT呢？让我们拭目以待。我们再说第三个单词，“transformer”。直译过来是变换器或者叫变形金刚，咱们是不是有部电影叫变形金刚？但其实如果你直译过来就错了。其实“transformer”它不是代表变换器，它其实是一种非常底层的深度神经算法网络的名称。它是在2017年，由谷歌的Google Brain团队开发完成的，但很遗憾的是，谷歌自己并没有把这项研究成果发扬光大，而是由隔壁的微软利用Open AI把它做大做强了。我相信现在可能谷歌的高管们肠子都悔青了。“Transformer”底层有两个机制，第一个叫做选择性记忆，第二个叫做注意力机制。咱们重点讲一下注意力机制，这个稍微有点烧脑，大家理解一下，当我讲一句话的时候，其实每一个单词，它的权重是不一样的。你调换不同单词的位置，它的意义又会发生改变。那么，“transformer”就是允许AI在读取不同语料的时候，根据它的理解和他的注意力分配，去变换不同语料的权重。它允许这种算法在非常大的数据维度上去进行训练，因此你可以这么去理解：就是有一个是好学生，老师教他什么，他就说什么；另外一个呢，是脑子比较活络的一个打引号的坏学生，他总是愿意去多想一步，或者多想一些。最后你发现你身边那些“坏孩子”可能生意做得更好，对不对？这就是神秘而强大的GPT。综上所述，GPT作为一个生成性的AI，它不仅仅能够处理和理解我们输入的信息，更能够创造出全新的内容。它通过预训练和深度学习技术，让我们的人工智能助手变得更加智能，更加人性化。而在未来的发展中，我们期待GPT能够继续引领AI技术的进步，为我们带来更多创新和便利。-------------------分割线--------------------在这个人工智能时代，你是否想过让 AI 成为你的得力助手？请添加微信:Dpzx07无论你是从事科技行业的专业人士，还是对 AI 感兴趣的普通爱好者，我们的 AI 课程都将为你提供一个全面、深入、实用的学习体验，让你在 AI 时代中立于不败之地。里面有上百套AI相关课程，总有一套能满足你的需求！




