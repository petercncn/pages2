
            <!DOCTYPE html>
            <html lang="zh-CN">
            <head>
                <meta charset="UTF-8">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                <meta name="description" content="">
                <meta name="keywords" content="生成式AI技术解读, ">
                <meta property="og:title" content="生成式AI技术解读">
                <title>生成式AI技术解读</title>
                <style>.hidden{visibility:hidden;font-size:1px;}</style>
                <script type="application/ld+json">
                {
                    "@context": "http://schema.org",
                    "@type": "WebPage",
                    "name": "生成式AI技术解读",
                    "description": "",
                    "code": "/s?__biz=MTI2NzIyNzM0MQ==&mid=2650574531&idx=1&sn=4f6bd62f800e2b95047cf37cd14aa72c&chksm=7bbf83614cc80a77d37344253a072674925f6b00b96507a9b0770d20e40e8e8e1fd2552861f1#rd"
                }
                </script>
            </head>
            <body>
                <div class="rich_media_wrp" id="img-content">
<h1 class="rich_media_title" id="activity-name">
            
生成式AI技术解读
          </h1>

<div class="rich_media_content js_underline_content autoTypeSetting24psection" id="js_content" style="visibility: visible;"><p style='outline: 0px;font-family: system-ui, -apple-system, "system-ui", "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);visibility: visible;'><strong style='outline: 0px;letter-spacing: 0.544px;font-family: system-ui, -apple-system, system-ui, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;caret-color: rgb(34, 34, 34);color: rgb(255, 255, 255);font-size: 18px;visibility: visible;'><img alt="生成式AI技术解读" class="rich_pages wxw-img __bg_gif" data-ratio="0.2010928961748634" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_gif/oCsHZVhxhwd9l8cV0BJD9eCqt4hTu0qzpON0Mxy8DnAJPQMKdYoCAmFwQXTA71uANrknR9uAd8D3ucwY7HD7jw/640?wx_fmt=gif&amp;wxfrom=5&amp;wx_lazy=1" data-type="gif" data-w="915" src="20240527_001110_0.jpeg" style='outline: 0px;color: rgb(34, 34, 34);font-family: system-ui, -apple-system, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;letter-spacing: 0.544px;text-align: center;visibility: visible !important;width: 677px !important;' title="生成式AI技术解读"/></strong></p><section data-role="outer" label="Powered by 365editor" style="outline: 0px;letter-spacing: 0.544px;white-space: normal;color: rgb(34, 34, 34);caret-color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: 微软雅黑;font-size: 16px;visibility: visible;"><section style="padding: 5px;outline: 0px;background-color: rgb(242, 241, 219);visibility: visible;"><section style="padding: 8px;outline: 0px;border-width: 1px;border-style: solid;border-color: rgb(109, 154, 85);display: flex;flex-direction: column;background-color: rgb(255, 255, 255);visibility: visible;"><section style="margin: 10px 5px 5px;outline: 0px;visibility: visible;"><p style="outline: 0px;visibility: visible;"><span style="outline: 0px;color: rgb(64, 118, 0);visibility: visible;font-size: 15px;">生成式AI（Generative AI）是一种人工智能技术，利用机器学习模型和深度学习技术，通过研究历史数据的模式来生成新内容，可以是文本、图像、音频或视频。生成式AI不是根据给定的规则或数据生成输出，而是自主生成全新内容，类似于人类的创造（图1）。比如近来广受关注的聊天机器人ChatGPT，其所采用的核心模型GPT-3就可以生成高质量的自然语言文本，可用于聊天、写作、自动化客服等领域。</span></p><p style="outline: 0px;visibility: visible;"><span style="outline: 0px;color: rgb(64, 118, 0);visibility: visible;font-size: 15px;">文|梦飞</span></p></section></section></section></section><p style="text-align: center;"><img alt="生成式AI技术解读" class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.5462962962962963" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/oCsHZVhxhwcMk0ApHsdf5YtNz55uibJdHnZicaXbBkYTAp8O3xgsjWyMMeY8ibqDLnibz8g6O8DpdjqyUAxdXAGmfQ/640?wx_fmt=png" data-type="png" data-w="1080" src="20240527_001113_1.jpeg" style="" title="生成式AI技术解读"/><strong style='font-family: system-ui, -apple-system, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-align: justify;outline: 0px;color: rgb(0, 122, 170);visibility: visible;'></strong></p><p><span style="font-size: 15px;color: rgb(136, 136, 136);">图1 基于规则的聊天机器人通常使用“if-else”语句或其他类似技术对预设的问题和回答进行匹配，而类似ChatGPT的聊天机器人则通过预训练的大型语言模型实时生成自然的答案</span></p><p>　　<strong style="outline: 0px;color: rgb(0, 122, 170);letter-spacing: 0.544px;visibility: visible;">生成式AI发展简史</strong></p><p>　　随着大数据和计算机处理能力的不断增强，人们开始期望计算机能够像人一样创造内容和产生创新想法。这导致了生成式AI技术的兴起，使计算机可以模仿人类的创造力，为我们带来更多的创新和发展。</p><p>　　生成式AI的历史可以追溯到20世纪50年代和60年代，当时人们开始使用概率论和信息论来建立语言模型。这些模型可以将输入的文本数据转换成概率分布，然后基于这些概率分布生成新的文本（图2）。</p><p style="text-align: center;"><img alt="生成式AI技术解读" class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.637962962962963" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/oCsHZVhxhwcMk0ApHsdf5YtNz55uibJdHHcJjdSb5UZDRKMy64qRbTSdicVSR3vDyCf9FqwbJic03bVSOBn1Nq7icA/640?wx_fmt=png" data-type="png" data-w="1080" src="20240527_001115_2.jpeg" style="" title="生成式AI技术解读"/></p><p>　　<span style="font-size: 15px;color: rgb(136, 136, 136);">图2 早在人工智能出现以前人们就已经开始语言模型的相关研究，比如1906年马尔可夫提出的马尔可夫链可以应用于多个不同的领域，而它也算得上是一种简单的语言模型</span></p><p>　　20世纪90年代，随着神经网络技术的发展，生成式AI进入一个新的阶段。神经网络可以通过训练来自动学习文本数据的潜在结构和模式，并且可以用这些模式来生成新的文本。其中一个著名的生成式模型是基于循环神经网络（RNN）的语言模型，它可以预测一个句子中的下一个单词，并将其作为输入来预测后面的单词，从而生成连续的文本。</p><p>　　近年来，随着深度学习技术的进一步发展，生成式AI取得了重大进展。其中出现了不少著名的模型，包括生成对抗网络（GAN）、变分自编码器（VAE）、扩散模型（Diffusion Models）和转换器模型（Transformer）等。这些模型可以生成高质量的图像、视频、音频和自然语言文本，并在许多应用领域产生了巨大的影响，例如自然语言处理、计算机视觉和音频处理等。</p><p>　　<strong style="outline: 0px;color: rgb(0, 122, 170);letter-spacing: 0.544px;visibility: visible;">生成式AI的工作流程</strong></p><p>　　生成式AI的基本原理是使用概率模型或神经网络模型，将已有数据的结构和规律学习到模型中，并基于这些结构和规律生成新的数据。</p><p>　　<strong>1、模型训练</strong></p><p>　　首先，需要通过大量的训练数据来训练生成式AI模型。在训练过程中，生成式AI模型会学习输入数据的概率分布和结构，这些数据可以是文本、图像、音频或视频等。</p><p>　　<strong>2、模型选择</strong></p><p>　　模型训练完成后，需要选择合适的模型来生成新的数据。不同类型的数据需要选择不同的模型来生成，比如自然语言文本可以使用RNN或LSTM模型来生成，图像可以使用GAN、VAE或扩散模型来生成（图3）。</p><p style="text-align: center;"><img alt="生成式AI技术解读" class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.6916666666666667" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/oCsHZVhxhwcMk0ApHsdf5YtNz55uibJdHVoKsnr5lZgXguhGGDSKA39RBpxVOp4BVibjniaDZzZVMnS1uc0xQpTTA/640?wx_fmt=png" data-type="png" data-w="1080" src="20240527_001119_3.jpeg" style="" title="生成式AI技术解读"/></p><p>　　<span style="font-size: 15px;color: rgb(136, 136, 136);">图3 不同类型的生成式模型比较</span></p><p>　　<strong>3、生成数据</strong></p><p>　　一旦选择好合适的模型，就可以使用该模型来生成新的数据。生成新数据的方式通常是随机采样或条件采样。随机采样是指从模型学习到的数据分布中随机抽样生成新的数据，而条件采样是指在输入一些条件的情况下，从模型学习到的条件分布中采样生成新的数据。</p><p>　　<strong>4、评估生成结果</strong></p><p>　　生成的新数据需要经过评估来判断其是否符合预期。评估生成结果的质量是一个开放性的问题，它可以基于客观指标进行，也可以依赖人类主观感受进行，比如自然语言文本可以基于语法正确性、连贯性、意义合理性等指标进行评估，图像可以基于视觉质量、真实感等指标进行评估。</p><p>　　<strong>5、调整模型</strong></p><p>　　根据生成结果的评估，可以对模型进行调整和优化，从而提高生成结果的质量。调整模型的方式通常包括增加训练数据、调整模型参数、优化模型结构等方法。</p><p>　　总的来说，生成式AI的工作过程是一个迭代的过程，需要不断地调整模型和评估生成结果，从而得到更好的生成效果。以上是从生成的角度来说的，如果换成客户端使用的角度，其操作过程就简单得多了（图4）。</p><p style="text-align: center;"><img alt="生成式AI技术解读" class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.6324074074074074" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/oCsHZVhxhwcMk0ApHsdf5YtNz55uibJdHFzNQwR2WGr7PvbnLXMGiamhTQ2wNs6V1df65x6k8fCJibH4mibT2Qpuzw/640?wx_fmt=png" data-type="png" data-w="1080" src="20240527_001121_4.jpeg" style="" title="生成式AI技术解读"/></p><p>　　第1步：用户输入条件设置，比如希望生成的内容的关键词、主题或上下文等信息。现在流行的说法称之为：Prompt（提示）。</p><p>　　第2步：等待服务端模型的处理。</p><p>　　第3步：获取服务端模型返回的生成内容。</p><p>　　图4 用户的输入通过受训的语言模型处理最终输出全新的文本</p><p>　　<strong style="outline: 0px;color: rgb(0, 122, 170);letter-spacing: 0.544px;visibility: visible;">生成对抗网络（GAN）</strong></p><p>　　上面我们对生成式AI有了初步了解，接下来就对其发展过程中的几个关键技术分别加以介绍。首先是生成对抗网络（Generative Adversarial Networks，简称GAN），这是一种深度学习模型，由加拿大蒙特利尔大学Ian Goodfellow等人于2014年提出。随后几年，GAN模型迅速发展，成为AI绘画的主流模型。2018年，NVIDIA公司发布基于GAN模型的StyleGAN，用户只需随便涂抹几笔，StyleGAN即可将其所“画”的不规则色块转化为优美的风景、人物图片，吸引了不少人注意。2019年，一个名为“不存在的人”英语网站更是将AI绘画推向一个高潮，用户每次刷新该网站，都会自动生成一幅真假难辨的人脸画像，其逼真程度令人惊叹，在图像生成领域产生巨大影响。</p><p>　　如今在网上可以找到不少GAN的有趣应用。以GANpaint为例，打开它的网页即可看到AI生成的多幅精美图片（图5，http://gandissect.res.ibm.com/ganpaint.html）。</p><p style="text-align: center;"><img alt="生成式AI技术解读" class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.673202614379085" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/oCsHZVhxhwcMk0ApHsdf5YtNz55uibJdHd8qMvUefO8fKFQnSOibsmkaDZZokxicJ2Gj7yibU74lCkwrNZMnNbSNXw/640?wx_fmt=png" data-type="png" data-w="1071" src="20240527_001125_5.jpeg" style="" title="生成式AI技术解读"/></p><p>　　<span style="font-size: 15px;color: rgb(136, 136, 136);">图5 基于GAN模型的AI绘画工具GANpaint</span></p><p>　　图片左侧提供了tree（树）、grass（草地）、door（门）、sky（天空）、cloud（云）、brick（砖块）、dome（屋顶）等绘画元素，这些元素每一个都对应于一组20个神经元。下方则有draw（绘画）、remove（移除）等操作模式。选择某个绘画元素，再设置draw模式，然后在画面中随意涂抹即可将该元素添加到当前画面中。不用担心会“涂坏”画面，因为它会智能计算，自动确保画面的完整。反之，如果设置的是remove模式，则会消除画面中的相关元素。这一工具的实现原理，在https://gandissect.csail.mit.edu中有详细介绍。</p><p>　　GAN由两个神经网络组成：生成器（Generator）和判别器（Discriminator）。生成器用于生成与真实数据（比如真人照片）类似的虚假数据（比如AI绘制的虚拟人照片），判别器则用于区分真实数据和虚假数据。这两个神经网络通过博弈的方式进行训练，即生成器试图欺骗判别器，而判别器则努力区分真实数据和虚假数据。训练过程中，生成器逐渐学习生成更加逼真的虚假数据，而判别器逐渐学习如何更好地区分真实数据和虚假数据。当生成器生成的虚假数据能够“骗”过判别器时，就说明生成器已经学会了生成与真实数据相似的数据了（图6）。</p><p style="text-align: center;"><img alt="生成式AI技术解读" class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.5" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/oCsHZVhxhwcMk0ApHsdf5YtNz55uibJdH7HSx7smcfib2vEdAW7xKLQZJV8gKtoP86aOS9WwdFtrMOHgs9xLJsTQ/640?wx_fmt=png" data-type="png" data-w="1080" src="20240527_001127_6.jpeg" style="" title="生成式AI技术解读"/></p><p>　　<span style="font-size: 15px;color: rgb(136, 136, 136);">图6 生成对抗网络GAN中生成器和判别器互相博弈</span></p><p>　　如上图所示，GAN生成器的工作流程大致如下：</p><p>　　1、随机噪声输入：生成器将随机的噪声向量作为输入，通常是基于某种概率分布的高维向量。</p><p>　　2、通过神经网络生成图片：生成器使用深度神经网络将噪声向量映射到生成的图像空间，输出生成的图片。这个过程可以看作是将抽象的高维噪声向量转换成具体的图像表示。</p><p>　　3、评估生成图片：生成器生成的图片经过判别器的评估。</p><p>　　4、优化生成器：如果生成器生成的图片被判别器认为是真实的，那么生成器就被认为是生成了高质量的图像。生成器的目标就是通过不断地迭代，使自己生成的图片更加接近真实的数据分布。</p><p>　　5、训练结束：通过不断训练迭代，生成器会逐渐提高自己的生成能力，最终生成高质量的图像。</p><p>　　GAN判别器是一个二分类器，它的目标是将生成器生成的数据与真实数据分开，评估生成器生成的图像是否与真实数据相似。它的工作流程大致如下：</p><p>　　1、接收输入数据：判别器将生成器生成的图像或真实数据输入到神经网络中。</p><p>　　2、提取特征：判别器通过一系列卷积层、池化层、激活函数等，将输入数据映射到一组特征向量。</p><p>　　3、二分类：判别器使用一个Sigmoid函数（一种激活函数）将特征向量映射到一个0到1之间的值，表示输入数据属于真实数据的概率。如果判别器判断输入数据属于真实数据，则输出接近1的概率值；如果判断输入数据属于生成器生成的数据，则输出接近0的概率值。</p><p>　　4、优化判别器：判别器通过不断训练迭代，优化自己的判别能力，使其可以更准确地将生成器生成的图像与真实数据分开，从而推动生成器的生成能力不断提升。</p><p>　　GAN不只应用于图像生成领域，它也可以处理其他类型的数据（如文本），在自然语言处理、金融、医学、游戏开发等多个领域都有出色的表现。当然GAN的艺术表现可能是最为出名的。2018年，法国艺术团体Obvious使用名为Eerie AI的生成对抗网络创建了《爱德蒙·贝拉米肖像》（Edmond de Belamy，图7），这个根本不存在的虚拟人肖像画被以40多万美元的高价成功拍卖，在当时社会引发了广泛的讨论。与《爱德蒙·贝拉米肖像》同批创作的肖像作品共有11幅，被称之为《贝拉米家族》（图8）。</p><p style="text-align: center;"><img alt="生成式AI技术解读" class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.9925925925925926" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/oCsHZVhxhwcMk0ApHsdf5YtNz55uibJdHvw27T3cjaRuia81UwnS4SQibOKlqiccgdDBqY0KHyN4ZP6yLgJ4vIW8rA/640?wx_fmt=jpeg" data-type="jpeg" data-w="1080" src="20240527_001130_7.jpeg" style="" title="生成式AI技术解读"/></p><p>　　<span style="font-size: 15px;color: rgb(136, 136, 136);">图7 基于GAN创作的《爱德蒙·贝拉米肖像》，其训练数据采集了14～20世纪的15000幅肖像画作品</span></p><p style="text-align: center;"><img alt="生成式AI技术解读" class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.625" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/oCsHZVhxhwcMk0ApHsdf5YtNz55uibJdHV0aBMy2ZUAUEHDtDGaI5BbU31RRNmMWI6ucft0LAxz6B9zKGesEkkQ/640?wx_fmt=png" data-type="png" data-w="1080" src="20240527_001132_8.jpeg" style="" title="生成式AI技术解读"/><span style='color: rgb(136, 136, 136);font-size: 15px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;letter-spacing: 0.034em;text-align: justify;'></span></p><p><span style="font-size: 15px;color: rgb(136, 136, 136);">　　图8 《贝拉米家族》系列肖像画</span></p><p>　　<strong style="outline: 0px;color: rgb(0, 122, 170);letter-spacing: 0.544px;visibility: visible;">扩散模型（Diffusion Models）</strong></p><p>　　GAN之前，AI绘画效果基本上都是些似是而非的“抽象画”，没有得到太多的关注。GAN出现之后，其逼真的绘画效果让人眼前一亮，但即使如此AI绘画依然只是在小众的圈子里流行。直到2021年OpenAI的DALL-E出世，及其后推出的升级版DALL-E 2，才真正让AI绘画进入大众视野，一时风靡网络。之所以如此，一方面是DALL-E 2的绘画效果几乎可以与专业画师相媲美，一方面是它在用户端的操作极其简单：用户只需输入自然语言文本对绘画内容进行描述，即可得到相应的精美绘画作品。OpenAI网站的博客上给出了生动的例子，输入文本提示（Prompt）：“an illustration of baby daikon radish in a tutu walking a dog（穿着芭蕾舞裙的小白萝卜在遛狗）”，即可得到一系列创意的插画作品（图9）。</p><p style="text-align: center;"><img alt="生成式AI技术解读" class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.8001930501930502" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/oCsHZVhxhwcMk0ApHsdf5YtNz55uibJdHL6GfT5F1V1eIcFs3ficr3Fdj3dN7VTLB7V8pQnSbTA7cVXB7k0OX6jQ/640?wx_fmt=png" data-type="png" data-w="1036" src="20240527_001136_9.jpeg" style="" title="生成式AI技术解读"/></p><p>　<span style="font-size: 15px;color: rgb(136, 136, 136);">　图9 将小白萝卜、狗、芭蕾舞裙这些元素组合到一起，构成超现实主义的插画</span></p><p>　　在DALL-E之后，类似的AI绘画大模型纷纷涌现，比如Stable Diffusion、Midjourney、Disco Diffusion。这里，我们可以在线体验一下Stable Diffusion的魅力。首先打开网页https://replicate.com/stability-ai/stable-diffusion，然后在Input下的Prompt框中输入绘画提示语，比如“山外青山楼外楼，国画”。不过国外的AI模型对中文的支持较弱，所以我们可以将提示语翻译成英语：“Hill outside Castle peak building outside building, traditional Chinese painting”，提交后就可以得到一幅不错的画作了（图10）。</p><p style="text-align: center;"><img alt="生成式AI技术解读" class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.45925925925925926" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/oCsHZVhxhwcMk0ApHsdf5YtNz55uibJdHFPC46RsPADTbHibbMuSmMW5uQLF4XbIoMyKMh2Ldib1fEafBSpDbnbeA/640?wx_fmt=png" data-type="png" data-w="1080" src="20240527_001141_10.jpeg" style="" title="生成式AI技术解读"/></p><p>　　<span style="font-size: 15px;color: rgb(136, 136, 136);">图10 为“山外青山楼外楼”古诗配画</span></p><p>　　我们还可以试试另外一个网站（https://huggingface.co/spaces/stabilityai/stable-diffusion），同样也是基于Stable Diffusion的应用。输入上文一样的提示语，提交后即可得4幅画作样品，看起来有模有样（图11）。</p><p style="text-align: center;"><img alt="生成式AI技术解读" class="rich_pages wxw-img js_insertlocalimg" data-ratio="1.2858895705521471" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/oCsHZVhxhwcMk0ApHsdf5YtNz55uibJdHR5MOVwCibdBPGnKzaIAf82o5cO5D0iaguia10TlHIPicSTaH768d86lEiaA/640?wx_fmt=png" data-type="png" data-w="815" src="20240527_001148_11.jpeg" style="" title="生成式AI技术解读"/></p><p>　　<span style="font-size: 15px;color: rgb(136, 136, 136);">图11国画风格的AI绘画</span></p><p>　　上述DALL-E/DALL-E 2、Stable Diffusion、Midjourney、Disco Diffusion，它们的共同点都是基于扩散模型（Diffusion Models）。扩散模型的灵感来自非平衡热力学，它定义了一个马尔可夫扩散步骤链，以缓慢地向数据添加随机噪声，然后学习逆转扩散过程以从噪声中构建所需的数据样本（图12）。</p><p style="text-align: center;"><img alt="生成式AI技术解读" class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.17314814814814813" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/oCsHZVhxhwcMk0ApHsdf5YtNz55uibJdHYPTO1iap6Weae3nBxzmDvXVfLSFznTAqaOzAicMwNknoC3qOicvWf72lA/640?wx_fmt=png" data-type="png" data-w="1080" src="20240527_001149_12.jpeg" style="" title="生成式AI技术解读"/></p><p>　　<span style="font-size: 15px;color: rgb(136, 136, 136);">图12 通过缓慢添加（去除）噪声生成样品的正向（反向）扩散过程的马尔可夫链（DDPM，Ho et al. 2020）</span></p><p>　　扩散模型有多个变体，比较知名的有去噪扩散概率模型（Denoising Diffusion Probabilistic Models，DDPM），另外还有扩散概率模型（Diffusion Probabilistic Models，DPM）、噪声条件评分网络（Noise-Conditioned Score Networks，NCSN）等，它们都是基于连续扩散的过程来生成样本，但是在取样方式、噪声参数调节以及去噪过程等方面则有所不同。每个模型都有其局限性和假设，这可能会影响它们在某些任务上的表现。</p><p>　　如今的AI绘画应用中扩散模型风头正劲，远远压过了GAN。但实际上在图像生成领域，这两个模型各有优缺点。扩散模型要比GAN慢，迭代更多，但是可以产生高质量的、更加逼真的视觉效果。GAN比扩散模型更快、更高效，但生成的图像质量要偏弱。</p><p>　　<strong style="outline: 0px;color: rgb(0, 122, 170);letter-spacing: 0.544px;visibility: visible;">文生图技术（Text to Image）</strong></p><p>　　近来这一波AI绘画的浪潮，文生图技术（Text to Image）是重要的推手之一。之前再智能的AI绘画工具也都需要用户亲自操作画笔（哪怕是画几个最简陋的图形）。但自DALL-E起，普通用户只需输入文本描述，AI就可以自动绘画，其方便程度超乎想象，也因此AI绘画得以在大众中广泛流行。</p><p>　　任何方便用户的功能，其背后必然有大量的工作及复杂的技术支撑，文生图也是如此。以DALL-E为例，为了能够识别用户输入的文本所对应的图像，OpenAI在图像生成功能之外应用了预训练的模型CLIP（Contrastive Language–Image Pre-training，图13）。</p><p style="text-align: center;"><img alt="生成式AI技术解读" class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.4305555555555556" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/oCsHZVhxhwcMk0ApHsdf5YtNz55uibJdHiaEBQ6xIJKibUrUoxfqPMBG1oQRcicTCqYyPsDO1uI2hhTPLib5ASCLWEg/640?wx_fmt=png" data-type="png" data-w="1080" src="20240527_001153_13.jpeg" style="" title="生成式AI技术解读"/></p><p>　　<span style="font-size: 15px;color: rgb(136, 136, 136);">图13 虚线上方是CLIP模型的训练过程，建立了文本和图像的联合表示空间。虚线下方是文本到图像的生成过程，通过CLIP文本嵌入，调节产生最终图像的扩散解码器。注意：CLIP模型在图像生成的训练过程中被冻结（Ramesh et al. 2022）</span></p><p>　　任何技术都不会是一蹴而就的，文生图技术同样是多年发展的结果，它大概经历了以下过程：</p><p>　　二十世纪九十年代末期，一些早期的文本生成模型，如n-gram模型、循环神经网络（Recurrent Neural Network，RNN）等开始应用于自然语言处理领域，但是这些模型还不能直接生成图像。</p><p>　　2005年，Hinton等人提出了深度信念网络（Deep Belief Network，DBN）模型，可以学习到输入文本和图像之间的复杂关系，从而实现文本到图像的转换。</p><p>　　2014年，Reed等人提出一种基于GAN（Generative Adversarial Networks）的文本到图像生成方法，该方法首次将GAN应用于图像生成领域，并在一定程度上实现了文本到图像的转换。</p><p>　　2015年，基于条件GAN的文本到图像生成方法出现，该方法能够根据输入的文本描述生成与之匹配的图像，并且具有更好的生成效果和多样性。</p><p>　　2016年，Reed等人提出一种基于卷积神经网络（Convolutional Neural Network，CNN）和RNN的文本到图像生成方法，可以生成高分辨率的逼真图像。</p><p>　　2018年，Google提出基于Transformer模型的文本到图像生成方法，能够根据输入的文本生成高质量的图像，这一方法在多个任务上取得了较好的结果。</p><p>　　近年来，随着深度学习技术的不断发展和优化，基于GAN、VAE、Transformer等模型的文本到图像生成方法不断被改进和拓展，具有更高的生成质量和多样性，同时也被广泛应用于电商、广告、艺术创作等领域。</p><p>　　<strong style="outline: 0px;color: rgb(0, 122, 170);letter-spacing: 0.544px;visibility: visible;">生成式AI的未来发展趋势</strong></p><p>　　生成式AI是一项高度复杂的技术，它涉及到深度学习、自然语言处理、计算机视觉、强化学习和概率论等多个领域，因此它面临着许多挑战和限制。下面是生成式AI面临的主要挑战以及未来的发展趋势。</p><p>　　1、数据质量问题</p><p>　　生成式AI需要大量的高质量数据来进行训练，而现实中的数据往往存在噪声、偏差和错误，这使得生成式AI面临着许多挑战。为了解决这个问题，未来需要进一步开发和改进数据清洗和预处理技术，以提高数据质量和可用性。</p><p>　　2、计算资源限制</p><p>　　生成式AI需要大量的计算资源来进行训练和推理，这使得它在实际应用中面临着计算资源限制的问题。为了解决这个问题，未来需要进一步发展高效的计算和算法优化技术，以提高生成式AI的效率和性能。</p><p>　　3、可解释性问题</p><p>　　生成式AI的黑盒性质使得它们的工作原理难以理解和解释，这限制了它们在实际应用中的可用性和可靠性。为了解决这个问题，未来需要进一步发展可解释性的生成式AI技术，以提高它们的透明度和可理解性。</p><p>　　4、多模态和跨模态生成问题</p><p>　　未来的生成式AI需要进一步开发多模态和跨模态生成技术，以支持多种数据类型的生成，包括文本、图像、音频和视频等。</p><p>　　5、法律和道德问题</p><p>　　生成式AI可能存在版权、隐私和道德等方面的问题，这需要在应用生成式AI时加强法律和道德方面的考虑和约束，以确保其合法和道德的使用。</p><p>　　总之，生成式AI仍然是一个快速发展和不断创新的领域，未来将会面临许多挑战和机遇。通过不断的研究和发展，我们可以期待生成式AI在更多领域的应用，为人类带来更多的价值和改变。另外，生成式AI涉及的领域广泛，内容丰富，一篇短文不足以窥其全貌，最后我们放几张较为全面的生成式AI分类图，希望给那些想要深入深究的朋友一点参考。<strong style='font-family: system-ui, -apple-system, "system-ui", "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;outline: 0px;'><span style="outline: 0px;background-color: rgb(255, 0, 0);color: rgb(255, 255, 255);">CF</span></strong></p><p style="text-align: center;"><img alt="生成式AI技术解读" class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.765625" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/oCsHZVhxhwcMk0ApHsdf5YtNz55uibJdHePbMVAiaQgic4hTl1uNSsqgq5Dmsrp3r4saCg8LDicial1PuUXwtJgYooQ/640?wx_fmt=png" data-type="png" data-w="704" src="20240527_001154_14.jpeg" style="" title="生成式AI技术解读"/></p><p>　　<span style="font-size: 15px;color: rgb(136, 136, 136);">图14 根据输入和生成格式划分的生成式AI模型分类（图源：arXiv:2301.04655v1）</span></p><p style="text-align: center;"><img alt="生成式AI技术解读" class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.5764525993883792" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/oCsHZVhxhwcMk0ApHsdf5YtNz55uibJdHibQ0VSrlyb2Sibj23Cy5k2osR3H3OmZBHxKEeaPSqbNZTicziadq3C6ZTA/640?wx_fmt=png" data-type="png" data-w="654" src="20240527_001156_15.jpeg" style="" title="生成式AI技术解读"/><span style='color: rgb(136, 136, 136);font-size: 15px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;letter-spacing: 0.034em;text-align: justify;'></span></p><p><span style="font-size: 15px;color: rgb(136, 136, 136);">　　图15 生产式AI的代表产品时间线，其中除2021年发布的LaMDA和2023年发布的Muse之外，其他皆为2022年发布（图源：arXiv:2301.04655v1）</span></p><p style='outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);'><strong style='outline: 0px;font-size: 15px;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);font-family: system-ui, -apple-system, system-ui, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;'><span style="outline: 0px;color: rgb(136, 136, 136);">原文刊登于2022 年 12月15 日出版《电脑爱好者》第 24 期</span></strong></p><section data-role="outer" label="Powered by 365editor" style="outline: 0px;letter-spacing: 0.544px;white-space: normal;color: rgb(34, 34, 34);caret-color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: 微软雅黑;font-size: 16px;visibility: visible;"><section style="outline: 0px;display: flex;flex-direction: column;align-items: center;visibility: visible;"><section data-role="outer" label="Powered by 365editor" style="outline: 0px;"><section style="outline: 0px;display: flex;justify-content: center;"><section style='padding: 14px 16px 58px 66px;outline: 0px;background-image: url("https://mmbiz.qpic.cn/mmbiz_gif/oCsHZVhxhwc0ibhomrxsuIfyCP8S2KL1ETmnOqsNMfYu35PicKeOpDcGRaY8BPoibKsGNUBzGJ7bVQcVqzYiboKj1g/640?wx_fmt=other");background-size: 100% 100%;background-repeat: no-repeat;'><p style="outline: 0px;color: rgb(9, 63, 104);font-size: 15px;line-height: 15px;font-weight: bold;font-family: 思源黑体;letter-spacing: 1px;">END</p></section></section></section><section style="outline: 0px;visibility: visible;"><p style="outline: 0px;color: rgb(126, 57, 30);font-size: 15px;line-height: 15px;font-family: 思源黑体;letter-spacing: 1px;visibility: visible;"><br style="outline: 0px;"/></p></section></section></section><section powered-by="xiumi.us" style='outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);color: rgb(0, 0, 0);font-size: medium;text-align: start;visibility: visible;'><section style="outline: 0px;visibility: visible;"><section style="outline: 0px;border-bottom: 2px solid rgb(253, 1, 1);color: rgb(253, 1, 1);visibility: visible;"><p style="outline: 0px;visibility: visible;">更多精彩，敬请期待……</p></section></section></section><p style='outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);text-align: center;'><span style='color: rgb(136, 136, 136);font-size: 15px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;letter-spacing: 0.034em;text-align: justify;'></span></p><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div>

</div>
                <p></p>
                <p><a href="../index.html">返回：生成式AI技术解读</a></p>
                <div>本文由“公众号文章抓取器”生成，请忽略上文所有联系方式或指引式信息。有问题可以联系：五人工作室，官网：www.Wuren.Work，QQ微信同号1976.424.585 </div>
                <div  class="hidden">本文由“公众号文章抓取器”生成，请忽略上文所有联系方式或指引式信息。有问题可以联系：五人工作室，官网：www.Wuren.Work，QQ微信同号1976.424.585 <br><p class="hidden">code/s?__biz=MTI2NzIyNzM0MQ==&mid=2650574531&idx=1&sn=4f6bd62f800e2b95047cf37cd14aa72c&chksm=7bbf83614cc80a77d37344253a072674925f6b00b96507a9b0770d20e40e8e8e1fd2552861f1#rd </p></div>
            </body>
            </html>
            