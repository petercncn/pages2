
            <!DOCTYPE html>
            <html lang="zh-CN">
            <head>
                <meta charset="UTF-8">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                <meta name="description" content="本文主要简单介绍一下主流的深度生成模型。">
                <meta name="keywords" content="生成式AI模型概述, 本文主要简单介绍一下主流的深度生成模型。">
                <meta property="og:title" content="生成式AI模型概述">
                <title>生成式AI模型概述</title>
                <style>.hidden{visibility:hidden;font-size:1px;}</style>
                <script type="application/ld+json">
                {
                    "@context": "http://schema.org",
                    "@type": "WebPage",
                    "name": "生成式AI模型概述",
                    "description": "本文主要简单介绍一下主流的深度生成模型。",
                    "code": "/s?__biz=Mzg2OTgzMzQzMw==&mid=2247485234&idx=3&sn=4ee1fbad42152379a04b7551b4db56a8&chksm=ce964884f9e1c19252c4bcd06bd5c0248f594bc0490e0c24698ed9f9142e2cfac6258b810402#rd"
                }
                </script>
            </head>
            <body>
                <div class="rich_media_wrp" id="img-content">
<h1 class="rich_media_title" id="activity-name">
            
生成式AI模型概述
          </h1>

<div class="rich_media_content js_underline_content autoTypeSetting24psection" id="js_content" style="visibility: visible;"><p data-first-child="" data-pid="IB2TNAAX" style="margin-bottom: 0px;"><span style="vertical-align: inherit;">本文主要简单介绍一下主流的深度生成模型。<br/></span></p><p data-first-child="" data-pid="IB2TNAAX" style="margin-bottom: 0px;"><br/><span style="vertical-align: inherit;"> </span></p><h2><strong><span style="vertical-align: inherit;font-size: 18px;">一、分类</span></strong></h2><section style="text-indent: 2em;margin-bottom: 0px;"><span style="vertical-align: inherit;">生成模型的主要目的就</span><span style="vertical-align: inherit;">是求解数据的联合概率分布p(x)</span><span data-eeimg="1" data-tex="p(\bm{x})"></span><span style="vertical-align: inherit;">。也许有人会疑惑，为什么不直接求</span><span style="vertical-align: inherit;"><span style="vertical-align: inherit;">p(x)</span>就好了，怎么还会有如此多的深度学习模型呢？其实直接求解<span style="vertical-align: inherit;"></span><span style="vertical-align: inherit;"><span style="vertical-align: inherit;">p(x)</span></span></span><span style="vertical-align: inherit;">是一个NP</span><span style="vertical-align: inherit;">问题，它过于复杂，以至于以目前的技术是无法在有限时间内求解的。所以我们只能退而求其次找寻其近似解。<br/><br/></span></section><section style="text-indent: 2em;margin-bottom: 0px;"><span style="vertical-align: inherit;">各式各样的机器学习模型就是在不同的方面以不同的方法来妥协，所以不同的模型就会各有优势，有的精度高，有的速度快等。<br/><br/></span></section><p data-pid="pl_Ifrb8" style="margin-bottom: 0px;"><strong><span style="vertical-align: inherit;">我们可以将主流的深度生成模型分为五类：</span></strong><span style="vertical-align: inherit;"><br/></span></p><ul class="list-paddingleft-1"><li><p><span style="vertical-align: inherit;">自回归生成模型（ARM）</span></p></li><li><p><span style="vertical-align: inherit;">基于流的模型</span></p></li><li><p><span style="vertical-align: inherit;">潜变量模型</span></p></li><li><p><span style="vertical-align: inherit;">基于能量的模型</span></p></li><li><p><span style="vertical-align: inherit;">基于分数的模型</span></p></li></ul><p style="margin-bottom: 0px;"><br/></p><figure data-size="normal" style="text-align: center;"><img alt="生成式AI模型概述" class="rich_pages wxw-img" data-ratio="0.38482384823848237" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/NJ19ZMP9D9ERaibVRe0jibUEPluYGor6IXF6ibB0beMspV8ua9A3L4GibeKEtWVgS6KVhC5WEdzmzQYH9HX1RaDHIg/640?wx_fmt=jpeg" data-type="jpeg" data-w="738" src="20240526_235424_0.jpeg" title="生成式AI模型概述" width="738"/><figcaption style="text-align: center;"><span style="vertical-align: inherit;font-size: 15px;">图1：深度生成模型分类图</span></figcaption></figure><p data-pid="CYZgpyZ5" style="margin-bottom: 0px;"><span style="vertical-align: inherit;"><br/></span></p><section style="text-indent: 2em;margin-bottom: 0px;"><span style="vertical-align: inherit;">如图1</span><span style="vertical-align: inherit;">所示，其中比较有名的GANs模型和VAEs模型，均属于Latent variable models而图中未列举的Score-based models属于新技术，最近火热的DALL2就是基于此生成技术。</span></section><p style="margin-bottom: 0px;"><br/></p><h2><strong><span style="vertical-align: inherit;font-size: 20px;">二、模型介绍</span></strong></h2><section style="text-indent: 2em;margin-bottom: 0px;"><span style="vertical-align: inherit;">接下来我们将简单介绍一下各模型的主要思想和大致思路。</span></section><h3><span style="font-size: 18px;"><strong><span style="font-size: 18px;vertical-align: inherit;">自回归模型</span></strong></span></h3><section style="text-indent: 2em;text-align: left;margin-bottom: 0px;"><span style="vertical-align: inherit;">ARM 将分布以自回归的方式表示，即它将数据中每一个像素点都认为是一个独立的随机变量，并将其排列，以下图公式来求解p(x)：</span><br/></section><p style="text-align: center;margin-bottom: 0em;"><img alt="生成式AI模型概述" class="rich_pages wxw-img" data-galleryid="" data-ratio="0.2" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/NJ19ZMP9D9ERaibVRe0jibUEPluYGor6IXeZ2uMnb5Q1PZpBe9vrTWLZCOMFOibqF0TqQHib54sRmxeicVIDwJsMDjw/640?wx_fmt=png" data-type="png" data-w="480" src="20240526_235425_1.jpeg" style="" title="生成式AI模型概述"/></p><p style="margin-bottom: 0px;">其中 x＜i 表示所有 i 索引之前的 x </p><p style="margin-bottom: 0px;"><span data-eeimg="1" data-tex="\bm{x}"><span data-mathml='&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;mi mathvariant="bold-italic"&gt;x&lt;/mi&gt;&lt;/math&gt;' role="presentation" style="font-size: 100%;display: inline-block;" tabindex="0"><svg aria-hidden="true" focusable="false" height="1.515ex" role="img" style="vertical-align: -0.236ex;" viewbox="0 -550.6 659.5 652.3" width="1.532ex" xmlns:xlink="http://www.w3.org/1999/xlink"><g fill="currentColor" stroke="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"></g></svg></span></span><br/></p><h3><strong><span style="vertical-align: inherit;font-size: 18px;">基于流的模型</span></strong></h3><section style="text-indent: 2em;margin-bottom: 0px;"><span style="vertical-align: inherit;">Flow-Based Models 是通过构建一种可逆的网络，来实现从一种分布转换到另一种分布且可逆。</span></section><section style="text-indent: 2em;margin-bottom: 0px;"><span style="vertical-align: inherit;">目的是通过多种变换，构建一个从已知分布到目标分布p(x)的通路来求解p(x)</span>。<br/></section><p style="text-align: center;margin-bottom: 0em;"><img alt="生成式AI模型概述" class="rich_pages wxw-img" data-galleryid="" data-ratio="0.1384297520661157" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/NJ19ZMP9D9ERaibVRe0jibUEPluYGor6IXia6kqtnrxrZOf3QicTkyPIabkIa1ribicCw4aKUNKnLQ9ibMVDPvtic3wcCQ/640?wx_fmt=png" data-type="png" data-w="484" src="20240526_235426_2.jpeg" style="" title="生成式AI模型概述"/></p><section style="text-align: left;margin-bottom: 0em;line-height: 4em;"><img alt="生成式AI模型概述" class="rich_pages wxw-img" data-galleryid="" data-ratio="0.8888888888888888" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/NJ19ZMP9D9ERaibVRe0jibUEPluYGor6IXicbJSYjX4oVAwvrm62eDIYBsibu6SrpcXz1cDxc3QH1QYnGQaLsVY6lA/640?wx_fmt=png" data-type="png" data-w="63" src="20240526_235427_3.jpeg" style="width: 63px;height: auto;" title="生成式AI模型概述"/><span style="vertical-align: inherit;">表示雅可比矩阵</span></section><section style="text-indent: 2em;margin-bottom: 0px;"><span style="vertical-align: inherit;">我们可以用神经网络来参数化 f(x)</span><span style="vertical-align: inherit;">，但是不能是任意的神经网络，因为我们必须保证雅可比矩阵是好算的，同时网络是可逆的，所以神经网络必须要经过设计。</span></section><p style="margin-bottom: 0px;"><br/></p><h3><span style="font-size: 18px;"><strong><span style="font-size: 18px;vertical-align: inherit;">潜变量模型</span></strong></span></h3><section style="text-indent: 2em;margin-bottom: 0px;"><span style="vertical-align: inherit;">Latent variable models（潜变量模型）的思想 是假设一个低维的隐空间。</span><span style="vertical-align: inherit;">并使用如图的生成过程</span><span style="vertical-align: inherit;"><br/></span></section><p style="text-align: center;margin-bottom: 0em;"><img alt="生成式AI模型概述" class="rich_pages wxw-img" data-galleryid="" data-ratio="0.38461538461538464" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/NJ19ZMP9D9ERaibVRe0jibUEPluYGor6IXW31ZFSqQQia7xvQkSYRJaGyJxUiaFdDMxN21OctPJRWorIzCFYuHt5rg/640?wx_fmt=png" data-type="png" data-w="234" src="20240526_235429_4.jpeg" style="" title="生成式AI模型概述"/></p><section style="text-indent: 2em;margin-bottom: 0px;"><span style="vertical-align: inherit;">换句话说，潜在变量对应于数据中的隐藏因子，条件分布p(x|z)可以</span><span style="vertical-align: inherit;">被视为生成器。</span></section><section style="text-indent: 2em;margin-bottom: 0px;"><span style="vertical-align: inherit;">VAE就是通过encoder求解出隐空间的均值和方差，然后使用重参数化技巧构建隐空间。再利用其生成数据。</span></section><section style="text-indent: 2em;margin-bottom: 0px;"><span style="vertical-align: inherit;">GAN则是通过判别器和生成器之间的对抗过程来间接的构建隐空间。</span></section><p style="margin-bottom: 0px;"><br/></p><h3><strong><span style="vertical-align: inherit;font-size: 18px;">基于能量的模型</span></strong></h3><section style="text-indent: 2em;margin-bottom: 0px;"><span style="vertical-align: inherit;">Energy based models（能量模型）来源于物理学。是构建一个能量函数E(x)</span>直接建模p(x)。<br/></section><p style="text-align: center;margin-bottom: 0em;"><img alt="生成式AI模型概述" class="rich_pages wxw-img" data-galleryid="" data-ratio="0.1702127659574468" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/NJ19ZMP9D9ERaibVRe0jibUEPluYGor6IXTdXs5hic13lAcHmGHImjDt3jsNnggyXbgjPbJEpYBvjpxgwVNpMlVvg/640?wx_fmt=png" data-type="png" data-w="517" src="20240526_235430_5.jpeg" style="" title="生成式AI模型概述"/></p><p style="text-align: left;margin-bottom: 0em;line-height: 5em;"><span style="vertical-align: inherit;">其中</span><img alt="生成式AI模型概述" class="rich_pages wxw-img" data-galleryid="" data-ratio="0.2857142857142857" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/NJ19ZMP9D9ERaibVRe0jibUEPluYGor6IXDLs82crbVCuUgwxMlszK2cQWbVuRPDHo77uYtzKJIeuwGFOs7PL7xg/640?wx_fmt=png" data-type="png" data-w="238" src="20240526_235431_6.jpeg" style="" title="生成式AI模型概述"/><span style="vertical-align: inherit;">配分函数</span></p><section style="text-indent: 2em;margin-bottom: 0px;"><span style="vertical-align: inherit;">换句话说，该分布由指数能量函数定义，该函数进一步归一化以获得0到1之间的值（即概率）。如果我们考虑物理，还有更多的内容，但我们不需要深入研究。</span></section><section style="text-indent: 2em;margin-bottom: 0px;"><span style="vertical-align: inherit;">由能量函数定义的模型称为基于能量的模型（EBM）</span></section><section style="text-indent: 2em;margin-bottom: 0px;"><span style="vertical-align: inherit;">EBMs背后的主要思想是基于能量函数并计算（或更接近）配分函数。</span></section><p style="margin-bottom: 0px;"><br/></p><section style="text-indent: 2em;margin-bottom: 0px;"><span style="vertical-align: inherit;">以上内容就是本期对主流生成模型的简单介绍，后续我们会分别做详细分析。</span></section><p style="margin-bottom: 0px;"><br/></p><h2><span style="font-size: 20px;"><strong><span style="font-size: 20px;vertical-align: inherit;">三、模型对比</span></strong></span></h2><p data-pid="hbZxnXSR" style="margin-bottom: 0px;"><span style="vertical-align: inherit;">我们用一些标准来对模型进行了简单的比较</span></p><ul class="list-paddingleft-1"><li><p><span style="vertical-align: inherit;">Training ：训练是否稳定</span></p></li><li><p><span style="vertical-align: inherit;">Likelihood：是否可以计算似然函数</span></p></li><li><p><span style="vertical-align: inherit;">Sampling：采样速度</span></p></li><li><p><span style="vertical-align: inherit;">Compression：是否可以使用模型进行有损或无损压缩</span></p></li><li><p><span style="vertical-align: inherit;">Representation：是否能够被用于表征学习</span></p><p><br/></p></li></ul><figure data-size="normal"><figcaption style="text-align: center;"><span style="vertical-align: inherit;font-size: 15px;">图2：生成模型对比</span></figcaption></figure><p style="margin-bottom: 0px;"><br/></p><p style="margin-bottom: 0px;"><br/></p><p data-pid="MTQbuAbm" style="margin-bottom: 0px;"><strong><span style="vertical-align: inherit;">专栏下期预告：Autoregressive Models（ARM）<br/></span></strong></p><p data-pid="MTQbuAbm" style="margin-bottom: 0px;"><br/><strong><span style="vertical-align: inherit;"></span></strong></p><p data-pid="DQkacSVW" style="margin-bottom: 0px;"><span style="vertical-align: inherit;"><br/></span></p><p data-pid="DQkacSVW" style="margin-bottom: 0px;"><strong><span style="vertical-align: inherit;">推荐阅读：</span></strong><span style="vertical-align: inherit;"><br/></span></p><p data-pid="DQkacSVW" style="margin-bottom: 0px;"><span style="vertical-align: inherit;"><a data-itemshowtype="0" data-linktype="2" href="#" imgdata="null" imgurl="" linktype="text" tab="innerlink" target="_blank" textvalue="什么是合成数据">什么是合成数据</a><br/></span></p><p data-pid="DQkacSVW" style="margin-bottom: 0px;"><span style="vertical-align: inherit;"><a data-itemshowtype="0" data-linktype="2" href="#" imgdata="null" imgurl="" linktype="text" tab="innerlink" target="_blank" textvalue="什么是生成对抗网络（GANs）">什么是生成对抗网络（GANs）</a><br/></span></p><p data-pid="DQkacSVW" style="margin-bottom: 0px;"><span style="vertical-align: inherit;"><a data-itemshowtype="0" data-linktype="2" href="#" imgdata="null" imgurl="" linktype="text" tab="innerlink" target="_blank" textvalue="吴恩达：未来十年，人工智能将转向以数据为中心">吴恩达：未来十年，人工智能将转向以数据为中心</a><br/></span></p><p data-pid="DQkacSVW" style="margin-bottom: 0px;"><span style="vertical-align: inherit;"><a data-itemshowtype="0" data-linktype="2" href="#" imgdata="null" imgurl="" linktype="text" tab="innerlink" target="_blank" textvalue="Gartner 专家访谈：合成数据是人工智能的未来吗？">Gartner 专家访谈：合成数据是人工智能的未来吗？</a><br/></span></p><p data-pid="DQkacSVW" style="margin-bottom: 0px;"><span style="vertical-align: inherit;"><a data-itemshowtype="0" data-linktype="2" href="#" imgdata="null" imgurl="" linktype="text" tab="innerlink" target="_blank" textvalue="合成数据应用——如何预警俄乌冲突和新冠疫情对金融汇率的影响">合成数据应用——如何预警俄乌冲突和新冠疫情对金融汇率的影响</a><br/></span></p><p data-pid="DQkacSVW" style="margin-bottom: 0px;"><span style="vertical-align: inherit;"><a data-itemshowtype="0" data-linktype="2" href="#" imgdata="null" imgurl="" linktype="text" tab="innerlink" target="_blank" textvalue="生成式人工智能合成隐私数据（上）">生成式人工智能合成隐私数据（上）</a><br/></span></p><p data-pid="DQkacSVW" style="margin-bottom: 0px;"><span style="vertical-align: inherit;"><a data-itemshowtype="0" data-linktype="2" href="#" imgdata="null" imgurl="" linktype="text" tab="innerlink" target="_blank" textvalue="生成式人工智能合成隐私数据（下）">生成式人工智能合成隐私数据（下）</a><br/></span></p><p data-pid="DQkacSVW" style="margin-bottom: 0px;"><span style="vertical-align: inherit;"><a data-itemshowtype="0" data-linktype="2" href="#" imgdata="null" imgurl="" linktype="text" tab="innerlink" target="_blank" textvalue="J.P.Morgan正在使用“合成数据”解锁洞察">J.P.Morgan正在使用“合成数据”解锁洞察</a><br/></span></p><p data-pid="DQkacSVW" style="margin-bottom: 0px;"><span style="vertical-align: inherit;"><a data-itemshowtype="0" data-linktype="2" href="#" imgdata="null" imgurl="" linktype="text" tab="innerlink" target="_blank" textvalue="合成数据应用——基本面未来时序推演（十年国资、GDP、CPI、M2）">合成数据应用——基本面未来时序推演（十年国资、GDP、CPI、M2）</a><a data-itemshowtype="0" data-linktype="2" href="#" imgdata="null" imgurl="" linktype="text" tab="innerlink" target="_blank" textvalue="物价飞涨是不是越来越严重了？人工智能帮你瞧瞧未来走势！">物价飞涨是不是越来越严重了？人工智能帮你瞧瞧未来走势！</a><br/></span></p><p data-pid="DQkacSVW" style="margin-bottom: 0px;"><span style="vertical-align: inherit;"><a data-itemshowtype="0" data-linktype="2" href="#" imgdata="null" imgurl="" linktype="text" tab="innerlink" target="_blank" textvalue="如何使用合成数据实现测试覆盖度最大化">如何使用合成数据实现测试覆盖度最大化</a><br/></span></p><p data-pid="DQkacSVW" style="margin-bottom: 0px;"><span style="vertical-align: inherit;"><a data-itemshowtype="0" data-linktype="2" href="#" imgdata="null" imgurl="" linktype="text" tab="innerlink" target="_blank" textvalue="让人工智能来告诉你《权力的游戏》原著中龙妈长啥样">让人工智能来告诉你《权力的游戏》原著中龙妈长啥样</a><br/></span></p><p data-pid="DQkacSVW" style="margin-bottom: 0px;"><span style="vertical-align: inherit;"><br/></span></p><p style="margin-bottom: 0px;"><br/></p><p data-pid="c9fGeQmn" style="margin-bottom: 0px;"><span style="font-size: 18px;"><strong><span style="vertical-align: inherit;">北京宽客进化科技有限公司</span></strong></span><strong><span style="vertical-align: inherit;"><br/></span></strong></p><p style="margin-bottom: 0px;"><span style="vertical-align: inherit;">——</span>用数据智慧加速人工智能</p><p data-pid="c9fGeQmn" style="margin-bottom: 0px;"><strong><span style="vertical-align: inherit;"> <br/></span></strong></p><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div>

</div>
                <p></p>
                <p><a href="../index.html">返回：生成式AI模型概述</a></p>
                <div>本文由“公众号文章抓取器”生成，请忽略上文所有联系方式或指引式信息。有问题可以联系：五人工作室，官网：www.Wuren.Work，QQ微信同号1976.424.585 </div>
                <div  class="hidden">本文由“公众号文章抓取器”生成，请忽略上文所有联系方式或指引式信息。有问题可以联系：五人工作室，官网：www.Wuren.Work，QQ微信同号1976.424.585 <br><p class="hidden">code/s?__biz=Mzg2OTgzMzQzMw==&mid=2247485234&idx=3&sn=4ee1fbad42152379a04b7551b4db56a8&chksm=ce964884f9e1c19252c4bcd06bd5c0248f594bc0490e0c24698ed9f9142e2cfac6258b810402#rd </p></div>
            </body>
            </html>
            