
            <!DOCTYPE html>
            <html lang="en">
            <head>
                <meta charset="UTF-8">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                <meta name="description" content="本文提出了一种新的框架：GAL，即通过生成大量和任务相关的合成文本，从而提升多种机器学习方法的性能，包括知识蒸馏， 自训练和基于提示的小样本学习。">
                <meta name="keywords" content="TACL 2022 _ GAL：合成文本在自然语言处理任务中的应用, 本文提出了一种新的框架：GAL，即通过生成大量和任务相关的合成文本，从而提升多种机器学习方法的性能，包括知识蒸馏， 自训练和基于提示的小样本学习。">
                <meta property="og:title" content="TACL 2022 | GAL：合成文本在自然语言处理任务中的应用">
                <title>TACL 2022 _ GAL：合成文本在自然语言处理任务中的应用</title>
                <style>.hidden{visibility:hidden;font-size:1px;}</style>
            </head>
            <body>
                <div class="rich_media_content js_underline_content autoTypeSetting24psection" id="js_content" style="visibility: visible;"><h1 class="rich_media_title" id="activity-name">TACL 2022 _ GAL：合成文本在自然语言处理任务中的应用</h1><section data-mpa-powered-by="yiban.io" style="text-align: center;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><img class="rich_pages wxw-img" data-backh="100" data-backw="578" data-galleryid="" data-ratio="0.1732283464566929" data-src="https://mmbiz.qpic.cn/mmbiz_gif/Psho9dm7oDHKVtfYDubjKdZRUjAfBQQicXjoZWJ3qnK42ooD4eeJUfJBM4SSZVa2RE5lO0j6rWwzliby0j9u4bDg/640?wx_fmt=gif" data-type="gif" data-w="635" src="20240525_020955_0.jpeg" style="width: 100%;height: auto !important;"/></section><section style="text-align: center;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><br/></section><p style="margin-bottom: 0px;text-align: right;line-height: 1.5em;margin-left: 0.5em;margin-right: 0.5em;"><strong><span style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 12px;letter-spacing: 0.5px;color: rgb(51, 51, 51);'>©PaperWeekly 原创 · 作者 | </span></strong><span style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 12px;letter-spacing: 0.5px;color: rgb(51, 51, 51);'>何玄黎</span></p><p style="margin-bottom: 0px;text-align: right;line-height: 1.5em;margin-left: 0.5em;margin-right: 0.5em;"><strong><span style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 12px;letter-spacing: 0.5px;color: rgb(51, 51, 51);'>单位 | </span></strong><span style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 12px;letter-spacing: 0.5px;color: rgb(51, 51, 51);'>伦敦大学学院（UCL）</span></p><p style="margin-bottom: 0px;text-align: right;line-height: 1.5em;margin-left: 0.5em;margin-right: 0.5em;"><strong><span style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 12px;letter-spacing: 0.5px;color: rgb(51, 51, 51);'>研究方向 | </span></strong><span style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 12px;letter-spacing: 0.5px;color: rgb(51, 51, 51);'>自然语言处理</span></p><p style="margin-left: 0.5em;margin-right: 0.5em;"><br/></p><p style="text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><img class="rich_pages wxw-img js_insertlocalimg" data-ratio="0.26796875" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgn3hnRWtTrQqB4yOuBlPHRl4ZRwyfXQiaBePaxMcjJC9FeEQKj4ia860SEMOYMJMuiboeBo5FpdTY5GA/640?wx_fmt=png" data-type="png" data-w="1280" src="20240525_020956_1.jpeg" style=""/></p><section style="margin-bottom: 0px;line-height: 1.5em;margin-left: 0.5em;margin-right: 0.5em;"><strong><span style="font-size: 12px;letter-spacing: 1px;color: rgb(63, 63, 63);">论文标题：</span></strong></section><section style="margin-bottom: 0px;line-height: 1.5em;margin-left: 0.5em;margin-right: 0.5em;"><span style="font-size: 12px;letter-spacing: 1px;color: rgb(63, 63, 63);">Generate, Annotate, and Learn: NLP with Synthetic Text</span></section><p style="margin: 16px 0.5em 0px;line-height: 1.5em;"><strong><span style="font-size: 12px;letter-spacing: 1px;color: rgb(63, 63, 63);">收录会议：</span></strong><span style="font-size: 12px;letter-spacing: 1px;color: rgb(63, 63, 63);"></span></p><section style="margin-bottom: 0px;line-height: 1.5em;margin-left: 0.5em;margin-right: 0.5em;"><span style="font-size: 12px;letter-spacing: 1px;color: rgb(63, 63, 63);">TACL 2022</span></section><p style="margin: 16px 0.5em 0px;line-height: 1.5em;"><strong><span style="font-size: 12px;letter-spacing: 1px;color: rgb(63, 63, 63);">论文链接：</span></strong><span style="font-size: 12px;letter-spacing: 1px;color: rgb(63, 63, 63);"></span></p><section style="margin-bottom: 0px;line-height: 1.5em;margin-left: 0.5em;margin-right: 0.5em;"><span style="font-size: 12px;letter-spacing: 1px;color: rgb(63, 63, 63);">https://arxiv.org/abs/2106.06168</span></section><p style="margin: 16px 0.5em 0px;line-height: 1.5em;"><strong><span style="font-size: 12px;letter-spacing: 1px;color: rgb(63, 63, 63);">博客链接：</span></strong></p><section style="margin-bottom: 0px;line-height: 1.5em;margin-left: 0.5em;margin-right: 0.5em;"><span style="font-size: 12px;letter-spacing: 1px;color: rgb(63, 63, 63);">https://synthetic-text.github.io/</span></section><p style="text-align: center;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;line-height: 2em;"><br/></p><section style="text-align: center;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><br/></section><p style="text-align: left;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><img class="rich_pages wxw-img" data-backh="84" data-backw="578" data-galleryid="" data-ratio="0.14577777777777778" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGhKg9nnSz5qQrwKvXibt3wulOVRfC18yCkd6xXqGq22h6QUk8chptF0fnQ4uXeZtAktYMrWwG2SyQ/640?wx_fmt=png" data-type="png" data-w="4500" src="20240525_020957_2.jpeg" style="width: 100%;height: auto !important;"/></p><p style="text-align: left;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><strong style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 20px;letter-spacing: 1px;text-align: left;'><span style="color: rgb(0, 0, 0);"><br/></span></strong></p><section style="text-align: left;margin-bottom: 16px;margin-left: 0.5em;margin-right: 0.5em;"><strong style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 20px;letter-spacing: 1px;text-align: left;'><span style="color: rgb(0, 0, 0);">研究背景</span></strong></section><p style="padding-top: 8px;padding-bottom: 8px;line-height: 1.75em;margin-bottom: 16px;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-size: 15px;font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;color: rgb(63, 63, 63);letter-spacing: 1px;'>未标记文本数据在自然语言处理任务上发挥着极其重要的作用。首先，预训练语言模型的成功主要归功于大量的未标注文本数据。其次，如果我们手上有大量任务相关的未标记数据，我们就可以利用这些数据来提升自训练（self-training）和知识蒸馏 （knowledge distillation）的效果。</span></p><p style="padding-top: 8px;padding-bottom: 8px;line-height: 1.75em;margin-bottom: 16px;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-size: 15px;font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;color: rgb(63, 63, 63);letter-spacing: 1px;'>但是在某一个指定任务上，未标注的数据通常是难以获取。该问题在某些自然语言处理任务上尤为突出，比如，文本相似度判断（text similarity），自然语言推断任务（natural language inference）。因为此类任务需要对一组文本之间的关系进行判别，所以它们的数据格式相较于单文本分类问题更为复杂。因此，很难采用传统信息检索的方式从互联网上获得此类任务的未标注数据。</span></p><p style="padding-top: 8px;padding-bottom: 8px;line-height: 1.75em;margin-bottom: 16px;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-size: 15px;font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;color: rgb(63, 63, 63);letter-spacing: 1px;'>此前的一些工作研究发现，通过微调 GPT2，即可生成一些任务相关的带标注合成文本（labelled synthetic text）。这些合成的标注数据可以提升常识推理 （Yang et al. 2020）和小样本文本分类任务 （Kumar et al. 2020）的性能。Ravuri et al. （2019）发现，即使带标注合成图片的质量在自动化评价指标上已经很接近真实的图片，但是和没用使用任何合成图片的图片分类模型比较，使用带标注合成图片的模型的准确度反而降低了。</span></p><p style="padding-top: 8px;padding-bottom: 8px;line-height: 1.75em;margin-bottom: 16px;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-size: 15px;font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;color: rgb(63, 63, 63);letter-spacing: 1px;'>同时，Kumar et al.（2020）也发现，带标注合成文本的语义信息和标注存在不一致的现象。除此以外，不少同期工作（Yang et al. 2020，Vu et al. 2021）也发现，合成数据可以大大提升各类自然语言处理任务的性能。但是这些方法都涉及到较为复杂的数据工程，比如，数据过滤，标注数据重标注等等。</span></p><section style="padding-top: 8px;padding-bottom: 8px;line-height: 1.75em;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-size: 15px;font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;color: rgb(63, 63, 63);letter-spacing: 1px;'>鉴于以上问题，我们提出一套更简洁和通用的框架：generate, annotate and learn（GAL）。我们的实验结果显示，GAL 可以显著提升知识蒸馏，自训练和小样本学习在文本任务上的性能，并且在 GLUE benchmark 的知识蒸馏赛道上可以打败最先进的基线方法。</span></section><p style="text-align: left;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;line-height: 2em;"><br/></p><section style="text-align: left;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><br/></section><section style="text-align: left;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><img class="rich_pages wxw-img" data-backh="84" data-backw="578" data-galleryid="" data-ratio="0.14555555555555555" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGhKg9nnSz5qQrwKvXibt3wuhfgUpIfdPSqH8YjjHbCUiaaKsMA36bIMsMtGNKoBcus5py06M0fvx3A/640?wx_fmt=png" data-type="png" data-w="4500" src="20240525_020958_3.jpeg" style="width: 100%;height: auto !important;"/></section><p style="text-align: left;margin-bottom: 0px;line-height: 1.75em;margin-left: 0.5em;margin-right: 0.5em;"><strong style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 20px;letter-spacing: 1px;text-align: left;'><span style="color: rgb(0, 0, 0);"><br/></span></strong></p><section style="text-align: left;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><strong style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 20px;letter-spacing: 1px;text-align: left;'><span style="color: rgb(0, 0, 0);">模型介绍</span></strong></section><h4 data-tool="mdnice编辑器" style="text-align: left;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><br/></h4><h4 data-tool="mdnice编辑器" style="text-align: left;margin-bottom: 16px;margin-left: 0.5em;margin-right: 0.5em;"><span style="font-size: 18px;"><strong style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 20px;letter-spacing: 1px;text-align: left;'><span style="font-size: 18px;color: rgb(0, 0, 0);">2.1 未标注合成文本在自训练和知识蒸馏的应用</span></strong></span></h4><section style="padding-top: 8px;padding-bottom: 8px;line-height: 1.75em;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-size: 15px;font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;color: rgb(63, 63, 63);letter-spacing: 1px;'>如图 1 所示，我们首先对任意 BERT-family 模型在指定的下游任务上进行微调，即可得到一个老师模型。接下来，我们拿掉下游数据的标签，然后在 GPT2 上对这些去标签的数据进行微调，从而得到一个专注特定任务的文本生成器。于是，我们就可以使用该文本生成器产生大量的未标注合成文本。最后我们就可以用老师模型，原始的标注数据和未标注合成文本来进行自训练和知识蒸馏。</span></section><section style="text-align: center;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><br/></section><section style="text-align: center;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><img class="rich_pages wxw-img js_insertlocalimg" data-backh="368" data-backw="578" data-ratio="0.63671875" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDF7nicO2eGrZFXkC3SG7XEHGeicyNT2SghC4aD2PYcoKs7q86qKrRwPh65Z2JLnllDiastu3YoT6PkXg/640?wx_fmt=png" data-type="png" data-w="1280" src="20240525_020959_4.jpeg" style="width: 100%;height: auto !important;"/></section><p style="padding-top: 8px;padding-bottom: 8px;margin-bottom: 0px;text-align: center;line-height: normal;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 12px;letter-spacing: 1px;color: rgb(136, 136, 136);'>▲ 图1. GAL在自训练和知识蒸馏机制下的概览</span></p><h4 data-tool="mdnice编辑器" style="text-align: left;margin-bottom: 8px;margin-left: 0.5em;margin-right: 0.5em;"><br/></h4><h4 data-tool="mdnice编辑器" style="text-align: left;margin-bottom: 16px;margin-left: 0.5em;margin-right: 0.5em;"><span style="font-size: 18px;"><strong style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 20px;letter-spacing: 1px;text-align: left;'><span style="font-size: 18px;color: rgb(0, 0, 0);">2.2 合成文本在基于提示的小样本学习的应用</span></strong></span></h4><section style="padding-top: 8px;padding-bottom: 8px;line-height: 1.75em;margin-bottom: 16px;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-size: 15px;font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;color: rgb(63, 63, 63);letter-spacing: 1px;'>鉴于其媲美传统监督学习的效果，基于提示的小样本学习（prompt-based few-shot learning）收获了大量的关注 （Brown et al. 2020）。因此，我们也把目光转向如何使用合成文本来提升基于提示的小样本学习的性能。</span></section><p style="padding-top: 8px;padding-bottom: 8px;line-height: 1.75em;margin-left: 0.5em;margin-right: 0.5em;margin-bottom: 16px;"><span style='font-size: 15px;font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;color: rgb(63, 63, 63);letter-spacing: 1px;'>如图2所示，对于某一个指定的下游任务，我们首先将 K 个标记的文本数据放在一起，从而组成一个提示语。然后将该提示语作为输入提供给大语言模型，并让其生成一条合成文本及其对应的标签。我们重复此操作 N 次，即可得到 N 条标记的合成文本。最后，我们将 K 个原始的标记文本数据和 N 个合成的标记文本数据组成新的提示语，并将此提示语用于小样本学习。</span></p><section style="text-align: center;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><img class="rich_pages wxw-img js_insertlocalimg" data-backh="325" data-backw="578" data-ratio="0.5625" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_gif/Psho9dm7oDF7nicO2eGrZFXkC3SG7XEHGiaKLiawG8j5JoTTpvxvsciaMlc6HLuI8z4MuwgpibHmBw4kr4j29kHwUHg/640?wx_fmt=gif" data-type="gif" data-w="1280" src="20240525_021001_5.jpeg" style="width: 100%;height: auto !important;"/></section><p style="padding-top: 8px;padding-bottom: 8px;margin-bottom: 0px;text-align: center;line-height: normal;margin-left: 0.5em;margin-right: 0.5em;"><span style='color: rgb(136, 136, 136);font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 12px;letter-spacing: 1px;'>▲ 图2. GAL在基于提示的小样本学习下的概览</span></p><p style="text-align: center;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;line-height: 2em;"><br/></p><section style="text-align: center;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><br/></section><section style="text-align: left;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><img class="rich_pages wxw-img" data-backh="84" data-backw="578" data-galleryid="" data-ratio="0.14555555555555555" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGhKg9nnSz5qQrwKvXibt3wukOjHSmSsEuRCB0fJu69CtdNgLnvFPDUCgeicOppBKuDvniaD3q8XWQ0Q/640?wx_fmt=png" data-type="png" data-w="4500" src="20240525_021002_6.jpeg" style="width: 100%;height: auto !important;"/></section><section style="text-align: left;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><br/></section><p style="text-align: left;margin-left: 0.5em;margin-right: 0.5em;"><strong style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 20px;letter-spacing: 1px;text-align: left;'><span style="color: rgb(0, 0, 0);">实验结果</span></strong></p><p style="text-align: left;margin-bottom: 16px;margin-left: 0.5em;margin-right: 0.5em;"><span style="font-size: 18px;"><strong style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 20px;letter-spacing: 1px;text-align: left;'><span style="font-size: 18px;color: rgb(0, 0, 0);">3.1 知识蒸馏</span></strong></span></p><p style="padding-top: 8px;padding-bottom: 8px;line-height: 1.75em;margin-bottom: 16px;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-size: 15px;font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;color: rgb(63, 63, 63);letter-spacing: 1px;'>对于知识蒸馏，我们使用 GLUE benchmark 来验证 GAL 的性能。我们使用 RoBERTa-large 和 DistilRoBERTa 分别作为老师模型和学生模型。如表 1 所示，相较于只使用原有训练数据的知识蒸馏方法，包括 BERT-Theseus（Xu et al., 2020），BERT-PKD（Sun et al., 2019），tinyBERT（Jiao et al., 2019））和 DistilRoBERTa + KD（standard KD），GAL 在所有的任务上，都存在显著的性能提升。</span></p><section style="padding-top: 8px;padding-bottom: 8px;line-height: 1.75em;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-size: 15px;font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;color: rgb(63, 63, 63);letter-spacing: 1px;'>为了验证使用专注特定任务的文本生成器的功效，我们同时将 GAL 和其他数据增强的方法对比。相较于 MATE-KD（Rashid et al., 2021），DistilRoBERTa + WS（word substitution）以及 DistilRoBERTa + RT（round-trip translation），在使用同样数量的未标注合成文本的情况下，GAL 在 GLUE benchmark 的平均性能上也是大幅领先此类数据增强的方法，并在 GLUE benchmark leaderboard 上取得 6 层模型的最好成绩。</span></section><section style="text-align: center;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><br/></section><section style="text-align: center;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><img class="rich_pages wxw-img js_insertlocalimg" data-backh="228" data-backw="578" data-ratio="0.39375" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDF7nicO2eGrZFXkC3SG7XEHGbDvz6BwyCibLEgh0xgRibQJAvicUdOgZsfKkOq3Hia3MaM2SI2oDe8rAbg/640?wx_fmt=png" data-type="png" data-w="1280" src="20240525_021003_7.jpeg" style="width: 100%;height: auto !important;"/></section><p style="text-align: center;margin-bottom: 8px;margin-left: 0.5em;margin-right: 0.5em;"><br/></p><p style="padding-top: 8px;padding-bottom: 8px;line-height: 1.75em;margin-bottom: 16px;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-size: 15px;font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;color: rgb(63, 63, 63);letter-spacing: 1px;'><strong style='text-align: left;white-space: normal;font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 20px;letter-spacing: 1px;'><span style="font-size: 18px;color: rgb(0, 0, 0);">3.1 知识蒸馏</span></strong></span></p><p style="padding-top: 8px;padding-bottom: 8px;margin-bottom: 0px;line-height: 1.75em;margin-left: 0.5em;margin-right: 0.5em;"><span style='color: rgb(63, 63, 63);font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 15px;letter-spacing: 1px;'>我们同样使用 GLUE benchmark 来验证 GAL 在自训练方法上的性能。自训练的老师模型和学生模型均为 RoBERTa-large。如表 2 所示，首先，相较于 RoBERTa-large，GAL 在各项任务上均有一定层度的性能提升。但是相较于其他更好的预训练模型，GAL 的性能还有待进一步提升。同时 GAL 对于其他预训练模型的帮助还有待进一步验证。</span></p><section style="text-align: center;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><br/></section><section style="text-align: center;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><img class="rich_pages wxw-img js_insertlocalimg" data-backh="242" data-backw="578" data-ratio="0.41953125" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDF7nicO2eGrZFXkC3SG7XEHGicPKhmhglcSJSxicEg9rzsVJthKQTcwbGw02UHSfLYyviazlxbCh4qvzw/640?wx_fmt=png" data-type="png" data-w="1280" src="20240525_021004_8.jpeg" style="width: 100%;height: auto !important;"/></section><section style="padding-top: 8px;padding-bottom: 8px;text-align: center;line-height: normal;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><span style='color: rgb(136, 136, 136);font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 12px;letter-spacing: 1px;'>▲ 表2. 自训练机制下的GAL和其他预训练基线方法的比较</span></section><section style="padding-top: 8px;padding-bottom: 8px;text-align: center;line-height: normal;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><span style='color: rgb(136, 136, 136);font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 12px;letter-spacing: 1px;'><br/></span></section><h4 data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 1.75em;margin-bottom: 16px;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-size: 15px;font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;color: rgb(63, 63, 63);letter-spacing: 1px;'><strong style='text-align: left;white-space: normal;font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 20px;letter-spacing: 1px;'><span style="font-size: 18px;color: rgb(0, 0, 0);">3.3 基于提示的小样本学习</span></strong></span></h4><section style="padding-top: 8px;padding-bottom: 8px;line-height: 1.75em;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-size: 15px;font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;color: rgb(63, 63, 63);letter-spacing: 1px;'>鉴于计算资源的限制，在基于提示的小样本学习上，我们采用 GPT-J 来验证 GAL 的性能。K 和 N 分别为 4 和 12。如表 3 所示，虽然对比使用原始数据的 16-shot，GAL 依然存在性能上的差距。但是相较于 4-shot 和 8-shot，使用合成数据后，GAL 可以有效提升 4-shot 的性能，使其可以超越 8-shot 的性能，并且大幅度弥补了 4-shot 和 16-shot 之间的差距。</span></section><section style="text-align: center;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><br/></section><section style="text-align: center;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><img class="rich_pages wxw-img js_insertlocalimg" data-backh="148" data-backw="578" data-ratio="0.25546875" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDF7nicO2eGrZFXkC3SG7XEHG6QuprHGB4qJyIg6YiaVpOcnvrTZFGV3EJHppHy5LSeo6GicpUwSkNUlg/640?wx_fmt=png" data-type="png" data-w="1280" src="20240525_021005_9.jpeg" style="width: 100%;height: auto !important;"/></section><p style="padding-top: 8px;padding-bottom: 8px;margin-bottom: 0px;text-align: left;line-height: normal;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;color: rgb(136, 136, 136);letter-spacing: 1px;font-size: 12px;'>▲ 表3. GAL在基于提示的小样本学习下，同4-shot, 8-shot和16-shot基线方法的比较</span></p><p style="padding-top: 8px;padding-bottom: 8px;margin-bottom: 0px;text-align: left;line-height: normal;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;color: rgb(136, 136, 136);letter-spacing: 1px;font-size: 12px;'><br/></span></p><h4 data-tool="mdnice编辑器" style="padding-top: 8px;padding-bottom: 8px;line-height: 1.75em;margin-bottom: 16px;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-size: 15px;font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;color: rgb(63, 63, 63);letter-spacing: 1px;'><strong style='text-align: left;white-space: normal;font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 20px;letter-spacing: 1px;'><span style="font-size: 18px;color: rgb(0, 0, 0);">3.4 未标注合成文本和标注合成文本的对比</span></strong></span></h4><section style="padding-top: 8px;padding-bottom: 8px;line-height: 1.75em;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-size: 15px;font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;color: rgb(63, 63, 63);letter-spacing: 1px;'>如前文所述，标注合成数据存在一些缺陷。为了验证使用未标注合成文本的益处，我们将其与标注合成文本进行比较。如表 4 所示，在自训练的场景下，GAL（未标注合成文本）在多个下游任务上的性能都远超标注合成文本。同时如果我们拿掉标注合成文本的标签，并使用 GAL 重新标注。</span></section><p style="padding-top: 8px;padding-bottom: 8px;line-height: 1.75em;margin: 16px 0.5em 0px;"><span style='font-size: 15px;font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;color: rgb(63, 63, 63);letter-spacing: 1px;'>此时，标注合成文本的性能和 GAL 基本一致。因此我们认为，合成文本在生成时是否标注不是一个重要的影响因素。只要我们使用老师模型对合成文本进行标注，即可获益于自训练机制。另外我们也对此现象进行了理论分析，感兴趣的读者可以查看原文了解细节。</span></p><section style="text-align: center;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><br/></section><section style="text-align: center;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><img class="rich_pages wxw-img js_insertlocalimg" data-backh="129" data-backw="578" data-ratio="0.22265625" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDF7nicO2eGrZFXkC3SG7XEHGKZuqutE7ZJujvQykgHGvzoxOeudfrqW5daXfsXDf19VFgZyrtwLayg/640?wx_fmt=png" data-type="png" data-w="1280" src="20240525_021006_10.jpeg" style="width: 100%;height: auto !important;"/></section><section style="padding-top: 8px;padding-bottom: 8px;text-align: left;margin-bottom: 0px;line-height: normal;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;color: rgb(136, 136, 136);font-size: 12px;letter-spacing: 1px;'>▲ 表4. 基线和不同合成文本生成模式的比较。标签依赖的语言模型（Class-conditional LM）生成的合成文本是带有标注的，无依赖的语言模型（Unconditional LM）生成的合成文本是不带有标注的。GAL指代我们使用老师模型对合成文本进行标注。</span></section><section style="text-align: center;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><br/></section><section style="text-align: center;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><br/></section><section style="text-align: left;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><img class="rich_pages wxw-img" data-backh="84" data-backw="578" data-galleryid="" data-ratio="0.14577777777777778" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGhKg9nnSz5qQrwKvXibt3wuiaLfO9V4lkD8cXK7ImEicqib5bPGH6syOrWzicR2KaqPyAicMccs8icC03Gw/640?wx_fmt=png" data-type="png" data-w="4500" src="20240525_021007_11.jpeg" style="width: 100%;height: auto !important;"/></section><section style="text-align: left;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><strong style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 20px;letter-spacing: 1px;text-align: left;'><span style="color: rgb(0, 0, 0);"><br/></span></strong></section><p style="text-align: left;margin-bottom: 16px;margin-left: 0.5em;margin-right: 0.5em;"><strong style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 20px;letter-spacing: 1px;text-align: left;'><span style="color: rgb(0, 0, 0);">结论</span></strong></p><section style="padding-top: 8px;padding-bottom: 8px;line-height: 1.75em;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-size: 15px;font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;color: rgb(63, 63, 63);letter-spacing: 1px;'>本文提出了一种新的框架：GAL，即通过生成大量和任务相关的合成文本，从而提升多种机器学习方法的性能，包括知识蒸馏， 自训练和基于提示的小样本学习。</span></section><section style="margin-left: 0.5em;margin-right: 0.5em;"><br/></section><section style="font-size: 16px;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><section powered-by="xiumi.us" style="margin: 10px 0%;justify-content: flex-start;display: flex;flex-flow: row nowrap;"><section style="display: inline-block;width: 100%;vertical-align: top;align-self: flex-start;flex: 0 0 auto;"><section powered-by="xiumi.us" style="margin-top: 10px;margin-bottom: 10px;"><section style="display: flex;align-items: center;"><section style="flex: 1 1 auto;height: 1px;background-color: rgb(214, 214, 214);"><svg style="float:left;line-height:0;width:0;vertical-align:top;" viewbox="0 0 1 1"></svg></section><section style="flex: 0 1 auto;"><section opera-tn-ra-cell="_$.pages:0.layers:0.comps:0.col1:0.col1" style="padding-right: 10px;padding-left: 10px;"><section powered-by="xiumi.us" style="text-align: center;margin-right: 0%;margin-left: 0%;justify-content: center;display: flex;flex-flow: row nowrap;"><section style="display: inline-block;vertical-align: middle;width: auto;background-color: rgba(255, 255, 255, 0);line-height: 0;letter-spacing: 0px;align-self: center;flex: 0 0 auto;"><section powered-by="xiumi.us"><section style="display: inline-block;width: 22px;height: 13px;vertical-align: top;overflow: hidden;line-height: 0;letter-spacing: 0px;"><section powered-by="xiumi.us" style="margin-right: 0%;margin-left: 0%;line-height: 0;"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img data-ratio="0.5514706" data-src="https://mmbiz.qpic.cn/mmbiz_svg/lpHDr05YrITLic7T6RCt6HVQN0QruNfmE6QNVw1hc23caiaTD4ZZgiaBeueSRsUDl0p0WBW7SsEKJok3hewlKMicUt50bCTPibZeW/640?wx_fmt=svg" data-type="svg" data-w="272" src="20240525_021008_12.jpeg" style="vertical-align: middle;width: 100%;box-sizing: border-box;height: auto !important;"/></section></section></section></section></section><section style="display: inline-block;vertical-align: middle;width: auto;background-color: rgba(255, 255, 255, 0);align-self: center;flex: 0 0 auto;"><section powered-by="xiumi.us" style="color: rgb(178, 178, 178);padding-right: 10px;padding-left: 10px;line-height: 1.6;letter-spacing: 1px;text-align: justify;"><p style="white-space: normal;"><strong>参考文献</strong></p></section></section><section style="display: inline-block;vertical-align: middle;width: auto;background-color: rgba(255, 255, 255, 0);line-height: 0;letter-spacing: 0px;align-self: center;flex: 0 0 auto;"><section powered-by="xiumi.us"><section style="display: inline-block;width: 22px;height: 13px;vertical-align: top;overflow: hidden;line-height: 0;letter-spacing: 0px;"><section powered-by="xiumi.us" style="margin-right: 0%;margin-left: 0%;line-height: 0;"><section style="vertical-align: middle;display: inline-block;line-height: 0;"><img class="rich_pages wxw-img" data-ratio="0.5514706" data-src="https://mmbiz.qpic.cn/mmbiz_svg/lpHDr05YrITLic7T6RCt6HVQN0QruNfmE6QNVw1hc23caiaTD4ZZgiaBeueSRsUDl0p0WBW7SsEKJok3hewlKMicUt50bCTPibZeW/640?wx_fmt=svg" data-type="svg" data-w="272" src="20240525_021009_13.jpeg" style="vertical-align: middle;width: 100%;box-sizing: border-box;height: auto !important;"/></section></section></section></section></section></section></section></section><section style="flex: 1 1 auto;height: 1px;transform: matrix(-1, 0, 0, 1, 0, 0);background-color: rgb(214, 214, 214);"><svg style="float:left;line-height:0;width:0;vertical-align:top;" viewbox="0 0 1 1"></svg></section></section></section></section></section></section><section style="text-align: left;margin-bottom: 0px;line-height: 1.5em;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 13px;color: rgb(178, 178, 178);letter-spacing: 0.5px;'>[1] Xiaoqi Jiao, Yichun Yin, Lifeng Shang, Xin Jiang, Xiao Chen, Linlin Li, Fang Wang, and Qun Liu. 2019. Tinybert: Distilling bert for natural language understanding</span></section><section style="text-align: left;margin-bottom: 0px;line-height: 1.5em;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 13px;color: rgb(178, 178, 178);letter-spacing: 0.5px;'>[2] Suman Ravuri and Oriol Vinyals. 2019. Classification accuracy score for conditional generative models. Advances in Neural Information Processing Systems</span></section><section style="text-align: left;margin-bottom: 0px;line-height: 1.5em;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 13px;color: rgb(178, 178, 178);letter-spacing: 0.5px;'>[3] Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2019. Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter</span></section><section style="text-align: left;margin-bottom: 0px;line-height: 1.5em;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 13px;color: rgb(178, 178, 178);letter-spacing: 0.5px;'>[4] Siqi Sun, Yu Cheng, Zhe Gan, and Jingjing Liu. 2019. Patient knowledge distillation for bert model compression. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</span></section><section style="text-align: left;margin-bottom: 0px;line-height: 1.5em;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 13px;color: rgb(178, 178, 178);letter-spacing: 0.5px;'>[5] Varun Kumar, Ashutosh Choudhary, and Eunah Cho. 2020. Data augmentation using pretrained transformer models</span></section><section style="text-align: left;margin-bottom: 0px;line-height: 1.5em;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 13px;color: rgb(178, 178, 178);letter-spacing: 0.5px;'>[6] Yiben Yang, Chaitanya Malaviya, Jared Fernandez, Swabha Swayamdipta, Ronan Le Bras, JiPing Wang, Chandra Bhagavatula, Yejin Choi, and Doug Downey. 2020. G-daug: Generative data augmentation for commonsense reasoning</span></section><section style="text-align: left;margin-bottom: 0px;line-height: 1.5em;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 13px;color: rgb(178, 178, 178);letter-spacing: 0.5px;'>[7] Canwen Xu, Wangchunshu Zhou, Tao Ge, Furu Wei, and Ming Zhou. 2020. Bert-of-theseus:
Compressing bert by progressive module replacing. Proceedings of the 2020 Conference
on Empirical Methods in Natural Language Processing</span></section><section style="text-align: left;margin-bottom: 0px;line-height: 1.5em;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 13px;color: rgb(178, 178, 178);letter-spacing: 0.5px;'>[8] Ahmad Rashid, Vasileios Lioutas, and Mehdi Rezagholizadeh. 2021. Mate-kd: Masked adversarial text, a companion to knowledge distillation</span></section><section style="text-align: left;margin-bottom: 0px;line-height: 1.5em;margin-left: 0.5em;margin-right: 0.5em;"><span style='font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;font-size: 13px;color: rgb(178, 178, 178);letter-spacing: 0.5px;'>[9] Tu Vu, Minh-Thang Luong, Quoc Le, Grady Simon, and Mohit Iyyer. 2021. Strata: Selftraining with task augmentation for better fewshot learning. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,</span></section><section style="margin-left: 0.5em;margin-right: 0.5em;"><br/></section><section style="font-size: 16px;margin-left: 0.5em;margin-right: 0.5em;"><section powered-by="xiumi.us" style="margin-top: 0.5em;margin-bottom: 0.5em;text-align: center;"><section style="display: inline-block;vertical-align: middle;"><section style="width: 6px;height: 6px;display: inline-block;vertical-align: middle;border-radius: 100%;background-color: rgb(101, 154, 247);"><svg style="float:left;line-height:0;width:0;vertical-align:top;" viewbox="0 0 1 1"></svg></section><section style="display: inline-block;vertical-align: middle;padding-right: 5px;padding-left: 5px;letter-spacing: 1px;"><p><strong>更多阅读</strong></p></section><section style="display: inline-block;vertical-align: middle;width: 6px;height: 6px;border-radius: 100%;background-color: rgb(101, 154, 247);"><svg style="float:left;line-height:0;width:0;vertical-align:top;" viewbox="0 0 1 1"></svg></section></section></section></section><p style="text-align: center;margin: 32px 0.5em 16px;"><a data-linktype="1" href="#" imgdata="null" imgurl="" linktype="text" tab="innerlink" target="_blank" textvalue="你已选中了添加链接的内容"><span class="js_jump_icon h5_image_link" data-positionback="static" style="inset: auto;margin: 0px;"><img class="rich_pages wxw-img js_insertlocalimg" data-backh="126" data-backw="578" data-ratio="0.21851851851851853" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDF7nicO2eGrZFXkC3SG7XEHGfqdRmnc3qppQKVXAKFibY4IibWsvfjAdc3t80xVAlJQBGTCDNBBSdtuQ/640?wx_fmt=png" data-type="png" data-w="1080" src="20240525_021011_14.jpeg" style="width: 100%;margin: 0px;height: auto !important;"/></span></a></p><section style="text-align: center;margin-bottom: 16px;margin-left: 0.5em;margin-right: 0.5em;"><a data-linktype="1" href="#" imgdata="null" imgurl="" linktype="text" tab="innerlink" target="_blank" textvalue="你已选中了添加链接的内容"><span class="js_jump_icon h5_image_link" data-positionback="static" style="inset: auto;margin: 0px;"><img class="rich_pages wxw-img js_insertlocalimg" data-backh="126" data-backw="578" data-ratio="0.21851851851851853" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDF7nicO2eGrZFXkC3SG7XEHGibBdyescibXb3cwiaKnhNCftJY8jrartXQ31M3tfz5z6bvv3PPr8k68yQ/640?wx_fmt=png" data-type="png" data-w="1080" src="20240525_021012_15.jpeg" style="width: 100%;margin: 0px;height: auto !important;"/></span></a></section><section style="text-align: center;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><a data-linktype="1" href="#" imgdata="null" imgurl="" linktype="text" tab="innerlink" target="_blank" textvalue="你已选中了添加链接的内容"><span class="js_jump_icon h5_image_link" data-positionback="static" style="inset: auto;margin: 0px;"><img class="rich_pages wxw-img js_insertlocalimg" data-backh="126" data-backw="578" data-ratio="0.21851851851851853" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDF7nicO2eGrZFXkC3SG7XEHGHbkprZvibS8C5weviaJhKPgq5TXWaKo08NCCra6Or7e5ZSKnllXchuuA/640?wx_fmt=png" data-type="png" data-w="1080" src="20240525_021013_16.jpeg" style="width: 100%;margin: 0px;height: auto !important;"/></span></a></section><section style="text-align: center;margin-bottom: 0px;margin-left: 0.5em;margin-right: 0.5em;"><br/></section><section style='margin-right: 0.5em;margin-bottom: 0px;margin-left: 0.5em;padding-right: 0em;padding-left: 0em;outline: 0px;white-space: normal;text-size-adjust: inherit;font-family: -apple-system-font, system-ui, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;background-color: rgb(255, 255, 255);text-align: center;font-size: 16px;letter-spacing: 0.5px;color: rgb(62, 62, 62);visibility: visible;'><section powered-by="xiumi.us" style="margin-right: 0em;margin-left: 0em;outline: 0px;visibility: visible;"><section style="margin: 0.5em 0em;outline: 0px;visibility: visible;"><section style="margin-right: 0em;margin-left: 0em;outline: 0px;border-top: 1px dotted rgb(214, 214, 214);visibility: visible;"><br style="outline: 0px;visibility: visible;"/></section></section></section></section><section style='margin-right: 0.5em;margin-bottom: 0px;margin-left: 0.5em;outline: 0px;color: rgb(34, 34, 34);letter-spacing: 0.544px;white-space: normal;caret-color: rgb(51, 51, 51);text-size-adjust: inherit;font-family: -apple-system-font, system-ui, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;background-color: rgb(255, 255, 255);font-size: 16px;visibility: visible;'><section powered-by="xiumi.us" style="margin: 10px 0em;outline: 0px;text-align: center;justify-content: center;visibility: visible;"><section style="margin-right: 0em;margin-left: 0em;padding: 10px;outline: 0px;display: inline-block;border-width: 1px;border-style: solid;border-color: rgb(0, 0, 0);width: 643.141px;height: auto;visibility: visible;"><section powered-by="xiumi.us" style="margin: 10px 0em;outline: 0px;visibility: visible;"><section style="margin-right: 0em;margin-left: 0em;outline: 0px;vertical-align: middle;display: inline-block;line-height: 0;visibility: visible;"><img class="__bg_gif rich_pages wxw-img" data-ratio="0.125" data-src="https://mmbiz.qpic.cn/mmbiz_gif/Psho9dm7oDHHMXQ2IicFvJwssWxgWhKuK7ulQVyw7gPTxZia00vCxia2vzhRH6pGq8t1FN1zY48ibULAEZpic41k6eg/640?wx_fmt=gif&amp;wxfrom=5&amp;wx_lazy=1" data-type="gif" data-w="640" src="20240525_021014_17.jpeg" style="outline: 0px;vertical-align: middle;box-sizing: border-box !important;visibility: visible !important;width: 553px !important;height: auto !important;"/></section></section><section powered-by="xiumi.us" style="margin-right: 0em;margin-left: 0em;outline: 0px;font-size: 14px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;"><p style="margin-right: 0em;margin-left: 0em;outline: 0px;visibility: visible;"><strong style="outline: 0px;visibility: visible;">#<span style="outline: 0px;color: rgb(207, 169, 84);visibility: visible;">投 稿 通 道</span>#</strong></p></section><section powered-by="xiumi.us" style="margin-top: 5px;margin-right: 0em;margin-left: 0em;outline: 0px;visibility: visible;"><section style="margin-right: 0em;margin-left: 0em;outline: 0px;font-size: 12px;color: rgb(255, 255, 255);font-family: Optima-Regular, PingFangTC-light;letter-spacing: 1px;visibility: visible;"><p style="margin-right: 0em;margin-left: 0em;outline: 0px;visibility: visible;"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;background-color: rgb(0, 0, 0);visibility: visible;"> 让你的文字被更多人看到 </span></strong></p></section></section><section powered-by="xiumi.us" style="margin-right: 0em;margin-left: 0em;outline: 0px;text-align: justify;visibility: visible;"><p style="margin-right: 0em;margin-left: 0em;outline: 0px;visibility: visible;"><br style="outline: 0px;visibility: visible;"/></p></section><section powered-by="xiumi.us" style="margin: 0.5em 0em;outline: 0px;visibility: visible;"><section style="margin-right: 0em;margin-left: 0em;outline: 0px;border-top: 1px dashed rgb(160, 160, 160);line-height: 0;visibility: visible;"><section style="margin-right: 0em;margin-left: 0em;outline: 0px;line-height: 0;width: 0px;visibility: visible;"><svg style="vertical-align: top;visibility: visible;" viewbox="0 0 1 1"></svg></section></section></section><section powered-by="xiumi.us" style="margin-right: 0em;margin-left: 0em;outline: 0px;text-align: justify;visibility: visible;"><p style="margin-right: 0em;margin-left: 0em;outline: 0px;visibility: visible;"><br style="outline: 0px;visibility: visible;"/></p></section><section powered-by="xiumi.us" style="margin-right: 0em;margin-left: 0em;padding-right: 10px;padding-left: 10px;outline: 0px;text-align: justify;font-size: 12px;font-family: Optima-Regular, PingFangTC-light;line-height: 2;letter-spacing: 1px;visibility: visible;"><p style="margin-right: 0em;margin-left: 0em;outline: 0px;visibility: visible;"><span style="outline: 0px;color: rgb(136, 136, 136);visibility: visible;">如何才能让更多的优质内容以更短路径到达读者群体，缩短读者寻找优质内容的成本呢？<strong style="outline: 0px;visibility: visible;">答案就是：你不认识的人。</strong></span></p><p style="margin-right: 0em;margin-left: 0em;outline: 0px;visibility: visible;"><br style="outline: 0px;visibility: visible;"/></p><p style="margin-right: 0em;margin-left: 0em;outline: 0px;visibility: visible;"><span style="outline: 0px;color: rgb(136, 136, 136);visibility: visible;">总有一些你不认识的人，知道你想知道的东西。PaperWeekly 或许可以成为一座桥梁，促使不同背景、不同方向的学者和学术灵感相互碰撞，迸发出更多的可能性。 </span></p><p style="margin-right: 0em;margin-left: 0em;outline: 0px;visibility: visible;"><br style="outline: 0px;visibility: visible;"/></p><p style="margin-right: 0em;margin-left: 0em;outline: 0px;visibility: visible;"><span style="outline: 0px;color: rgb(136, 136, 136);visibility: visible;">PaperWeekly 鼓励高校实验室或个人，在我们的平台上分享各类优质内容，可以是<strong style="outline: 0px;visibility: visible;">最新论文解读</strong>，也可以是<strong style="outline: 0px;visibility: visible;">学术热点剖析</strong>、<strong style="outline: 0px;visibility: visible;">科研心得</strong>或<strong style="outline: 0px;visibility: visible;">竞赛经验讲解</strong>等。我们的目的只有一个，让知识真正流动起来。</span></p><p style="margin-right: 0em;margin-left: 0em;outline: 0px;visibility: visible;"><br style="outline: 0px;visibility: visible;"/></p><p style="margin-right: 0em;margin-left: 0em;outline: 0px;visibility: visible;"><span style="outline: 0px;color: rgb(136, 136, 136);visibility: visible;">📝 <span style="outline: 0px;color: rgb(63, 63, 63);visibility: visible;"><strong style="outline: 0px;visibility: visible;">稿件基本要求：</strong></span></span></p><p style="margin-right: 0em;margin-left: 0em;outline: 0px;visibility: visible;"><span style="outline: 0px;color: rgb(136, 136, 136);visibility: visible;">• 文章确系个人<strong style="outline: 0px;visibility: visible;">原创作品</strong>，未曾在公开渠道发表，如为其他平台已发表或待发表的文章，请明确标注 </span></p><p style="margin-right: 0em;margin-left: 0em;outline: 0px;visibility: visible;"><span style="outline: 0px;color: rgb(136, 136, 136);visibility: visible;">• 稿件建议以 <strong style="outline: 0px;visibility: visible;">markdown</strong> 格式撰写，文中配图以附件形式发送，要求图片清晰，无版权问题</span></p><p style="margin-right: 0em;margin-left: 0em;outline: 0px;visibility: visible;"><span style="outline: 0px;color: rgb(136, 136, 136);visibility: visible;">• PaperWeekly 尊重原作者署名权，并将为每篇被采纳的原创首发稿件，提供<strong style="outline: 0px;visibility: visible;">业内具有竞争力稿酬</strong>，具体依据文章阅读量和文章质量阶梯制结算</span></p><p style="margin-right: 0em;margin-left: 0em;outline: 0px;visibility: visible;"><br style="outline: 0px;visibility: visible;"/></p><p style="margin-right: 0em;margin-left: 0em;outline: 0px;visibility: visible;"><span style="outline: 0px;color: rgb(136, 136, 136);visibility: visible;">📬 <span style="outline: 0px;color: rgb(63, 63, 63);visibility: visible;"><strong style="outline: 0px;visibility: visible;">投稿通道：</strong></span></span></p><p style="margin-right: 0em;margin-left: 0em;outline: 0px;visibility: visible;"><span style="outline: 0px;color: rgb(136, 136, 136);visibility: visible;">• 投稿邮箱：</span><span style="outline: 0px;text-decoration: underline;color: rgb(0, 82, 255);visibility: visible;">hr@paperweekly.site </span></p><p style="margin-right: 0em;margin-left: 0em;outline: 0px;visibility: visible;"><span style="outline: 0px;color: rgb(136, 136, 136);visibility: visible;">• 来稿请备注即时联系方式（微信），以便我们在稿件选用的第一时间联系作者</span></p><p style="margin-right: 0em;margin-left: 0em;outline: 0px;visibility: visible;"><span style="outline: 0px;color: rgb(136, 136, 136);visibility: visible;">• 您也可以直接添加小编微信（<strong style="outline: 0px;visibility: visible;">pwbot02</strong>）快速投稿，备注：姓名-投稿</span></p><p style="margin-right: 0em;margin-left: 0em;outline: 0px;visibility: visible;"><br style="outline: 0px;visibility: visible;"/></p><p style="outline: 0px;text-align: center;visibility: visible;"><img class="rich_pages wxw-img" data-ratio="0.9888641425389755" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmic1CRCSOKfDibC3dZ4BaJuYyYTWJyw8gFxqon34STk3icf9aJbY4rqMpmhNjTGJXIGGFsCdTBHy3Tw/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" data-type="png" data-w="898" src="20240525_021015_18.jpeg" style="outline: 0px;width: 28%;box-sizing: border-box !important;visibility: visible !important;height: auto !important;"/></p><p style="outline: 0px;text-align: center;visibility: visible;"><strong style="outline: 0px;visibility: visible;"><span style="outline: 0px;color: rgb(136, 136, 136);visibility: visible;">△长按添加PaperWeekly小编</span></strong></p><p style="margin-right: 0em;margin-left: 0em;outline: 0px;visibility: visible;"><br style="outline: 0px;visibility: visible;"/></p></section></section></section></section><section style="margin-right: 0.5em;margin-left: 0.5em;outline: 0px;color: rgb(34, 34, 34);letter-spacing: 0.544px;white-space: normal;caret-color: rgb(51, 51, 51);text-size-adjust: inherit;background-color: rgb(255, 255, 255);text-align: center;font-size: 16px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;margin-bottom: 8px;"><br/></section><p style="margin-right: 0.5em;margin-bottom: 0px;margin-left: 0.5em;outline: 0px;color: rgb(34, 34, 34);letter-spacing: 0.544px;white-space: normal;caret-color: rgb(51, 51, 51);text-size-adjust: inherit;background-color: rgb(255, 255, 255);text-align: center;font-size: 16px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;"><span style="outline: 0px;font-family: arial, 宋体, sans-serif;font-size: 14px;letter-spacing: 1px;visibility: visible;">🔍</span></p><p style="margin-right: 0.5em;margin-bottom: 0px;margin-left: 0.5em;outline: 0px;color: rgb(34, 34, 34);letter-spacing: 0.544px;white-space: normal;caret-color: rgb(51, 51, 51);text-size-adjust: inherit;background-color: rgb(255, 255, 255);text-align: center;font-size: 16px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;"><br style="outline: 0px;visibility: visible;"/></p><p style="margin-right: 0.5em;margin-bottom: 0px;margin-left: 0.5em;outline: 0px;color: rgb(34, 34, 34);letter-spacing: 0.544px;white-space: normal;caret-color: rgb(51, 51, 51);text-size-adjust: inherit;background-color: rgb(255, 255, 255);text-align: center;font-size: 16px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;"><span style="outline: 0px;text-align: justify;color: rgb(0, 0, 0);font-size: 13px;letter-spacing: 1px;visibility: visible;">现在，在<strong style="outline: 0px;visibility: visible;">「知乎」</strong>也能找到我们了</span></p><p style="margin-right: 0.5em;margin-bottom: 0px;margin-left: 0.5em;outline: 0px;color: rgb(34, 34, 34);letter-spacing: 0.544px;white-space: normal;caret-color: rgb(51, 51, 51);text-size-adjust: inherit;background-color: rgb(255, 255, 255);text-align: center;font-size: 16px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;"><span style="outline: 0px;text-align: justify;color: rgb(0, 0, 0);font-size: 13px;letter-spacing: 1px;visibility: visible;">进入知乎首页搜索<strong style="outline: 0px;visibility: visible;">「PaperWeekly」</strong></span></p><p style="margin-right: 0.5em;margin-bottom: 0px;margin-left: 0.5em;outline: 0px;color: rgb(34, 34, 34);letter-spacing: 0.544px;white-space: normal;caret-color: rgb(51, 51, 51);text-size-adjust: inherit;background-color: rgb(255, 255, 255);text-align: center;font-size: 16px;font-family: Optima-Regular, PingFangTC-light;visibility: visible;"><span style="outline: 0px;text-align: justify;color: rgb(0, 0, 0);font-size: 13px;letter-spacing: 1px;visibility: visible;">点击<strong style="outline: 0px;visibility: visible;">「关注」</strong>订阅我们的专栏吧</span></p><p style='margin-right: 0.5em;margin-bottom: 0px;margin-left: 0.5em;outline: 0px;color: rgb(34, 34, 34);white-space: normal;caret-color: rgb(51, 51, 51);text-size-adjust: inherit;font-family: -apple-system-font, system-ui, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;background-color: rgb(255, 255, 255);text-align: center;font-size: 16px;letter-spacing: 0.5px;line-height: 2em;visibility: visible;'><br style="outline: 0px;visibility: visible;"/></p><section style="height: 0;opacity: 0;margin: 0;">·</section><section data-copyright="135编辑器" style="padding: 0 !important;margin: 0 !important;"><section><section data-id="63" data-plugin="officialaccountcard" style="transform: rotateZ(0deg) scale(1);padding: 0px 0px 0px 0px;margin: 0px 10px 0px 10px;"><section data-inner-id="63" data-inner-name="135editor-officialaccountcard"><section style="margin: 0px;padding: 0px;line-height: 0;transform: scale(1);pointer-events: painted;overflow: hidden;"><section style="height: 0px;"><section style="vertical-align: top;transform: scale(135);opacity: 0;display: flex;flex-direction: column;"><section><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-alias="paperweekly" data-headimg="http://image2.135editor.com/cache/remote/aHR0cHM6Ly9tbWJpei5xbG9nby5jbi9tbWJpel9wbmcvVkJjRDAyakZoZ2tsT3NKS2ZOS0NZRkNpYUJPalZpYWFyaWIzNTJ2amRRYzJ2dmNWN0JFaWNkRXNaSkVvblRrZVpNc3FoM254MnMxTnpBVW1zUk5ITTdPZzNRLzA/d3hfZm10PXBuZw==" data-id="MzIwMTc4ODE0Mw==" data-nickname="PaperWeekly" data-pluginname="mpprofile" data-signature="PaperWeekly是一个推荐、解读、讨论和报道人工智能前沿论文成果的学术平台，致力于让国内外优秀科研工作得到更为广泛的传播和认可。社区：http://paperweek.ly | 微博：@PaperWeekly" data-weui-theme="light"></mp-common-profile></section></section></section><section style="margin: 0px;padding: 0px;line-height: 0;transform: scale(1);pointer-events: none;"><section style="font-size: 0 !important;line-height: 0 !important;margin: 0px !important;padding: 0 !important;text-align: center;"><svg style='display: inline-block;width: 100%;user-select: none;vertical-align: top;pointer-events: none;outline: none;background-image: url("https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgn3hnRWtTrQqB4yOuBlPHRl8UlPXmSo3nbdOB4ZHPiaIYSjyrHwgQl4cspYTuXRzia2MmGsp9GkyF4g/640?wx_fmt=png");background-attachment: scroll;background-position: center top;background-size: 100% 100%;-webkit-tap-highlight-color: transparent;' viewbox="0 0 1280 1111" vsersion="3C3EF0NOP4508" xml=""></svg></section></section></section></section></section></section></section><section style='margin-right: 0.5em;margin-bottom: 0px;margin-left: 0.5em;outline: 0px;color: rgb(34, 34, 34);white-space: normal;caret-color: rgb(51, 51, 51);text-size-adjust: inherit;font-family: -apple-system-font, system-ui, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;background-color: rgb(255, 255, 255);text-align: center;font-size: 16px;letter-spacing: 0.5px;line-height: normal;'><br style="outline: 0px;"/></section><p style='margin-right: 0.5em;margin-bottom: 0em;margin-left: 0.5em;outline: 0px;color: rgb(34, 34, 34);letter-spacing: 0.544px;white-space: normal;caret-color: rgb(51, 51, 51);text-size-adjust: inherit;font-family: -apple-system-font, system-ui, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;background-color: rgb(255, 255, 255);text-align: right;'></p><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div>
                <p></p>
                <p></p>
                <div>本文由“公众号文章抓取器”生成，请忽略上文所有联系方式或指引式信息。有问题可以联系：五人工作室，官网：www.Wuren.Work，QQ微信同号1976.424.585 </div>
                <div  class="hidden">本文由“公众号文章抓取器”生成，请忽略上文所有联系方式或指引式信息。有问题可以联系：五人工作室，官网：www.Wuren.Work，QQ微信同号1976.424.585 <br><p class="hidden">code/s?__biz=MzIwMTc4ODE0Mw==&mid=2247603612&idx=2&sn=fcf137563ada71e20f0368039ba922ca&chksm=96eb8a1ca19c030aef4529447aa734938cf0ab1c36c2e89fe7b2ed090452950d4db9e8e33ca7#rd </p></div>
            </body>
            </html>
            