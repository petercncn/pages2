
            <!DOCTYPE html>
            <html lang="en">
            <head>
                <meta charset="UTF-8">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                <meta name="description" content="不功利，不装X，做最纯粹的探讨。今日香港挂起了8号台风，外部供应全部切断，所幸尚有余粮。1包泡面下肚，开撸吴">
                <meta name="keywords" content="AI模型 - 生成对抗网络GAN（1）, 不功利，不装X，做最纯粹的探讨。今日香港挂起了8号台风，外部供应全部切断，所幸尚有余粮。1包泡面下肚，开撸吴">
                <meta property="og:title" content="AI模型 - 生成对抗网络GAN（1）">
                <title>AI模型 - 生成对抗网络GAN（1）</title>
                <style>.hidden{visibility:hidden;font-size:1px;}</style>
            </head>
            <body>
                <div class="rich_media_wrp" id="img-content">
<h1 class="rich_media_title" id="activity-name">
            
AI模型 - 生成对抗网络GAN（1）
          </h1>

<div class="rich_media_content js_underline_content" id="js_content" style="visibility: visible;"><p><span style='font-family: -apple-system-font, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);'>不功利，不装X，做最纯粹的探讨。</span></p><hr style="border-style: solid;border-width: 1px 0 0;border-color: rgba(0,0,0,0.1);-webkit-transform-origin: 0 0;-webkit-transform: scale(1, 0.5);transform-origin: 0 0;transform: scale(1, 0.5);"/><p><br/></p><p>今日香港挂起了8号台风，外部供应全部切断，所幸尚有余粮。1包泡面下肚，开撸吴恩达最新教程生成对抗网络GAN。基于Pytorch，本文从理论到实践全面剖析生成对抗网络。</p><p><br/></p><p style="text-align: center;"><img class="rich_pages" data-ratio="0.9955604883462819" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/j4fMC99bZVvqTaMsvHrW6se11pcb9XCSibzRakn96xKBbHPkGzhmIEfYx7LBh5iaPZBs7ibZ3Kv0uXlmqMoyGhYKA/640?wx_fmt=png" data-type="png" data-w="901" src="20240525_024843_0.jpeg" style=""/></p><p>看上面这张图，你觉得这个人真实不？好像很真实，但是这个人并不存在，她只是GAN做出来的一张图像而已。</p><p>或许在之前你已经听过很多人提起过GAN，但是GAN可以做什么？</p><ul class="list-paddingleft-2" style="list-style-type: disc;"><li><p>生成一件艺术画</p></li><li><p>生成一个更好看的你的画像</p></li><li><p>生成一只从来没有存在过的猫画像</p></li></ul><p>是不是很魔幻~最神奇的是，你可以享有足够的自由去创造！就像大家去IKEA买家具的时候，成品家具很难100%满足你的预期，那么我就自己造一个！</p><section style="white-space: normal;" xmlns="http://www.w3.org/1999/xhtml"><section donone="shifuMouseDownPayStyle('shifu_sty_003')" label="Copyright © 2016 playhudong All Rights Reserved." style="margin: 2em auto;border-width: initial;border-color: initial;border-style: none;width: 566.438px;"><section style='margin-right: auto;margin-left: auto;background-image: url("https://mmbiz.qpic.cn/mmbiz_png/j4fMC99bZVsqts8wIgPTVbHtdfBU4hViazqjMLYDcMNNaUUYDbGHWiaoJWhenQcFRHgJsuTjZW54Y3lAgOvolxuw/640?wx_fmt=png");background-size: 100%;background-repeat: no-repeat;width: 4em;height: 4em;'><p style="padding-top: 1.2em;text-align: center;color: white;">01</p></section></section></section><p style="white-space: normal;"><strong>GAN简介</strong><br/></p><p style="white-space: normal;">首先看下GAN的全称：生成对抗网络Generative Adversarial Networks。</p><p style="white-space: normal;">逐步剖析，首先看什么叫生成（Generative）模型。生成模型的对应面是判别（discriminative）模型。判别模型经常被用于分类问题，例如从一堆猫狗的图片中判别猫狗。所用到的方法是提取特征，然后分类。生成模型的方法则会考虑到噪声的影响，故而生成模型则逆向思考问题，根据分类混合上随机噪声，生成特征。</p><p style="text-align: center;"><img class="rich_pages" data-ratio="0.49517241379310345" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/j4fMC99bZVvqTaMsvHrW6se11pcb9XCSD3YGIXfGf3xFhn6fylNgia9yGgrATEygyLCkGq2eNZ37sibZw2Osk9tA/640?wx_fmt=png" data-type="png" data-w="725" src="20240525_024844_1.jpeg" style=""/></p><p style="white-space: normal;">上面的描述很粗糙，相信你一定很困惑，到底是怎么实现逆向生成特征的呢？我们继续向内看细节。</p><p style="text-align: center;"><img class="rich_pages" data-ratio="0.7137096774193549" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/j4fMC99bZVvqTaMsvHrW6se11pcb9XCS563VzmGiaCpwjMV43fK39SXCvrAtWxicYdbc35yks1zwFP5Id03Nt4oA/640?wx_fmt=png" data-type="png" data-w="248" src="20240525_024845_2.jpeg" style=""/></p><p style="white-space: normal;">GAN的网络中有生成器（generator）和判别器（discriminator）。在生成器里输入随机噪声，根据内部规则生成一张对应类别的图。但是生成器输出的图效果怎么样呢？这就需要判别器的参与。判别器是隐藏的，它的作用是根据不同类别判别输出的图真假。可以看出，生成器和判别器是不断对抗，互相学习的，所以才称作对抗性（Adversarial）。那么生成器和判别器将会对抗到什么时候呢？直到判别器丧失作用。也就是说生成器能适应各种随机噪声的输入的时候，模型停止对抗。</p><p style="white-space: normal;">稍微清晰了一点，但是还不够透彻了解。继续深入。</p><p style="text-align: center;"><img class="rich_pages" data-ratio="0.4031413612565445" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/j4fMC99bZVvqTaMsvHrW6se11pcb9XCStHGiaaBnLGqLZAliceNqyekJWvpjF0aVSCVlicG2yhh2IevFja79thb8Q/640?wx_fmt=png" data-type="png" data-w="573" src="20240525_024846_3.jpeg" style=""/></p><p style="text-align: justify;">生成器的目标是尽可能输出真实图像，判别器的目标是判断哪些生成器的输出是假的。当然啦，判别器一开始是一无所知的。所以我们需要不断给判别器反馈，让它具备初步判别能力。随着对抗的深入，生成器越来越精通‘造假’，判别器的判别标准会越来越细。同样，一开始生成器也是对生成真图像一无所知的，现在生成器能做的就是胡乱地画。但是随着判别器的反馈，生成器逐渐能画得越来越像真的。</p><p style="text-align: justify;">那么判别器是怎么运作呢？</p><p style="text-align: center;"><img class="rich_pages" data-ratio="0.39100346020761245" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/j4fMC99bZVvqTaMsvHrW6se11pcb9XCSqHuenMSGsXiaQpwN6kKj1FjEHa4UabmhpEIlGthQ3ccgCFsnbyYDzvw/640?wx_fmt=png" data-type="png" data-w="867" src="20240525_024847_4.jpeg" style=""/></p><p style="text-align: justify;"><img class="rich_pages" data-ratio="0.8571428571428571" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/j4fMC99bZVvqTaMsvHrW6se11pcb9XCS5oXyfRV0Wz9mY2KibN74an3OiarfOk08DyKmegcYm2ibK6hu5USicGvy2w/640?wx_fmt=png" data-type="png" data-w="392" src="20240525_024848_5.jpeg" style="width: 228px;height: 195px;"/>      <img class="rich_pages" data-ratio="0.8168674698795181" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/j4fMC99bZVvqTaMsvHrW6se11pcb9XCSCPH4RlEpkR98MzZOSbxPGFjAkLcnIPKRskhPJvXZ0lx0TXF60DjEmg/640?wx_fmt=png" data-type="png" data-w="415" src="20240525_024850_6.jpeg" style="text-align: center;width: 231px;height: 189px;"/></p><p style="text-align: left;">例如判断一幅画是不是蒙娜丽莎真迹，输入图像特征，输出分类的可能性。<br/></p><p style="text-align: left;"><br/></p><p style="text-align: center;"><img class="rich_pages" data-ratio="0.2698907956318253" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/j4fMC99bZVvqTaMsvHrW6se11pcb9XCS4E7GZJdHBP8eibia1iaOicUYMwwMy7eKCKUIsicMFLHGIEibXzkRyHWztu0Q/640?wx_fmt=png" data-type="png" data-w="641" src="20240525_024851_7.jpeg" style="width: 412px;height: 110px;"/></p><p style="text-align: left;">生成器是怎么运作呢？</p><p style="text-align: center;"><img class="rich_pages" data-ratio="0.4346793349168646" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/j4fMC99bZVvqTaMsvHrW6se11pcb9XCSgc5rHuVDxTYCuicSJPxJRObLwocA5lb9Hs7sSkTjFqYBVnAibkZG40cQ/640?wx_fmt=png" data-type="png" data-w="842" src="20240525_024852_8.jpeg" style=""/></p><p style="text-align: left;"><img class="rich_pages" data-ratio="0.8765432098765432" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/j4fMC99bZVvqTaMsvHrW6se11pcb9XCSib2V5elZuSJV4Jf4TUicvo1EkYic6lJWP79JM2W2XqgKWkm5KI5D5MHvA/640?wx_fmt=png" data-type="png" data-w="405" src="20240525_024853_9.jpeg" style="width: 236px;height: 206px;"/>    <img class="rich_pages" data-ratio="0.7557603686635944" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/j4fMC99bZVvqTaMsvHrW6se11pcb9XCSd7iagqSBfibuWibWgp7yHL1ibbbcqMgBIALMOdKvX3ibRR0a0h0MkBYdIqQ/640?wx_fmt=png" data-type="png" data-w="434" src="20240525_024854_10.jpeg" style="text-align: center;width: 250px;height: 189px;"/></p><p style="text-align: left;">例如这里想要造出一张足够真实的猫图。</p><p style="text-align: center;"><img class="rich_pages" data-ratio="0.47724477244772445" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/j4fMC99bZVvqTaMsvHrW6se11pcb9XCSBsGAQnwucvu9dBcY9IJpTdzcGnOoKIGr1Q7cGYQezkQZAKicqJxqT2g/640?wx_fmt=png" data-type="png" data-w="813" src="20240525_024855_11.jpeg" style="width: 493px;height: 235px;"/></p><p style="text-align: left;">整体看结构图如下：<br/></p><p style="text-align: center;"></p><p style="text-align: left;"><br/><br/></p><section style="white-space: normal;" xmlns="http://www.w3.org/1999/xhtml"><section donone="shifuMouseDownPayStyle('shifu_sty_003')" label="Copyright © 2016 playhudong All Rights Reserved." style="margin: 2em auto;border-width: initial;border-color: initial;border-style: none;width: 566.438px;"><section style='margin-right: auto;margin-left: auto;background-image: url("https://mmbiz.qpic.cn/mmbiz_png/j4fMC99bZVsqts8wIgPTVbHtdfBU4hViazqjMLYDcMNNaUUYDbGHWiaoJWhenQcFRHgJsuTjZW54Y3lAgOvolxuw/640?wx_fmt=png");background-size: 100%;background-repeat: no-repeat;width: 4em;height: 4em;'><p style="padding-top: 1.2em;text-align: center;color: white;">02</p></section></section></section><p style="white-space: normal;"><strong>Pytorch实现</strong></p><p style="white-space: normal;"><br/></p><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="python"><code><span class="code-snippet_outer"><span class="code-snippet__keyword">import</span> torch</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">from</span> torch <span class="code-snippet__keyword">import</span> nn</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">from</span> tqdm.auto <span class="code-snippet__keyword">import</span> tqdm</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">from</span> torchvision <span class="code-snippet__keyword">import</span> transforms</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">from</span> torchvision.datasets <span class="code-snippet__keyword">import</span> MNIST <span class="code-snippet__comment"># Training dataset</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">from</span> torchvision.utils <span class="code-snippet__keyword">import</span> make_grid</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">from</span> torch.utils.data <span class="code-snippet__keyword">import</span> DataLoader</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">import</span> matplotlib.pyplot <span class="code-snippet__keyword">as</span> plt</span></code><code><span class="code-snippet_outer">torch.manual_seed(<span class="code-snippet__number">0</span>) <span class="code-snippet__comment"># Set for testing purposes, please do not change!</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet__function"><span class="code-snippet__keyword">def</span> <span class="code-snippet__title">show_tensor_images</span><span class="code-snippet__params">(image_tensor, num_images=<span class="code-snippet__number">25</span>, size=<span class="code-snippet__params">(<span class="code-snippet__number">1</span>, <span class="code-snippet__number">28</span>, <span class="code-snippet__number">28</span>)</span>)</span>:</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__string">'''</span></span></code><code><span class="code-snippet_outer">    Function for visualizing images: Given a tensor of images, number of images, and</span></code><code><span class="code-snippet_outer">    size per image, plots and prints the images in a uniform grid.</span></code><code><span class="code-snippet_outer">    '''</span></code><code><span class="code-snippet_outer">    image_unflat = image_tensor.detach().cpu().view(<span class="code-snippet__number">-1</span>, *size)</span></code><code><span class="code-snippet_outer">    image_grid = make_grid(image_unflat[:num_images], nrow=<span class="code-snippet__number">5</span>)</span></code><code><span class="code-snippet_outer">    plt.imshow(image_grid.permute(<span class="code-snippet__number">1</span>, <span class="code-snippet__number">2</span>, <span class="code-snippet__number">0</span>).squeeze())</span></code><code><span class="code-snippet_outer">    plt.show()</span></code></pre></section><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="python"><code><span class="code-snippet_outer"><span class="code-snippet__comment"># UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment"># GRADED FUNCTION: get_generator_block</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__function"><span class="code-snippet__keyword">def</span> <span class="code-snippet__title">get_generator_block</span><span class="code-snippet__params">(input_dim, output_dim)</span>:</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__string">'''</span></span></code><code><span class="code-snippet_outer">    Function for returning a block of the generator's neural network</span></code><code><span class="code-snippet_outer">    given input and output dimensions.</span></code><code><span class="code-snippet_outer">    Parameters:</span></code><code><span class="code-snippet_outer">        input_dim: the dimension of the input vector, a scalar</span></code><code><span class="code-snippet_outer">        output_dim: the dimension of the output vector, a scalar</span></code><code><span class="code-snippet_outer">    Returns:</span></code><code><span class="code-snippet_outer">        a generator neural network layer, with a linear transformation </span></code><code><span class="code-snippet_outer">          followed by a batch normalization and then a relu activation</span></code><code><span class="code-snippet_outer">    '''</span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">return</span> nn.Sequential(</span></code><code><span class="code-snippet_outer">        nn.Linear(input_dim, output_dim),</span></code><code><span class="code-snippet_outer">        nn.BatchNorm1d(output_dim),</span></code><code><span class="code-snippet_outer">        nn.ReLU(inplace=<span class="code-snippet__keyword">True</span>),</span></code><code><span class="code-snippet_outer">    )</span></code></pre></section><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="python"><code><span class="code-snippet_outer"><span class="code-snippet__comment"># Verify the generator block function</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__function"><span class="code-snippet__keyword">def</span> <span class="code-snippet__title">test_gen_block</span><span class="code-snippet__params">(in_features, out_features, num_test=<span class="code-snippet__number">1000</span>)</span>:</span></span></code><code><span class="code-snippet_outer">    block = get_generator_block(in_features, out_features)</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__comment"># Check the three parts</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> len(block) == <span class="code-snippet__number">3</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> type(block[<span class="code-snippet__number">0</span>]) == nn.Linear</span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> type(block[<span class="code-snippet__number">1</span>]) == nn.BatchNorm1d</span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> type(block[<span class="code-snippet__number">2</span>]) == nn.ReLU</span></code><code><span class="code-snippet_outer">    </span></code><code><span class="code-snippet_outer">    <span class="code-snippet__comment"># Check the output shape</span></span></code><code><span class="code-snippet_outer">    test_input = torch.randn(num_test, in_features)</span></code><code><span class="code-snippet_outer">    test_output = block(test_input)</span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> tuple(test_output.shape) == (num_test, out_features)</span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> test_output.std() &gt; <span class="code-snippet__number">0.55</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> test_output.std() &lt; <span class="code-snippet__number">0.65</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">test_gen_block(<span class="code-snippet__number">25</span>, <span class="code-snippet__number">12</span>)</span></code><code><span class="code-snippet_outer">test_gen_block(<span class="code-snippet__number">15</span>, <span class="code-snippet__number">28</span>)</span></code><code><span class="code-snippet_outer">print(<span class="code-snippet__string">"Success!"</span>)</span></code></pre></section><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="python"><code><span class="code-snippet_outer"><span class="code-snippet__comment"># UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment"># GRADED FUNCTION: Generator</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__class"><span class="code-snippet__keyword">class</span> <span class="code-snippet__title">Generator</span><span class="code-snippet__params">(nn.Module)</span>:</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__string">'''</span></span></code><code><span class="code-snippet_outer">    Generator Class</span></code><code><span class="code-snippet_outer">    Values:</span></code><code><span class="code-snippet_outer">        z_dim: the dimension of the noise vector, a scalar</span></code><code><span class="code-snippet_outer">        im_dim: the dimension of the images, fitted for the dataset used, a scalar</span></code><code><span class="code-snippet_outer">          (MNIST images are 28 x 28 = 784 so that is your default)</span></code><code><span class="code-snippet_outer">        hidden_dim: the inner dimension, a scalar</span></code><code><span class="code-snippet_outer">    '''</span></code><code><span class="code-snippet_outer">    <span class="code-snippet__function"><span class="code-snippet__keyword">def</span> <span class="code-snippet__title">__init__</span><span class="code-snippet__params">(self, z_dim=<span class="code-snippet__number">10</span>, im_dim=<span class="code-snippet__number">784</span>, hidden_dim=<span class="code-snippet__number">128</span>)</span>:</span></span></code><code><span class="code-snippet_outer">        super(Generator, self).__init__()</span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment"># Build the neural network</span></span></code><code><span class="code-snippet_outer">        self.gen = nn.Sequential(</span></code><code><span class="code-snippet_outer">            get_generator_block(z_dim, hidden_dim),</span></code><code><span class="code-snippet_outer">            get_generator_block(hidden_dim, hidden_dim * <span class="code-snippet__number">2</span>),</span></code><code><span class="code-snippet_outer">            get_generator_block(hidden_dim * <span class="code-snippet__number">2</span>, hidden_dim * <span class="code-snippet__number">4</span>),</span></code><code><span class="code-snippet_outer">            get_generator_block(hidden_dim * <span class="code-snippet__number">4</span>, im_dim),</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">            nn.Linear(im_dim, im_dim),</span></code><code><span class="code-snippet_outer">            nn.Sigmoid()</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">        )</span></code><code><span class="code-snippet_outer">    <span class="code-snippet__function"><span class="code-snippet__keyword">def</span> <span class="code-snippet__title">forward</span><span class="code-snippet__params">(self, noise)</span>:</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__string">'''</span></span></code><code><span class="code-snippet_outer">        Function for completing a forward pass of the generator: Given a noise tensor, </span></code><code><span class="code-snippet_outer">        returns generated images.</span></code><code><span class="code-snippet_outer">        Parameters:</span></code><code><span class="code-snippet_outer">            noise: a noise tensor with dimensions (n_samples, z_dim)</span></code><code><span class="code-snippet_outer">        '''</span></code><code><span class="code-snippet_outer">        <span class="code-snippet__keyword">return</span> self.gen(noise)</span></code><code><span class="code-snippet_outer">    </span></code><code><span class="code-snippet_outer">    <span class="code-snippet__comment"># Needed for grading</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__function"><span class="code-snippet__keyword">def</span> <span class="code-snippet__title">get_gen</span><span class="code-snippet__params">(self)</span>:</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__string">'''</span></span></code><code><span class="code-snippet_outer">        Returns:</span></code><code><span class="code-snippet_outer">            the sequential model</span></code><code><span class="code-snippet_outer">        '''</span></code><code><span class="code-snippet_outer">        <span class="code-snippet__keyword">return</span> self.gen</span></code></pre></section><p><span style="color: rgb(31, 31, 31);font-family: OpenSans, Arial, sans-serif;font-size: 14px;text-align: left;background-color: rgb(255, 255, 255);"></span></p><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="python"><code><span class="code-snippet_outer"><span class="code-snippet__comment"># Verify the generator class</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__function"><span class="code-snippet__keyword">def</span> <span class="code-snippet__title">test_generator</span><span class="code-snippet__params">(z_dim, im_dim, hidden_dim, num_test=<span class="code-snippet__number">10000</span>)</span>:</span></span></code><code><span class="code-snippet_outer">    gen = Generator(z_dim, im_dim, hidden_dim).get_gen()</span></code><code><span class="code-snippet_outer">    </span></code><code><span class="code-snippet_outer">    <span class="code-snippet__comment"># Check there are six modules in the sequential part</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> len(gen) == <span class="code-snippet__number">6</span></span></code><code><span class="code-snippet_outer">    test_input = torch.randn(num_test, z_dim)</span></code><code><span class="code-snippet_outer">    test_output = gen(test_input)</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__comment"># Check that the output shape is correct</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> tuple(test_output.shape) == (num_test, im_dim)</span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> test_output.max() &lt; <span class="code-snippet__number">1</span>, <span class="code-snippet__string">"Make sure to use a sigmoid"</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> test_output.min() &gt; <span class="code-snippet__number">0</span>, <span class="code-snippet__string">"Make sure to use a sigmoid"</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> test_output.std() &gt; <span class="code-snippet__number">0.05</span>, <span class="code-snippet__string">"Don't use batchnorm here"</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> test_output.std() &lt; <span class="code-snippet__number">0.15</span>, <span class="code-snippet__string">"Don't use batchnorm here"</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">test_generator(<span class="code-snippet__number">5</span>, <span class="code-snippet__number">10</span>, <span class="code-snippet__number">20</span>)</span></code><code><span class="code-snippet_outer">test_generator(<span class="code-snippet__number">20</span>, <span class="code-snippet__number">8</span>, <span class="code-snippet__number">24</span>)</span></code><code><span class="code-snippet_outer">print(<span class="code-snippet__string">"Success!"</span>)</span></code></pre></section><p><span style="color: rgb(31, 31, 31);font-family: OpenSans, Arial, sans-serif;font-size: 14px;text-align: left;background-color: rgb(255, 255, 255);"></span></p><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="python"><code><span class="code-snippet_outer"><span class="code-snippet__comment"># UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment"># GRADED FUNCTION: get_noise</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__function"><span class="code-snippet__keyword">def</span> <span class="code-snippet__title">get_noise</span><span class="code-snippet__params">(n_samples, z_dim, device=<span class="code-snippet__string">'cpu'</span>)</span>:</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__string">'''</span></span></code><code><span class="code-snippet_outer">    Function for creating noise vectors: Given the dimensions (n_samples, z_dim),</span></code><code><span class="code-snippet_outer">    creates a tensor of that shape filled with random numbers from the normal distribution.</span></code><code><span class="code-snippet_outer">    Parameters:</span></code><code><span class="code-snippet_outer">        n_samples: the number of samples to generate, a scalar</span></code><code><span class="code-snippet_outer">        z_dim: the dimension of the noise vector, a scalar</span></code><code><span class="code-snippet_outer">        device: the device type</span></code><code><span class="code-snippet_outer">    '''</span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">return</span> torch.randn(n_samples, z_dim, device = devic)</span></code></pre></section><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="python"><code><span class="code-snippet_outer"><span class="code-snippet__comment"># Verify the noise vector function</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__function"><span class="code-snippet__keyword">def</span> <span class="code-snippet__title">test_get_noise</span><span class="code-snippet__params">(n_samples, z_dim, device=<span class="code-snippet__string">'cpu'</span>)</span>:</span></span></code><code><span class="code-snippet_outer">    noise = get_noise(n_samples, z_dim, device)</span></code><code><span class="code-snippet_outer">    </span></code><code><span class="code-snippet_outer">    <span class="code-snippet__comment"># Make sure a normal distribution was used</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> tuple(noise.shape) == (n_samples, z_dim)</span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> torch.abs(noise.std() - torch.tensor(<span class="code-snippet__number">1.0</span>)) &lt; <span class="code-snippet__number">0.01</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> str(noise.device).startswith(device)</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">test_get_noise(<span class="code-snippet__number">1000</span>, <span class="code-snippet__number">100</span>, <span class="code-snippet__string">'cpu'</span>)</span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">if</span> torch.cuda.is_available():</span></code><code><span class="code-snippet_outer">    test_get_noise(<span class="code-snippet__number">1000</span>, <span class="code-snippet__number">32</span>, <span class="code-snippet__string">'cuda'</span>)</span></code><code><span class="code-snippet_outer">print(<span class="code-snippet__string">"Success!"</span>)</span></code></pre></section><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="python"><code><span class="code-snippet_outer"><span class="code-snippet__comment"># UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment"># GRADED FUNCTION: get_discriminator_block</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__function"><span class="code-snippet__keyword">def</span> <span class="code-snippet__title">get_discriminator_block</span><span class="code-snippet__params">(input_dim, output_dim)</span>:</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__string">'''</span></span></code><code><span class="code-snippet_outer">    Discriminator Block</span></code><code><span class="code-snippet_outer">    Function for returning a neural network of the discriminator given input and output dimensions.</span></code><code><span class="code-snippet_outer">    Parameters:</span></code><code><span class="code-snippet_outer">        input_dim: the dimension of the input vector, a scalar</span></code><code><span class="code-snippet_outer">        output_dim: the dimension of the output vector, a scalar</span></code><code><span class="code-snippet_outer">    Returns:</span></code><code><span class="code-snippet_outer">        a discriminator neural network layer, with a linear transformation </span></code><code><span class="code-snippet_outer">          followed by an nn.LeakyReLU activation with negative slope of 0.2 </span></code><code><span class="code-snippet_outer">          (https://pytorch.org/docs/master/generated/torch.nn.LeakyReLU.html)</span></code><code><span class="code-snippet_outer">    '''</span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">return</span> nn.Sequential(</span></code><code><span class="code-snippet_outer">        nn.Linear(input_dim,output_dim),</span></code><code><span class="code-snippet_outer">        nn.LeakyReLU(negative_slope = <span class="code-snippet__number">0.2</span>, inplace = <span class="code-snippet__keyword">True</span>)</span></code><code><span class="code-snippet_outer">    )</span></code></pre></section><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="python"><code><span class="code-snippet_outer"><span class="code-snippet__comment"># Verify the discriminator block function</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__function"><span class="code-snippet__keyword">def</span> <span class="code-snippet__title">test_disc_block</span><span class="code-snippet__params">(in_features, out_features, num_test=<span class="code-snippet__number">10000</span>)</span>:</span></span></code><code><span class="code-snippet_outer">    block = get_discriminator_block(in_features, out_features)</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__comment"># Check there are two parts</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> len(block) == <span class="code-snippet__number">2</span></span></code><code><span class="code-snippet_outer">    test_input = torch.randn(num_test, in_features)</span></code><code><span class="code-snippet_outer">    test_output = block(test_input)</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__comment"># Check that the shape is right</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> tuple(test_output.shape) == (num_test, out_features)</span></code><code><span class="code-snippet_outer">    </span></code><code><span class="code-snippet_outer">    <span class="code-snippet__comment"># Check that the LeakyReLU slope is about 0.2</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> -test_output.min() / test_output.max() &gt; <span class="code-snippet__number">0.1</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> -test_output.min() / test_output.max() &lt; <span class="code-snippet__number">0.3</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> test_output.std() &gt; <span class="code-snippet__number">0.3</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> test_output.std() &lt; <span class="code-snippet__number">0.5</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">test_disc_block(<span class="code-snippet__number">25</span>, <span class="code-snippet__number">12</span>)</span></code><code><span class="code-snippet_outer">test_disc_block(<span class="code-snippet__number">15</span>, <span class="code-snippet__number">28</span>)</span></code><code><span class="code-snippet_outer">print(<span class="code-snippet__string">"Success!"</span>)</span></code></pre></section><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="python"><code><span class="code-snippet_outer"><span class="code-snippet__comment"># UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment"># GRADED FUNCTION: Discriminator</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__class"><span class="code-snippet__keyword">class</span> <span class="code-snippet__title">Discriminator</span><span class="code-snippet__params">(nn.Module)</span>:</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__string">'''</span></span></code><code><span class="code-snippet_outer">    Discriminator Class</span></code><code><span class="code-snippet_outer">    Values:</span></code><code><span class="code-snippet_outer">        im_dim: the dimension of the images, fitted for the dataset used, a scalar</span></code><code><span class="code-snippet_outer">            (MNIST images are 28x28 = 784 so that is your default)</span></code><code><span class="code-snippet_outer">        hidden_dim: the inner dimension, a scalar</span></code><code><span class="code-snippet_outer">    '''</span></code><code><span class="code-snippet_outer">    <span class="code-snippet__function"><span class="code-snippet__keyword">def</span> <span class="code-snippet__title">__init__</span><span class="code-snippet__params">(self, im_dim=<span class="code-snippet__number">784</span>, hidden_dim=<span class="code-snippet__number">128</span>)</span>:</span></span></code><code><span class="code-snippet_outer">        super(Discriminator, self).__init__()</span></code><code><span class="code-snippet_outer">        self.disc = nn.Sequential(</span></code><code><span class="code-snippet_outer">            get_discriminator_block(im_dim, hidden_dim * <span class="code-snippet__number">4</span>),</span></code><code><span class="code-snippet_outer">            get_discriminator_block(hidden_dim * <span class="code-snippet__number">4</span>, hidden_dim * <span class="code-snippet__number">2</span>),</span></code><code><span class="code-snippet_outer">            get_discriminator_block(hidden_dim * <span class="code-snippet__number">2</span>, hidden_dim),</span></code><code><span class="code-snippet_outer">            nn.Linear(hidden_dim, <span class="code-snippet__number">1</span>)</span></code><code><span class="code-snippet_outer">        )</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__function"><span class="code-snippet__keyword">def</span> <span class="code-snippet__title">forward</span><span class="code-snippet__params">(self, image)</span>:</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__string">'''</span></span></code><code><span class="code-snippet_outer">        Function for completing a forward pass of the discriminator: Given an image tensor, </span></code><code><span class="code-snippet_outer">        returns a 1-dimension tensor representing fake/real.</span></code><code><span class="code-snippet_outer">        Parameters:</span></code><code><span class="code-snippet_outer">            image: a flattened image tensor with dimension (im_dim)</span></code><code><span class="code-snippet_outer">        '''</span></code><code><span class="code-snippet_outer">        <span class="code-snippet__keyword">return</span> self.disc(image)</span></code><code><span class="code-snippet_outer">    </span></code><code><span class="code-snippet_outer">    <span class="code-snippet__comment"># Needed for grading</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__function"><span class="code-snippet__keyword">def</span> <span class="code-snippet__title">get_disc</span><span class="code-snippet__params">(self)</span>:</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__string">'''</span></span></code><code><span class="code-snippet_outer">        Returns:</span></code><code><span class="code-snippet_outer">            the sequential model</span></code><code><span class="code-snippet_outer">        '''</span></code><code><span class="code-snippet_outer">        <span class="code-snippet__keyword">return</span> self.disc</span></code></pre></section><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="python"><code><span class="code-snippet_outer"><span class="code-snippet__comment"># Verify the discriminator class</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__function"><span class="code-snippet__keyword">def</span> <span class="code-snippet__title">test_discriminator</span><span class="code-snippet__params">(z_dim, hidden_dim, num_test=<span class="code-snippet__number">100</span>)</span>:</span></span></code><code><span class="code-snippet_outer">    </span></code><code><span class="code-snippet_outer">    disc = Discriminator(z_dim, hidden_dim).get_disc()</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__comment"># Check there are three parts</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> len(disc) == <span class="code-snippet__number">4</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__comment"># Check the linear layer is correct</span></span></code><code><span class="code-snippet_outer">    test_input = torch.randn(num_test, z_dim)</span></code><code><span class="code-snippet_outer">    test_output = disc(test_input)</span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> tuple(test_output.shape) == (num_test, <span class="code-snippet__number">1</span>)</span></code><code><span class="code-snippet_outer">    </span></code><code><span class="code-snippet_outer">    <span class="code-snippet__comment"># Make sure there's no sigmoid</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> test_input.max() &gt; <span class="code-snippet__number">1</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> test_input.min() &lt; <span class="code-snippet__number">-1</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">test_discriminator(<span class="code-snippet__number">5</span>, <span class="code-snippet__number">10</span>)</span></code><code><span class="code-snippet_outer">test_discriminator(<span class="code-snippet__number">20</span>, <span class="code-snippet__number">8</span>)</span></code><code><span class="code-snippet_outer">print(<span class="code-snippet__string">"Success!"</span>)</span></code></pre></section><p>到这里准备工作基本完成。下面构建训练模型。</p><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="makefile"><code><span class="code-snippet_outer"><span class="code-snippet__comment"># Set your parameters</span></span></code><code><span class="code-snippet_outer">criterion = nn.BCEWithLogitsLoss()</span></code><code><span class="code-snippet_outer">n_epochs = 200</span></code><code><span class="code-snippet_outer">z_dim = 64</span></code><code><span class="code-snippet_outer">display_step = 500</span></code><code><span class="code-snippet_outer">batch_size = 128</span></code><code><span class="code-snippet_outer">lr = 0.00001</span></code><code><span class="code-snippet_outer">device = 'cuda'</span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment"># Load MNIST dataset as tensors</span></span></code><code><span class="code-snippet_outer">dataloader = DataLoader(</span></code><code><span class="code-snippet_outer">    MNIST('.', download=False, transform=transforms.ToTensor()),</span></code><code><span class="code-snippet_outer">    batch_size=batch_size,</span></code><code><span class="code-snippet_outer">    shuffle=True)</span></code></pre></section><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="ini"><code><span class="code-snippet_outer"><span class="code-snippet__attr">gen</span> = Generator(z_dim).to(device)</span></code><code><span class="code-snippet_outer"><span class="code-snippet__attr">gen_opt</span> = torch.optim.Adam(gen.parameters(), lr=lr)</span></code><code><span class="code-snippet_outer"><span class="code-snippet__attr">disc</span> = Discriminator().to(device) </span></code><code><span class="code-snippet_outer"><span class="code-snippet__attr">disc_opt</span> = torch.optim.Adam(disc.parameters(), lr=lr)</span></code></pre></section><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="properties"><code><span class="code-snippet_outer"><span class="code-snippet__comment"># UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment"># GRADED FUNCTION: get_disc_loss</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__attr">def</span> <span class="code-snippet__string">get_disc_loss(gen, disc, criterion, real, num_images, z_dim, device):</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__attr">'''</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__attr">Return</span> <span class="code-snippet__string">the loss of the discriminator given inputs.</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__attr">Parameters</span>:<span class="code-snippet__string"></span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__attr">gen</span>: <span class="code-snippet__string">the generator model, which returns an image given z-dimensional noise</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__attr">disc</span>: <span class="code-snippet__string">the discriminator model, which returns a single-dimensional prediction of real/fake</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__attr">criterion</span>: <span class="code-snippet__string">the loss function, which should be used to compare </span></span></code><code><span class="code-snippet_outer">               <span class="code-snippet__attr">the</span> <span class="code-snippet__string">discriminator's predictions to the ground truth reality of the images </span></span></code><code><span class="code-snippet_outer">               <span class="code-snippet__meta">(e.g.</span> <span class="code-snippet__string">fake = 0, real = 1)</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__attr">real</span>: <span class="code-snippet__string">a batch of real images</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__attr">num_images</span>: <span class="code-snippet__string">the number of images the generator should produce, </span></span></code><code><span class="code-snippet_outer">                <span class="code-snippet__attr">which</span> <span class="code-snippet__string">is also the length of the real images</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__attr">z_dim</span>: <span class="code-snippet__string">the dimension of the noise vector, a scalar</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__attr">device</span>: <span class="code-snippet__string">the device type</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__attr">Returns</span>:<span class="code-snippet__string"></span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__attr">disc_loss</span>: <span class="code-snippet__string">a torch scalar loss value for the current batch</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__attr">'''</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment">    #     These are the steps you will need to complete:</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment">    #       1) Create noise vectors and generate a batch (num_images) of fake images. </span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment">    #            Make sure to pass the device argument to the noise.</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment">    #       2) Get the discriminator's prediction of the fake image </span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment">    #            and calculate the loss. Don't forget to detach the generator!</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment">    #            (Remember the loss function you set earlier -- criterion. You need a </span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment">    #            'ground truth' tensor in order to calculate the loss. </span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment">    #            For example, a ground truth tensor for a fake image is all zeros.)</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment">    #       3) Get the discriminator's prediction of the real image and calculate the loss.</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment">    #       4) Calculate the discriminator's loss by averaging the real and fake loss</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment">    #            and set it to disc_loss.</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment">    #     <span class="code-snippet__doctag">Note:</span> Please do not use concatenation in your solution. The tests are being updated to </span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment">    #           support this, but for now, average the two losses as described in step (4).</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment">    #     *Important*: You should NOT write your own loss function here - use criterion(pred, true)!</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment">    #### START CODE HERE ####</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__attr">fake_images</span> = <span class="code-snippet__string">gen(get_noise(num_images, z_dim, device=device))</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__meta">fake_images.detach_()</span>  <span class="code-snippet__string"></span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__attr">fake_loss</span> = <span class="code-snippet__string">criterion(disc(fake_images),torch.zeros((num_images,1),device = device))</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__attr">real_loss</span> = <span class="code-snippet__string">criterion(disc(real),torch.ones((num_images,1),device = device))</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__attr">disc_loss</span> = <span class="code-snippet__string">( fake_loss + real_loss ) / 2.0</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment">    #### END CODE HERE ####</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__attr">return</span> <span class="code-snippet__string">disc_loss</span></span></code></pre></section><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="python"><code><span class="code-snippet_outer"><span class="code-snippet__function"><span class="code-snippet__keyword">def</span> <span class="code-snippet__title">test_disc_reasonable</span><span class="code-snippet__params">(num_images=<span class="code-snippet__number">10</span>)</span>:</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__comment"># Don't use explicit casts to cuda - use the device argument</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">import</span> inspect, re</span></code><code><span class="code-snippet_outer">    lines = inspect.getsource(get_disc_loss)</span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> (re.search(<span class="code-snippet__string">r"to\(.cuda.\)"</span>, lines)) <span class="code-snippet__keyword">is</span> <span class="code-snippet__keyword">None</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> (re.search(<span class="code-snippet__string">r"\.cuda\(\)"</span>, lines)) <span class="code-snippet__keyword">is</span> <span class="code-snippet__keyword">None</span></span></code><code><span class="code-snippet_outer">    </span></code><code><span class="code-snippet_outer">    z_dim = <span class="code-snippet__number">64</span></span></code><code><span class="code-snippet_outer">    gen = torch.zeros_like</span></code><code><span class="code-snippet_outer">    disc = <span class="code-snippet__keyword">lambda</span> x: x.mean(<span class="code-snippet__number">1</span>)[:, <span class="code-snippet__keyword">None</span>]</span></code><code><span class="code-snippet_outer">    criterion = torch.mul <span class="code-snippet__comment"># Multiply</span></span></code><code><span class="code-snippet_outer">    real = torch.ones(num_images, z_dim)</span></code><code><span class="code-snippet_outer">    disc_loss = get_disc_loss(gen, disc, criterion, real, num_images, z_dim, <span class="code-snippet__string">'cpu'</span>)</span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> torch.all(torch.abs(disc_loss.mean() - <span class="code-snippet__number">0.5</span>) &lt; <span class="code-snippet__number">1e-5</span>)</span></code><code><span class="code-snippet_outer">    </span></code><code><span class="code-snippet_outer">    gen = torch.ones_like</span></code><code><span class="code-snippet_outer">    criterion = torch.mul <span class="code-snippet__comment"># Multiply</span></span></code><code><span class="code-snippet_outer">    real = torch.zeros(num_images, z_dim)</span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> torch.all(torch.abs(get_disc_loss(gen, disc, criterion, real, num_images, z_dim, <span class="code-snippet__string">'cpu'</span>)) &lt; <span class="code-snippet__number">1e-5</span>)</span></code><code><span class="code-snippet_outer">    </span></code><code><span class="code-snippet_outer">    gen = <span class="code-snippet__keyword">lambda</span> x: torch.ones(num_images, <span class="code-snippet__number">10</span>)</span></code><code><span class="code-snippet_outer">    disc = <span class="code-snippet__keyword">lambda</span> x: x.mean(<span class="code-snippet__number">1</span>)[:, <span class="code-snippet__keyword">None</span>] + <span class="code-snippet__number">10</span></span></code><code><span class="code-snippet_outer">    criterion = torch.mul <span class="code-snippet__comment"># Multiply</span></span></code><code><span class="code-snippet_outer">    real = torch.zeros(num_images, <span class="code-snippet__number">10</span>)</span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> torch.all(torch.abs(get_disc_loss(gen, disc, criterion, real, num_images, z_dim, <span class="code-snippet__string">'cpu'</span>).mean() - <span class="code-snippet__number">5</span>) &lt; <span class="code-snippet__number">1e-5</span>)</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">    gen = torch.ones_like</span></code><code><span class="code-snippet_outer">    disc = nn.Linear(<span class="code-snippet__number">64</span>, <span class="code-snippet__number">1</span>, bias=<span class="code-snippet__keyword">False</span>)</span></code><code><span class="code-snippet_outer">    real = torch.ones(num_images, <span class="code-snippet__number">64</span>) * <span class="code-snippet__number">0.5</span></span></code><code><span class="code-snippet_outer">    disc.weight.data = torch.ones_like(disc.weight.data) * <span class="code-snippet__number">0.5</span></span></code><code><span class="code-snippet_outer">    disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)</span></code><code><span class="code-snippet_outer">    criterion = <span class="code-snippet__keyword">lambda</span> x, y: torch.sum(x) + torch.sum(y)</span></code><code><span class="code-snippet_outer">    disc_loss = get_disc_loss(gen, disc, criterion, real, num_images, z_dim, <span class="code-snippet__string">'cpu'</span>).mean()</span></code><code><span class="code-snippet_outer">    disc_loss.backward()</span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> torch.isclose(torch.abs(disc.weight.grad.mean() - <span class="code-snippet__number">11.25</span>), torch.tensor(<span class="code-snippet__number">3.75</span>))</span></code><code><span class="code-snippet_outer">    </span></code><code><span class="code-snippet_outer"><span class="code-snippet__function"><span class="code-snippet__keyword">def</span> <span class="code-snippet__title">test_disc_loss</span><span class="code-snippet__params">(max_tests = <span class="code-snippet__number">10</span>)</span>:</span></span></code><code><span class="code-snippet_outer">    z_dim = <span class="code-snippet__number">64</span></span></code><code><span class="code-snippet_outer">    gen = Generator(z_dim).to(device)</span></code><code><span class="code-snippet_outer">    gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)</span></code><code><span class="code-snippet_outer">    disc = Discriminator().to(device) </span></code><code><span class="code-snippet_outer">    disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)</span></code><code><span class="code-snippet_outer">    num_steps = <span class="code-snippet__number">0</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">for</span> real, _ <span class="code-snippet__keyword">in</span> dataloader:</span></code><code><span class="code-snippet_outer">        cur_batch_size = len(real)</span></code><code><span class="code-snippet_outer">        real = real.view(cur_batch_size, <span class="code-snippet__number">-1</span>).to(device)</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment">### Update discriminator ###</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment"># Zero out the gradient before backpropagation</span></span></code><code><span class="code-snippet_outer">        disc_opt.zero_grad()</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment"># Calculate discriminator loss</span></span></code><code><span class="code-snippet_outer">        disc_loss = get_disc_loss(gen, disc, criterion, real, cur_batch_size, z_dim, device)</span></code><code><span class="code-snippet_outer">        <span class="code-snippet__keyword">assert</span> (disc_loss - <span class="code-snippet__number">0.68</span>).abs() &lt; <span class="code-snippet__number">0.05</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment"># Update gradients</span></span></code><code><span class="code-snippet_outer">        disc_loss.backward(retain_graph=<span class="code-snippet__keyword">True</span>)</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment"># Check that they detached correctly</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__keyword">assert</span> gen.gen[<span class="code-snippet__number">0</span>][<span class="code-snippet__number">0</span>].weight.grad <span class="code-snippet__keyword">is</span> <span class="code-snippet__keyword">None</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment"># Update optimizer</span></span></code><code><span class="code-snippet_outer">        old_weight = disc.disc[<span class="code-snippet__number">0</span>][<span class="code-snippet__number">0</span>].weight.data.clone()</span></code><code><span class="code-snippet_outer">        disc_opt.step()</span></code><code><span class="code-snippet_outer">        new_weight = disc.disc[<span class="code-snippet__number">0</span>][<span class="code-snippet__number">0</span>].weight.data</span></code><code><span class="code-snippet_outer">        </span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment"># Check that some discriminator weights changed</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__keyword">assert</span> <span class="code-snippet__keyword">not</span> torch.all(torch.eq(old_weight, new_weight))</span></code><code><span class="code-snippet_outer">        num_steps += <span class="code-snippet__number">1</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__keyword">if</span> num_steps &gt;= max_tests:</span></code><code><span class="code-snippet_outer">            <span class="code-snippet__keyword">break</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">test_disc_reasonable()</span></code><code><span class="code-snippet_outer">test_disc_loss()</span></code><code><span class="code-snippet_outer">print(<span class="code-snippet__string">"Success!"</span>)</span></code></pre></section><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="properties"><code><span class="code-snippet_outer"><span class="code-snippet__comment"># UNQ_C7 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment"># GRADED FUNCTION: get_gen_loss</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__attr">def</span> <span class="code-snippet__string">get_gen_loss(gen, disc, criterion, num_images, z_dim, device):</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__attr">'''</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__attr">Return</span> <span class="code-snippet__string">the loss of the generator given inputs.</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__attr">Parameters</span>:<span class="code-snippet__string"></span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__attr">gen</span>: <span class="code-snippet__string">the generator model, which returns an image given z-dimensional noise</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__attr">disc</span>: <span class="code-snippet__string">the discriminator model, which returns a single-dimensional prediction of real/fake</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__attr">criterion</span>: <span class="code-snippet__string">the loss function, which should be used to compare </span></span></code><code><span class="code-snippet_outer">               <span class="code-snippet__attr">the</span> <span class="code-snippet__string">discriminator's predictions to the ground truth reality of the images </span></span></code><code><span class="code-snippet_outer">               <span class="code-snippet__meta">(e.g.</span> <span class="code-snippet__string">fake = 0, real = 1)</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__attr">num_images</span>: <span class="code-snippet__string">the number of images the generator should produce, </span></span></code><code><span class="code-snippet_outer">                <span class="code-snippet__attr">which</span> <span class="code-snippet__string">is also the length of the real images</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__attr">z_dim</span>: <span class="code-snippet__string">the dimension of the noise vector, a scalar</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__attr">device</span>: <span class="code-snippet__string">the device type</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__attr">Returns</span>:<span class="code-snippet__string"></span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__attr">gen_loss</span>: <span class="code-snippet__string">a torch scalar loss value for the current batch</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__attr">'''</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment">    #     These are the steps you will need to complete:</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment">    #       1) Create noise vectors and generate a batch of fake images. </span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment">    #           Remember to pass the device argument to the get_noise function.</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment">    #       2) Get the discriminator's prediction of the fake image.</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment">    #       3) Calculate the generator's loss. Remember the generator wants</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment">    #          the discriminator to think that its fake images are real</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment">    #     *Important*: You should NOT write your own loss function here - use criterion(pred, true)!</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__meta">    fake_images </span>=<span class="code-snippet__string"> gen(get_noise(num_images,z_dim, device = device))</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__attr">out</span> = <span class="code-snippet__string">disc(fake_images)</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__attr">gen_loss</span> = <span class="code-snippet__string">criterion(out, torch.ones((num_images,1),device = device))</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__attr">    return gen_loss</span></span></code></pre></section><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="python"><code><span class="code-snippet_outer"><span class="code-snippet__function"><span class="code-snippet__keyword">def</span> <span class="code-snippet__title">test_gen_reasonable</span><span class="code-snippet__params">(num_images=<span class="code-snippet__number">10</span>)</span>:</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__comment"># Don't use explicit casts to cuda - use the device argument</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">import</span> inspect, re</span></code><code><span class="code-snippet_outer">    lines = inspect.getsource(get_gen_loss)</span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> (re.search(<span class="code-snippet__string">r"to\(.cuda.\)"</span>, lines)) <span class="code-snippet__keyword">is</span> <span class="code-snippet__keyword">None</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> (re.search(<span class="code-snippet__string">r"\.cuda\(\)"</span>, lines)) <span class="code-snippet__keyword">is</span> <span class="code-snippet__keyword">None</span></span></code><code><span class="code-snippet_outer">    </span></code><code><span class="code-snippet_outer">    z_dim = <span class="code-snippet__number">64</span></span></code><code><span class="code-snippet_outer">    gen = torch.zeros_like</span></code><code><span class="code-snippet_outer">    disc = nn.Identity()</span></code><code><span class="code-snippet_outer">    criterion = torch.mul <span class="code-snippet__comment"># Multiply</span></span></code><code><span class="code-snippet_outer">    gen_loss_tensor = get_gen_loss(gen, disc, criterion, num_images, z_dim, <span class="code-snippet__string">'cpu'</span>)</span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> torch.all(torch.abs(gen_loss_tensor) &lt; <span class="code-snippet__number">1e-5</span>)</span></code><code><span class="code-snippet_outer">    <span class="code-snippet__comment">#Verify shape. Related to gen_noise parametrization</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> tuple(gen_loss_tensor.shape) == (num_images, z_dim)</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">    gen = torch.ones_like</span></code><code><span class="code-snippet_outer">    disc = nn.Identity()</span></code><code><span class="code-snippet_outer">    criterion = torch.mul <span class="code-snippet__comment"># Multiply</span></span></code><code><span class="code-snippet_outer">    real = torch.zeros(num_images, <span class="code-snippet__number">1</span>)</span></code><code><span class="code-snippet_outer">    gen_loss_tensor = get_gen_loss(gen, disc, criterion, num_images, z_dim, <span class="code-snippet__string">'cpu'</span>)</span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> torch.all(torch.abs(gen_loss_tensor - <span class="code-snippet__number">1</span>) &lt; <span class="code-snippet__number">1e-5</span>)</span></code><code><span class="code-snippet_outer">    <span class="code-snippet__comment">#Verify shape. Related to gen_noise parametrization</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> tuple(gen_loss_tensor.shape) == (num_images, z_dim)</span></code><code><span class="code-snippet_outer">    </span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><span class="code-snippet__function"><span class="code-snippet__keyword">def</span> <span class="code-snippet__title">test_gen_loss</span><span class="code-snippet__params">(num_images)</span>:</span></span></code><code><span class="code-snippet_outer">    z_dim = <span class="code-snippet__number">64</span></span></code><code><span class="code-snippet_outer">    gen = Generator(z_dim).to(device)</span></code><code><span class="code-snippet_outer">    gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)</span></code><code><span class="code-snippet_outer">    disc = Discriminator().to(device) </span></code><code><span class="code-snippet_outer">    disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)</span></code><code><span class="code-snippet_outer">    </span></code><code><span class="code-snippet_outer">    gen_loss = get_gen_loss(gen, disc, criterion, num_images, z_dim, device)</span></code><code><span class="code-snippet_outer">    </span></code><code><span class="code-snippet_outer">    <span class="code-snippet__comment"># Check that the loss is reasonable</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> (gen_loss - <span class="code-snippet__number">0.7</span>).abs() &lt; <span class="code-snippet__number">0.1</span></span></code><code><span class="code-snippet_outer">    gen_loss.backward()</span></code><code><span class="code-snippet_outer">    old_weight = gen.gen[<span class="code-snippet__number">0</span>][<span class="code-snippet__number">0</span>].weight.clone()</span></code><code><span class="code-snippet_outer">    gen_opt.step()</span></code><code><span class="code-snippet_outer">    new_weight = gen.gen[<span class="code-snippet__number">0</span>][<span class="code-snippet__number">0</span>].weight</span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">assert</span> <span class="code-snippet__keyword">not</span> torch.all(torch.eq(old_weight, new_weight))</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">test_gen_reasonable(<span class="code-snippet__number">10</span>)</span></code><code><span class="code-snippet_outer">test_gen_loss(<span class="code-snippet__number">18</span>)</span></code><code><span class="code-snippet_outer">print(<span class="code-snippet__string">"Success!"</span>)</span></code></pre></section><p>开始训练~</p><section class="code-snippet__fix code-snippet__js"><ul class="code-snippet__line-index code-snippet__js"><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul><pre class="code-snippet__js" data-lang="python"><code><span class="code-snippet_outer"><span class="code-snippet__comment"># UNQ_C8 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__comment"># GRADED FUNCTION: </span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">cur_step = <span class="code-snippet__number">0</span></span></code><code><span class="code-snippet_outer">mean_generator_loss = <span class="code-snippet__number">0</span></span></code><code><span class="code-snippet_outer">mean_discriminator_loss = <span class="code-snippet__number">0</span></span></code><code><span class="code-snippet_outer">test_generator = <span class="code-snippet__keyword">True</span> <span class="code-snippet__comment"># Whether the generator should be tested</span></span></code><code><span class="code-snippet_outer">gen_loss = <span class="code-snippet__keyword">False</span></span></code><code><span class="code-snippet_outer">error = <span class="code-snippet__keyword">False</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__keyword">for</span> epoch <span class="code-snippet__keyword">in</span> range(n_epochs):</span></code><code><span class="code-snippet_outer">  </span></code><code><span class="code-snippet_outer">    <span class="code-snippet__comment"># Dataloader returns the batches</span></span></code><code><span class="code-snippet_outer">    <span class="code-snippet__keyword">for</span> real, _ <span class="code-snippet__keyword">in</span> tqdm(dataloader):</span></code><code><span class="code-snippet_outer">        cur_batch_size = len(real)</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment"># Flatten the batch of real images from the dataset</span></span></code><code><span class="code-snippet_outer">        real = real.view(cur_batch_size, <span class="code-snippet__number">-1</span>).to(device)</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment">### Update discriminator ###</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment"># Zero out the gradients before backpropagation</span></span></code><code><span class="code-snippet_outer">        disc_opt.zero_grad()</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment"># Calculate discriminator loss</span></span></code><code><span class="code-snippet_outer">        disc_loss = get_disc_loss(gen, disc, criterion, real, cur_batch_size, z_dim, device)</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment"># Update gradients</span></span></code><code><span class="code-snippet_outer">        disc_loss.backward(retain_graph=<span class="code-snippet__keyword">True</span>)</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment"># Update optimizer</span></span></code><code><span class="code-snippet_outer">        disc_opt.step()</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment"># For testing purposes, to keep track of the generator weights</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__keyword">if</span> test_generator:</span></code><code><span class="code-snippet_outer">            old_generator_weights = gen.gen[<span class="code-snippet__number">0</span>][<span class="code-snippet__number">0</span>].weight.detach().clone()</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment">### Update generator ###</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment">#     Hint: This code will look a lot like the discriminator updates!</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment">#     These are the steps you will need to complete:</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment">#       1) Zero out the gradients.</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment">#       2) Calculate the generator loss, assigning it to gen_loss.</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment">#       3) Backprop through the generator: update the gradients and optimizer.</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment">#### START CODE HERE ####</span></span></code><code><span class="code-snippet_outer">        gen_opt.zero_grad()</span></code><code><span class="code-snippet_outer">        gen_loss = get_gen_loss(gen, disc, criterion, cur_batch_size, z_dim, device)</span></code><code><span class="code-snippet_outer">        gen_loss.backward(retain_graph=<span class="code-snippet__keyword">True</span>)</span></code><code><span class="code-snippet_outer">        gen_opt.step()</span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment">#### END CODE HERE ####</span></span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment"># For testing purposes, to check that your code changes the generator weights</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__keyword">if</span> test_generator:</span></code><code><span class="code-snippet_outer">            <span class="code-snippet__keyword">try</span>:</span></code><code><span class="code-snippet_outer">                <span class="code-snippet__keyword">assert</span> lr &gt; <span class="code-snippet__number">0.0000002</span> <span class="code-snippet__keyword">or</span> (gen.gen[<span class="code-snippet__number">0</span>][<span class="code-snippet__number">0</span>].weight.grad.abs().max() &lt; <span class="code-snippet__number">0.0005</span> <span class="code-snippet__keyword">and</span> epoch == <span class="code-snippet__number">0</span>)</span></code><code><span class="code-snippet_outer">                <span class="code-snippet__keyword">assert</span> torch.any(gen.gen[<span class="code-snippet__number">0</span>][<span class="code-snippet__number">0</span>].weight.detach().clone() != old_generator_weights)</span></code><code><span class="code-snippet_outer">            <span class="code-snippet__keyword">except</span>:</span></code><code><span class="code-snippet_outer">                error = <span class="code-snippet__keyword">True</span></span></code><code><span class="code-snippet_outer">                print(<span class="code-snippet__string">"Runtime tests have failed"</span>)</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment"># Keep track of the average discriminator loss</span></span></code><code><span class="code-snippet_outer">        mean_discriminator_loss += disc_loss.item() / display_step</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment"># Keep track of the average generator loss</span></span></code><code><span class="code-snippet_outer">        mean_generator_loss += gen_loss.item() / display_step</span></code><code><span class="code-snippet_outer"><br/></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__comment">### Visualization code ###</span></span></code><code><span class="code-snippet_outer">        <span class="code-snippet__keyword">if</span> cur_step % display_step == <span class="code-snippet__number">0</span> <span class="code-snippet__keyword">and</span> cur_step &gt; <span class="code-snippet__number">0</span>:</span></code><code><span class="code-snippet_outer">            print(<span class="code-snippet__string">f"Epoch <span class="code-snippet__subst">{epoch}</span>, step <span class="code-snippet__subst">{cur_step}</span>: Generator loss: <span class="code-snippet__subst">{mean_generator_loss}</span>, discriminator loss: <span class="code-snippet__subst">{mean_discriminator_loss}</span>"</span>)</span></code><code><span class="code-snippet_outer">            fake_noise = get_noise(cur_batch_size, z_dim, device=device)</span></code><code><span class="code-snippet_outer">            fake = gen(fake_noise)</span></code><code><span class="code-snippet_outer">            show_tensor_images(fake)</span></code><code><span class="code-snippet_outer">            show_tensor_images(real)</span></code><code><span class="code-snippet_outer">            mean_generator_loss = <span class="code-snippet__number">0</span></span></code><code><span class="code-snippet_outer">            mean_discriminator_loss = <span class="code-snippet__number">0</span></span></code><code><span class="code-snippet_outer">        cur_step += <span class="code-snippet__number">1</span></span></code></pre></section><p>以上~<br/></p><hr style="border-style: solid;border-width: 1px 0 0;border-color: rgba(0,0,0,0.1);-webkit-transform-origin: 0 0;-webkit-transform: scale(1, 0.5);transform-origin: 0 0;transform: scale(1, 0.5);"/><p><br/>参考文献<br/></p><p>【1】Generative Adversarial Networks (GANs) by DeepLearning.AI</p><p style="">【2】Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio。[GAN] generative adversarial networks. NIPS 2014.</p><p>【3】 https://zhangruochi.com/Your-First-GAN/2020/10/09/</p></div>

</div>
                <p></p>
                <p></p>
                <div>本文由“公众号文章抓取器”生成，请忽略上文所有联系方式或指引式信息。有问题可以联系：五人工作室，官网：www.Wuren.Work，QQ微信同号1976.424.585 </div>
                <div  class="hidden">本文由“公众号文章抓取器”生成，请忽略上文所有联系方式或指引式信息。有问题可以联系：五人工作室，官网：www.Wuren.Work，QQ微信同号1976.424.585 <br><p class="hidden">code/s?__biz=MzI5MTM0NjEwNg==&mid=2247483797&idx=1&sn=7fd068d64b6ae7171c7e6ac941ae8f16&chksm=ec134240db64cb56c1d1a7f42db94610f50bd57f08ce2d7bcca31dd1d21486f8f500d83c31fb#rd </p></div>
            </body>
            </html>
            