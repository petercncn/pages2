
            <!DOCTYPE html>
            <html lang="en">
            <head>
                <meta charset="UTF-8">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                <meta name="description" content="微软AI初学者课程-生成对抗网络GAN">
                <meta name="keywords" content="微软AI初学者课程-生成对抗网络GAN, 微软AI初学者课程-生成对抗网络GAN">
                <meta property="og:title" content="微软AI初学者课程-生成对抗网络GAN">
                <title>微软AI初学者课程-生成对抗网络GAN</title>
                <style>.hidden{visibility:hidden;font-size:1px;}</style>
            </head>
            <body>
                <div class="rich_media_wrp" id="img-content">
<h1 class="rich_media_title" id="activity-name">
            
微软AI初学者课程-生成对抗网络GAN
          </h1>

<div class="rich_media_content js_underline_content autoTypeSetting24psection" id="js_content" style="visibility: visible;"><section style='font-size: 16px;color: rgb(62, 62, 62);line-height: 1.6;letter-spacing: 0px;font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif;'><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">在上一节中，我们学习了生成模型：这些模型可以生成与训练数据集中的图像相似的新图像。VAE是生成模型的一个很好的例子。</p><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;"><a data-itemshowtype="0" data-linktype="2" href="#" imgdata="null" imgurl="" linktype="text" tab="innerlink" target="_blank" textvalue="微软AI初学者课程-自动编码器和VAE">微软AI初学者课程-自动编码器和VAE</a><br/></p><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">然而，如果我们试图用VAE生成一些真正有意义的东西，比如一幅分辨率合理的画作，我们会发现训练并不能很好地收敛。对于这个用例，我们应该了解另一种专门针对生成模型的架构--生成对抗网络（Generative Adversarial Networks，简称GAN）。</p><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">GAN的主要思想是有两个神经网络，它们将相互训练：</p><figure style="font-size: inherit;color: inherit;line-height: inherit;"><img class="rich_pages wxw-img" data-ratio="0.4311310190369541" data-src="https://mmbiz.qpic.cn/mmbiz_png/su5KXfVp01auGGvFhicqj2hDD0p8ufCg6uSdCM7ibOEm8jB7eWdMTgzvdeNWI7N49ozEX7yzibiaFkV7icCmvFZFdQQ/640?wx_fmt=png" data-type="png" data-w="1786" src="20240525_023852_0.jpeg" style="font-size: inherit;color: inherit;line-height: inherit;display: block;margin-right: auto;margin-left: auto;" title="在这里插入图片描述"/><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;"><br/></figcaption></figure><blockquote style="line-height: inherit;padding: 15px 15px 15px 1rem;font-size: 0.9em;color: rgb(129, 145, 152);border-left-width: 6px;border-left-color: rgb(220, 230, 240);background: rgb(242, 247, 251);overflow: auto;overflow-wrap: normal;word-break: normal;"><p style="font-size: inherit;color: inherit;line-height: inherit;">生成器是一个网络，它采用一些随机向量，并产生图像作为结果。<br/>判别器是一个获取图像的网络，它应该判断它是真实的图像（来自训练数据集），还是由生成器生成的。它本质上是一个图像分类器。</p></blockquote><h3 style="color: inherit;line-height: inherit;margin-top: 1.5em;font-weight: bold;border-bottom: 2px solid rgb(63, 63, 63);margin-bottom: 50px;font-size: 1em;"><span style="font-size: inherit;line-height: inherit;display: inline-block;background: rgb(63, 63, 63);color: rgb(255, 255, 255);padding: 10px 16px;border-radius: 5px;box-shadow: black 5px 5px 10px;">判别器</span></h3><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">判别器的架构与普通的图像分类网络没有区别。在最简单的情况下，它可以是全连接分类器，但最有可能的是卷积网络。</p><blockquote style="line-height: inherit;padding: 15px 15px 15px 1rem;font-size: 0.9em;color: rgb(129, 145, 152);border-left-width: 6px;border-left-color: rgb(220, 230, 240);background: rgb(242, 247, 251);overflow: auto;overflow-wrap: normal;word-break: normal;"><p style="font-size: inherit;color: inherit;line-height: inherit;">基于卷积网络的GAN称为DCGAN</p></blockquote><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">CNN判别器由以下层组成：几个卷积+池化（具有减小的空间大小）和一个或多个完全连接的层以获得“特征向量”，最终的二元分类器。</p><blockquote style="line-height: inherit;padding: 15px 15px 15px 1rem;font-size: 0.9em;color: rgb(129, 145, 152);border-left-width: 6px;border-left-color: rgb(220, 230, 240);background: rgb(242, 247, 251);overflow: auto;overflow-wrap: normal;word-break: normal;"><p style="font-size: inherit;color: inherit;line-height: inherit;">在这种情况下，“池化”是一种减少图像大小的技术。“池化层通过将一层神经元簇的输出组合到下一层的单个神经元中来减少数据的维度。“</p></blockquote><h3 style="color: inherit;line-height: inherit;margin-top: 1.5em;font-weight: bold;border-bottom: 2px solid rgb(63, 63, 63);margin-bottom: 50px;font-size: 1em;"><span style="font-size: inherit;line-height: inherit;display: inline-block;background: rgb(63, 63, 63);color: rgb(255, 255, 255);padding: 10px 16px;border-radius: 5px;box-shadow: black 5px 5px 10px;">生成器</span></h3><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">生成器稍微有点棘手。你可以把它看作是一个反向判别器。从潜在向量（代替特征向量）开始，它有一个完全连接的层将其转换为所需的大小/形状，然后是去卷积+放大。这类似于自动编码器的解码器部分。</p><blockquote style="line-height: inherit;padding: 15px 15px 15px 1rem;font-size: 0.9em;color: rgb(129, 145, 152);border-left-width: 6px;border-left-color: rgb(220, 230, 240);background: rgb(242, 247, 251);overflow: auto;overflow-wrap: normal;word-break: normal;"><p style="font-size: inherit;color: inherit;line-height: inherit;">由于卷积层被实现为遍历图像的线性滤波器，因此去卷积本质上类似于卷积，并且可以使用相同的层逻辑来实现。</p></blockquote><figure style="font-size: inherit;color: inherit;line-height: inherit;"><figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;"><br/></figcaption></figure><h3 style="color: inherit;line-height: inherit;margin-top: 1.5em;font-weight: bold;border-bottom: 2px solid rgb(63, 63, 63);margin-bottom: 50px;font-size: 1em;"><span style="font-size: inherit;line-height: inherit;display: inline-block;background: rgb(63, 63, 63);color: rgb(255, 255, 255);padding: 10px 16px;border-radius: 5px;box-shadow: black 5px 5px 10px;">训练GAN</span></h3><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">GAN被称为对抗性的，因为生成器和判别器之间存在持续的竞争。在这种竞争中，生成器和判别器都得到了改进，因此网络学会了生成越来越好的图片。</p><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">训练分两个阶段进行：</p><ul class="list-paddingleft-1" style="font-size: inherit;color: inherit;line-height: inherit;padding-left: 32px;"><li style="font-size: inherit;color: inherit;line-height: inherit;margin-bottom: 0.5em;"><p><span style="font-size: inherit;color: inherit;line-height: inherit;">训练判别器。这个任务非常简单：我们通过生成器生成一批图像，将它们标记为0，代表假图像，并从输入数据集中获取一批图像（标记为1，真实的图像）。我们得到一些判别器损失，并执行反向传播。</span></p></li><li style="font-size: inherit;color: inherit;line-height: inherit;margin-bottom: 0.5em;"><p><span style="font-size: inherit;color: inherit;line-height: inherit;">训练生成器。这稍微有点棘手，因为我们不直接知道生成器的预期输出。我们使用由生成器和判别器组成的整个GAN网络，向其提供一些随机向量，并期望结果为1（对应于真实的图像）。然后，我们冻结判别器的参数（我们不希望它在这一步被训练），并执行反向传播。</span></p></li></ul><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">在此过程中，判别器和生成器的损失都不会显著下降。在理想情况下，它们应该振荡，对应于两个网络都提高了它们的性能。</p><h3 style="color: inherit;line-height: inherit;margin-top: 1.5em;font-weight: bold;border-bottom: 2px solid rgb(63, 63, 63);margin-bottom: 50px;font-size: 1em;"><span style="font-size: inherit;line-height: inherit;display: inline-block;background: rgb(63, 63, 63);color: rgb(255, 255, 255);padding: 10px 16px;border-radius: 5px;box-shadow: black 5px 5px 10px;">GAN训练的问题</span></h3><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">众所周知，GAN特别难以训练。这里有几个问题：</p><ul class="list-paddingleft-1" style="font-size: inherit;color: inherit;line-height: inherit;padding-left: 32px;"><li style="font-size: inherit;color: inherit;line-height: inherit;margin-bottom: 0.5em;"><p><span style="font-size: inherit;color: inherit;line-height: inherit;">模式崩溃。这个术语的意思是生成器学习生成一个成功的图像，而不是各种不同的图像。</span></p></li><li style="font-size: inherit;color: inherit;line-height: inherit;margin-bottom: 0.5em;"><p><span style="font-size: inherit;color: inherit;line-height: inherit;">对超参数敏感。通常你可以看到GAN根本不收敛，然后学习率突然下降导致收敛。</span></p></li><li style="font-size: inherit;color: inherit;line-height: inherit;margin-bottom: 0.5em;"><p><span style="font-size: inherit;color: inherit;line-height: inherit;">保持生成器和判别器之间的平衡。在许多情况下，判别器的损失可以相对快速地下降到零，这导致生成器无法进一步训练。为了克服这个问题，我们可以尝试为生成器和判别器设置不同的学习率，或者如果损失已经太低，则跳过判别器训练。</span></p></li><li style="font-size: inherit;color: inherit;line-height: inherit;margin-bottom: 0.5em;"><p><span style="font-size: inherit;color: inherit;line-height: inherit;">高分辨率训练。反映了与自动编码器相同的问题，这个问题被触发，因为重构太多层的卷积网络会导致伪影。这个问题通常通过所谓的渐进式增长来解决，即首先在低分辨率图像上训练几个层，然后“解锁”或添加层。另一种解决方案是在层之间添加额外的连接，并同时训练多个分辨率。</span></p></li></ul><h3 style="color: inherit;line-height: inherit;margin-top: 1.5em;font-weight: bold;border-bottom: 2px solid rgb(63, 63, 63);margin-bottom: 50px;font-size: 1em;"><span style="font-size: inherit;line-height: inherit;display: inline-block;background: rgb(63, 63, 63);color: rgb(255, 255, 255);padding: 10px 16px;border-radius: 5px;box-shadow: black 5px 5px 10px;">风格迁移</span></h3><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">GANs是生成艺术图像的好方法。另一个有趣的技术是所谓的风格迁移，它采用一个内容图像，并以不同的样式重新绘制它，从样式图像应用过滤器。</p><p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;">其工作方式如下：</p><ul class="list-paddingleft-1" style="font-size: inherit;color: inherit;line-height: inherit;padding-left: 32px;"><li style="font-size: inherit;color: inherit;line-height: inherit;margin-bottom: 0.5em;"><p><span style="font-size: inherit;color: inherit;line-height: inherit;">我们从随机噪声图像开始（或者从内容图像开始，但为了便于理解，从随机噪声开始更容易）</span></p></li><li style="font-size: inherit;color: inherit;line-height: inherit;margin-bottom: 0.5em;"><p>我们的目标是创建这样一个图像，它将接近内容图像和样式图像。这将由两个损失函数确定：<br/>基于CNN在当前图像和内容图像的某些层提取的特征来计算内容损失<br/>使用Gram矩阵以一种巧妙的方式计算当前图像和样式图像之间的样式损失</p></li><li style="font-size: inherit;color: inherit;line-height: inherit;margin-bottom: 0.5em;"><p><span style="font-size: inherit;color: inherit;line-height: inherit;">为了使图像更平滑和去除噪声，我们还引入了变异损失，它计算相邻像素之间的平均距离</span></p></li><li style="font-size: inherit;color: inherit;line-height: inherit;margin-bottom: 0.5em;"><p><span style="font-size: inherit;color: inherit;line-height: inherit;">主优化循环使用梯度下降（或一些其他优化算法）来调整当前图像以最小化总损失，总损失是所有三个损失的加权和。</span></p></li></ul></section><section class="mp_profile_iframe_wrp"><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-alias="" data-from="0" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/su5KXfVp01ZeF9m0RrpOt66M8FlGCsHn3JYWic7GRcuw2HaKRGUoqkacotcvYVp7b2exlmR3ZAfQweFt5QnBFrg/0?wx_fmt=png" data-id="MzIxOTU0OTY2OQ==" data-is_biz_ban="0" data-nickname="python收藏家" data-pluginname="mpprofile" data-signature="记录python学习笔记，分享python相关知识与案例，人生苦短，我用python。 每天不定时更新~"></mp-common-profile></section><p><br/></p><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div>

</div>
                <p></p>
                <p></p>
                <div>本文由“公众号文章抓取器”生成，请忽略上文所有联系方式或指引式信息。有问题可以联系：五人工作室，官网：www.Wuren.Work，QQ微信同号1976.424.585 </div>
                <div  class="hidden">本文由“公众号文章抓取器”生成，请忽略上文所有联系方式或指引式信息。有问题可以联系：五人工作室，官网：www.Wuren.Work，QQ微信同号1976.424.585 <br><p class="hidden">code/s?__biz=MzIxOTU0OTY2OQ==&mid=2247486503&idx=1&sn=00880e0fe7df104dabf5457eeecce291&chksm=97d8d6ada0af5fbbbf44adbe49d8e4d48ff83a8d4e8df0a4252deca8170f38304aaf0d98b104#rd </p></div>
            </body>
            </html>
            