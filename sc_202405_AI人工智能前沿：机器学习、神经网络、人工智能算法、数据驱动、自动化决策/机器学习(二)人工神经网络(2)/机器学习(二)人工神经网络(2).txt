


            
机器学习(二)人工神经网络(2)
          




机器学习(二) 人工神经网络(2)本章主要介绍感知器算法上一章主要介绍了最基本的神经元模型「mp」模型因为太过于简单，并没有得到学术界的重视，直到1957年，「Frank Rosenblatt」从纯数学的角度重新考察这一模型，指出能够从一些输入输出对中通过机器学习的方法，自动获取权重和偏置变量。
提出了感知器算法(「Percetion Algorithm」)❝这里仍然假设输入的样本为,其中为训练样本,分别代表相应的类别❞❝我们的任务是找到一个向量和一个常数，使得对,❞若则若则我们把某个训练数据满足上述条件称之为这个数据获得了平衡，否则叫做没有获得平衡。未获得平衡的关系如下若则若则利用感知器算法寻找,的方法如下随机选择和取一个训练样本若且则若且则再取一个训练样本，回到2:终止条件：直到所有输入输出对，都不满足2中的两个条件之一，退出循环现在来看一下这个算法的意思，观察第二步，当数据处于不平衡状态时，需要对其进行调整。
分析第二步的第一种情形，即当时，调整方式新旧新旧那么这么调整的理由时什么呢，我们将上述调整代入，得到：新新旧旧旧旧旧旧可以看出通过更新，通过调整后，使得距离平衡状态至少近了一点。❝但是这个算法真的停的下来吗，我们要知道数据集是不仅仅只有一组数据，会不会出现使得一组数据得到平衡状态，却使得另外一组数据不平衡的情况。如果是这样，那么这个调整进入一个死循环❞❝(「Percetion Algorithm」)发明感知器算法最伟大的地方是证明了只要训练数据线性可分，那么感知器算法就一定可以停下来。我们还需要对任务的表达做一个简化❞首先，对于某个,我们定义它的增广向量如下若则若则定义增广向量的目的是为了简化表达，原来的任务是寻找一个向量和一个常数，使得对,若则若则这样任务就简化为寻找,使得对,有感知器算法收敛定理❝对于个增广向量，如果存在一个权重向量，使得，有❞其实这个收敛条件与线性可分是等价的，运用上述感知器算法，我们一定能在有限步呢，找到一个,使得对于所有内，有「证明」:
不失一般性，设,(这样做的理由是因为向量和向量代表的是同一个平面，因此可以用一个去加权,使得根据感知器算法将这个式子两边同时减去,两边再同时取模，得到展开，再合并，得到此时，
因此有：注意到，对于任意，均有，是一个固定的值，那么一定可以取一个足够大的，使得这样得到假设的初值为,那么经过次迭代，一定会收敛于「证毕」❝可是现实情况往往不需要那么多次迭代，就能收敛❞




