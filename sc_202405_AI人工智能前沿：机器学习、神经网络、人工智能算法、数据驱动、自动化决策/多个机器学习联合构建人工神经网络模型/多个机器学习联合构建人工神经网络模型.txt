


            
多个机器学习联合构建人工神经网络模型
          




机器学习筛选特征基因若仅仅使用单算法，很可能会存在偶然性因此需要多个算法进行联合分析，筛选出共同的高打分特征基因此外，多个算法联合得到特征基因构建的模型更具有预测价值下面直接上代码👇1.准备R包library(readr)library(VIM)library(caret)library(rpart)library(rpart.plot)library(Metrics)library(stringr)library(rpart)library(tibble)library(bitops)library(rattle)library(rpart.plot)library(RColorBrewer)library(tidyverse)library(limma)library(pheatmap)library(visNetwork)library(ggpol)library(ggplot2)library(sparkline)library(randomForest)library(venn)library(sparkline)library(dplyr)library(tidyverse)library(caret)library(DALEX)library(gbm)library(caret)library(glmnet) library(xgboost)library(DALEX)library(gbm)library(VennDiagram)library(limma)  library(neuralnet)library(NeuralNetTools)2.准备数据1）差异基因表达谱文件2）差异基因结果文件3.多个AI算法联合计算1）Gradient Boosting Machine（GBM）fit <- train(x=data,y=as.factor(group),  method = "gbm", trControl = fitControl,verbose = FALSE)2）randomForest（随机森林）rf2=randomForest(as.factor(group)~., data=data, ntree=optionTrees)3）Decision Tree（决策树）mod1<-rpart(as.factor(group)~.,data = data2,method = "class")4）Lassocvfit=cv.glmnet(x, y, family="binomial", alpha=1,type.measure='deviance',nfolds = 10)5）XGboostmodel<- train(x=data,y=as.factor(group),  method = "xgbTree", trControl = TrainControl,verbose = FALSE)4.提取符合打分条件基因




