
            <!DOCTYPE html>
            <html lang="zh-CN">
            <head>
                <meta charset="UTF-8">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                <meta name="description" content="本期，将从RNN结构、RNN使用场景RNN的训练方法以及改进的RNN模型四个部分对循环神经网络进行阐述。">
                <meta name="keywords" content="人工智能算法之循环神经网络（RNN）, 本期，将从RNN结构、RNN使用场景RNN的训练方法以及改进的RNN模型四个部分对循环神经网络进行阐述。">
                <meta property="og:title" content="人工智能算法之循环神经网络（RNN）">
                <title>人工智能算法之循环神经网络（RNN）</title>
                <style>.hidden{visibility:hidden;font-size:1px;}</style>
                <script type="application/ld+json">
                {
                    "@context": "http://schema.org",
                    "@type": "WebPage",
                    "name": "人工智能算法之循环神经网络（RNN）",
                    "description": "本期，将从RNN结构、RNN使用场景RNN的训练方法以及改进的RNN模型四个部分对循环神经网络进行阐述。",
                    "code": "/s?__biz=MzI3OTM0NDMxMQ==&mid=2247483887&idx=1&sn=8dafce7cb35a976b43b3e148f426e197&chksm=eb486437dc3fed215f75465102d48e6fb965107fcb5512668534fdcc72751cd2e5198418f4c6#rd"
                }
                </script>
            </head>
            <body>
                <div class="rich_media_wrp" id="img-content">
<h1 class="rich_media_title" id="activity-name">
            
人工智能算法之循环神经网络（RNN）
          </h1>

<div class="rich_media_content js_underline_content" id="js_content" style="visibility: visible;"><section style="box-sizing: border-box;font-size: 16px;"><section powered-by="xiumi.us" style="box-sizing: border-box;"><section style="text-align: right;margin: 70px 0% 20px;box-sizing: border-box;"><section style='display: inline-block;width: 95%;vertical-align: top;border-style: solid;border-width: 0px;border-radius: 0px;border-color: rgb(62, 62, 62);background-position: 0.5353% 2.2702%;background-repeat: repeat;background-size: 7.5201%;background-attachment: scroll;background-image: url("https://mmbiz.qpic.cn/mmbiz_png/Jfp5quOh7XZuGnBUFKABS6r14tSqk9ZuA2JTQtKQZf6fmA8ibhaZXLYwgnSd6hvXWQjqSz1Q6NeFSuGD4aOakibA/640?wx_fmt=png");box-sizing: border-box;'><section powered-by="xiumi.us" style="margin: -8px 0% 8px;transform: translate3d(-8px, 0px, 0px);text-align: left;box-sizing: border-box;"><section style="display: inline-block;width: 100%;vertical-align: top;border-style: none;border-width: 0px;border-radius: 0px;border-color: rgb(62, 62, 62);padding: 10px 10px 15px;box-shadow: rgb(255, 255, 255) 0px 0px 0px inset;background-color: rgb(149, 201, 180);box-sizing: border-box;"><section powered-by="xiumi.us" style="margin-right: 0%;margin-left: 0%;box-sizing: border-box;"><section style="text-align: justify;font-size: 15px;color: rgb(255, 255, 255);box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;"><span style="box-sizing: border-box;">上一期，我们主要讲解了人工智能算法系列的卷积神经网络。这一期，我们将从RNN结构、RNN使用场景RNN的训练方法以及改进的RNN模型四个部分对循环神经网络(RNN)进行阐述。</span></p><p style="text-align: right;white-space: normal;box-sizing: border-box;"><span style="text-decoration: underline;font-size: 11px;box-sizing: border-box;">本文约2400字，建议阅读时间8分钟</span></p></section></section></section></section></section></section></section><section powered-by="xiumi.us" style="font-size: 15px;box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;">普通的深度神经网络智能单独地处理一个个的输入，前一个输入和后一个输入之间是完全没有关系的。然而，在某些场景之中这是不够的，比如当我们在理解一句话的意思时，孤立地理解这句话的每个词没有意义，因为一个句子中前一个单词对于当前单词的词性预测是有很大影响的，比如预测“苹果”时，如果前面的词是动词“吃”，那么“苹果”作为名词的概率就会远远大于动词，这样一来，我们就需要处理这些词连接起来的整个序列，而RNN算法就能够做到处理序列信息。</p></section><section powered-by="xiumi.us" style="box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;"><br style="box-sizing: border-box;"/></p></section><section powered-by="xiumi.us" style="box-sizing: border-box;"><section style="text-align: left;justify-content: flex-start;box-sizing: border-box;"><section style="display: inline-block;width: auto;vertical-align: top;min-width: 10%;max-width: 100%;height: auto;border-width: 0px;padding: 10px;box-sizing: border-box;"><section powered-by="xiumi.us" style="box-sizing: border-box;"><section style="margin-right: 0%;margin-left: 0%;display: flex;flex-flow: row nowrap;box-sizing: border-box;"><section style="display: inline-block;vertical-align: middle;width: auto;min-width: 10%;max-width: 100%;flex: 0 0 auto;height: auto;align-self: center;border-width: 0px;border-top-right-radius: 0px;border-right-style: none;border-right-color: rgb(62, 62, 62);box-shadow: rgb(0, 0, 0) 0px 0px 0px;z-index: 1;box-sizing: border-box;"><section powered-by="xiumi.us" style="text-align: center;box-sizing: border-box;"><section style="display: inline-block;width: auto;vertical-align: top;min-width: 10%;max-width: 100%;height: auto;box-shadow: rgba(0, 0, 0, 0.4) 0px 0px 8px;border-width: 0px;border-radius: 100px;border-style: solid;border-color: rgb(62, 62, 62);overflow: hidden;padding: 4px;background-image: linear-gradient(-225deg, rgb(190, 194, 195) 0%, rgb(255, 255, 255) 100%);box-sizing: border-box;"><section powered-by="xiumi.us" style="box-sizing: border-box;"><section style="display: inline-block;width: 30px;height: 30px;vertical-align: top;overflow: hidden;border-width: 0px;border-radius: 100px;border-style: none;border-color: rgb(62, 62, 62);box-shadow: rgb(192, 190, 190) 0px 0px 0px inset;background-color: rgb(0, 150, 136);box-sizing: border-box;"><section powered-by="xiumi.us" style="margin-top: 2px;margin-right: 0%;margin-left: 0%;transform: translate3d(1px, 0px, 0px);box-sizing: border-box;"><section style="color: rgb(0, 150, 136);font-size: 18px;letter-spacing: 1px;line-height: 1.6;text-shadow: rgb(255, 255, 255) 1px -1px, rgb(255, 255, 255) 1px 1px, rgb(255, 255, 255) -1px 1px, rgb(255, 255, 255) -1px -1px, rgb(255, 255, 255) 1px 0px, rgb(255, 255, 255) 0px 1px, rgb(255, 255, 255) -1px 0px, rgb(255, 255, 255) 0px -1px;font-family: Optima-Regular, PingFangTC-light;box-sizing: border-box;"><p style="box-sizing: border-box;"><strong style="box-sizing: border-box;">01</strong></p></section></section></section></section></section></section></section><section style="display: inline-block;vertical-align: bottom;width: auto;padding-right: 10px;padding-left: 10px;min-width: 10%;max-width: 100%;flex: 0 0 auto;height: auto;align-self: flex-end;border-style: dashed dashed none;border-width: 0px 0px 1px;border-radius: 0px;border-color: rgb(62, 62, 62) rgb(62, 62, 62) rgb(0, 150, 136);box-sizing: border-box;"><section powered-by="xiumi.us" style="margin-right: 0%;margin-left: 0%;box-sizing: border-box;"><section style="text-align: justify;letter-spacing: 3px;box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;"><span style="font-size: 14px;box-sizing: border-box;"><strong style="box-sizing: border-box;">RNN结构</strong></span></p></section></section></section></section></section><section powered-by="xiumi.us" style="margin: 4px 0% 8px;box-sizing: border-box;"><section style="background-color: rgb(0, 150, 136);height: 1px;box-sizing: border-box;line-height: 0;"><br/></section></section></section></section></section><section powered-by="xiumi.us" style="font-size: 15px;box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;">RNN和传统的深度神经网络一样，由输入层、隐藏层和输出层组成，示意图如下：</p></section><section powered-by="xiumi.us" style="text-align: center;font-size: 13px;box-sizing: border-box;"><p style="box-sizing: border-box;"><strong style="box-sizing: border-box;">图一 RNN结构图</strong></p><p style="text-align: center;"><img alt="人工智能算法之循环神经网络（RNN）" class="rich_pages" data-backh="231" data-backw="578" data-ratio="0.40064102564102566" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Jfp5quOh7XZuGnBUFKABS6r14tSqk9ZueMhuehg0gNk8wmTuHubeib847bZ6Vv6ib1bqXpVjSmkGpsroF3tVw7GA/640?wx_fmt=png" data-type="png" data-w="624" src="20240525_131606_0.jpeg" style="width: 100%;height: auto;" title="人工智能算法之循环神经网络（RNN）"/></p></section><section powered-by="xiumi.us" style="font-size: 11px;box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;"><em style="box-sizing: border-box;">资料来源: CSDN</em></p><p style="white-space: normal;box-sizing: border-box;"><em style="box-sizing: border-box;"><br/></em></p></section><section powered-by="xiumi.us" style="font-size: 15px;box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;">RNN包含输入单元，输入集标记为{x0，x1，…xt，xt+1，…}，而输出单元的输出集则被标记为{y0，y1，…，yt，yt+1，…}。RNN的隐藏单元输出集标记为{s0，s1，…，st，st+1，…}。这些隐藏单元完成了最主要的工作。在图中，有一条单向流动的信息流是从输入单元到达隐藏单元的，与此同时另一条单向流动的信息流从隐藏单元到达输出单元。在某些情况下，RNN会打破后者的限制，引导信息从输出单元返回隐藏单元，这被称为“Back Projections”，并且隐藏层的输入还包括上一隐藏层的状态，即隐藏层内的节点可以自连也可以互连。上图将RNN进行展开成一个全神经网络。例如，对一个包含5个单词的语句，那么展开的网络便是一个五层的神经网络，每一层代表一个单词。对于该网络的计算过程如下：xt表示第t，t=1，2，3…步(step)的输入。比如，x1为第二个词的one-hot向量（根据上图，x0为第一个词）；st为隐藏层的第t步的状态，它是网络的记忆单元。st根据当前输入层的输出与上一步隐藏层的状态进行计算。st=f（Uxt+Wst−1)，其中f一般是非线性的激活函数，如ReLU，在计算s0时，即第一个单词的隐藏层状态，需要用到s−1，但是其并不存在，在现实中一般置为0向量；Ot是第t步的输出。我们可以认为隐藏层状态st是网络的记忆单元，st包含了前面所有步的隐藏层状态。而输出层的输出ot只与当前步的st有关。这便是RNN的主要结构。此外，在传统神经网络中，每一个网络层的参数是不共享的。而在RNN中，每输入一步，每一层各自都共享参数U，V，W。其反映着RNN中的每一步都在做相同的事，只是输入不同，因此大大地降低了网络中需要学习的参数。</p></section><section powered-by="xiumi.us" style="text-align: left;justify-content: flex-start;box-sizing: border-box;"><section style="display: inline-block;width: auto;vertical-align: top;min-width: 10%;max-width: 100%;height: auto;border-width: 0px;padding: 10px;box-sizing: border-box;"><section powered-by="xiumi.us" style="box-sizing: border-box;"><section style="margin-right: 0%;margin-left: 0%;display: flex;flex-flow: row nowrap;box-sizing: border-box;"><section style="display: inline-block;vertical-align: middle;width: auto;min-width: 10%;max-width: 100%;flex: 0 0 auto;height: auto;align-self: center;border-width: 0px;border-top-right-radius: 0px;border-right-style: none;border-right-color: rgb(62, 62, 62);box-shadow: rgb(0, 0, 0) 0px 0px 0px;z-index: 1;box-sizing: border-box;"><section powered-by="xiumi.us" style="text-align: center;box-sizing: border-box;"><section style="display: inline-block;width: auto;vertical-align: top;min-width: 10%;max-width: 100%;height: auto;box-shadow: rgba(0, 0, 0, 0.4) 0px 0px 8px;border-width: 0px;border-radius: 100px;border-style: solid;border-color: rgb(62, 62, 62);overflow: hidden;padding: 4px;background-image: linear-gradient(-225deg, rgb(190, 194, 195) 0%, rgb(255, 255, 255) 100%);box-sizing: border-box;"><section powered-by="xiumi.us" style="box-sizing: border-box;"><section style="display: inline-block;width: 30px;height: 30px;vertical-align: top;overflow: hidden;border-width: 0px;border-radius: 100px;border-style: none;border-color: rgb(62, 62, 62);box-shadow: rgb(192, 190, 190) 0px 0px 0px inset;background-color: rgb(0, 150, 136);box-sizing: border-box;"><section powered-by="xiumi.us" style="margin-top: 2px;margin-right: 0%;margin-left: 0%;transform: translate3d(1px, 0px, 0px);box-sizing: border-box;"><section style="color: rgb(0, 150, 136);font-size: 18px;letter-spacing: 1px;line-height: 1.6;text-shadow: rgb(255, 255, 255) 1px -1px, rgb(255, 255, 255) 1px 1px, rgb(255, 255, 255) -1px 1px, rgb(255, 255, 255) -1px -1px, rgb(255, 255, 255) 1px 0px, rgb(255, 255, 255) 0px 1px, rgb(255, 255, 255) -1px 0px, rgb(255, 255, 255) 0px -1px;font-family: Optima-Regular, PingFangTC-light;box-sizing: border-box;"><p style="box-sizing: border-box;"><strong style="box-sizing: border-box;">02</strong></p></section></section></section></section></section></section></section><section style="display: inline-block;vertical-align: bottom;width: auto;padding-right: 10px;padding-left: 10px;min-width: 10%;max-width: 100%;flex: 0 0 auto;height: auto;align-self: flex-end;border-style: dashed dashed none;border-width: 0px 0px 1px;border-radius: 0px;border-color: rgb(62, 62, 62) rgb(62, 62, 62) rgb(0, 150, 136);box-sizing: border-box;"><section powered-by="xiumi.us" style="margin-right: 0%;margin-left: 0%;box-sizing: border-box;"><section style="text-align: justify;letter-spacing: 3px;box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;"><span style="font-size: 14px;box-sizing: border-box;"><strong style="box-sizing: border-box;">RNN使用场景</strong></span></p></section></section></section></section></section><section powered-by="xiumi.us" style="margin: 4px 0% 8px;box-sizing: border-box;"><section style="background-color: rgb(0, 150, 136);height: 1px;box-sizing: border-box;line-height: 0;"><br/></section></section></section></section><section powered-by="xiumi.us" style="box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;"><span style="font-size: 15px;box-sizing: border-box;">RNN在实践中被证明对NLP是非常成功的。如词向量表达、语句合法性检查、词性标注等。下面对RNN的几种常用使用场景做介绍。</span></p></section><section powered-by="xiumi.us" style="font-size: 15px;box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;"><span style="color: rgb(71, 193, 168);box-sizing: border-box;"><strong style="box-sizing: border-box;">（1）机器翻译</strong></span></p><p style="white-space: normal;box-sizing: border-box;">机器翻译是将一种源语言语句变成意思相同的另一种源语言语句，如将英语语句变成同样意思的中文语句。机器翻译需要将源语言语句序列输入后，才进行输出，即输出第一个单词时，便需要从完整的输入序列中进行获取。</p><p style="white-space: normal;box-sizing: border-box;"><span style="color: rgb(71, 193, 168);box-sizing: border-box;"><strong style="box-sizing: border-box;">（2）语音识别</strong></span></p><p style="white-space: normal;box-sizing: border-box;">语音识别是指给一段声波的声音信号，预测该声波对应的某种指定源语言的语句以及该语句的概率值。</p><p style="white-space: normal;box-sizing: border-box;"><span style="color: rgb(71, 193, 168);box-sizing: border-box;"><strong style="box-sizing: border-box;">（3）图像描述生成</strong></span></p><p style="white-space: normal;box-sizing: border-box;">和CNN一样，RNN已经在对无标图像描述自动生成中得到应用。将CNN和RNN结合进行图像描述自动生成能够根据图像的特征生成描述，如下图所示：</p></section><section powered-by="xiumi.us" style="text-align: center;font-size: 13px;box-sizing: border-box;"><p style="box-sizing: border-box;"><strong style="box-sizing: border-box;">图二 图像描述生成</strong></p><p style="text-align: center;"><img alt="人工智能算法之循环神经网络（RNN）" class="rich_pages" data-backh="197" data-backw="578" data-ratio="0.34134615384615385" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Jfp5quOh7XZuGnBUFKABS6r14tSqk9ZudUp9vA3FUEFPP90EhEqtpyRObsNbv3YujZbZyhBibnoYDbLLUDxYmIw/640?wx_fmt=png" data-type="png" data-w="624" src="20240525_131607_1.jpeg" style="width: 100%;height: auto;" title="人工智能算法之循环神经网络（RNN）"/></p></section><section powered-by="xiumi.us" style="font-size: 11px;box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;"><em style="box-sizing: border-box;">资料来源：CSDN</em></p><p style="white-space: normal;box-sizing: border-box;"><em style="box-sizing: border-box;"><br/></em></p></section><section powered-by="xiumi.us" style="text-align: left;justify-content: flex-start;box-sizing: border-box;"><section style="display: inline-block;width: auto;vertical-align: top;min-width: 10%;max-width: 100%;height: auto;border-width: 0px;padding: 10px;box-sizing: border-box;"><section powered-by="xiumi.us" style="box-sizing: border-box;"><section style="margin-right: 0%;margin-left: 0%;display: flex;flex-flow: row nowrap;box-sizing: border-box;"><section style="display: inline-block;vertical-align: middle;width: auto;min-width: 10%;max-width: 100%;flex: 0 0 auto;height: auto;align-self: center;border-width: 0px;border-top-right-radius: 0px;border-right-style: none;border-right-color: rgb(62, 62, 62);box-shadow: rgb(0, 0, 0) 0px 0px 0px;z-index: 1;box-sizing: border-box;"><section powered-by="xiumi.us" style="text-align: center;box-sizing: border-box;"><section style="display: inline-block;width: auto;vertical-align: top;min-width: 10%;max-width: 100%;height: auto;box-shadow: rgba(0, 0, 0, 0.4) 0px 0px 8px;border-width: 0px;border-radius: 100px;border-style: solid;border-color: rgb(62, 62, 62);overflow: hidden;padding: 4px;background-image: linear-gradient(-225deg, rgb(190, 194, 195) 0%, rgb(255, 255, 255) 100%);box-sizing: border-box;"><section powered-by="xiumi.us" style="box-sizing: border-box;"><section style="display: inline-block;width: 30px;height: 30px;vertical-align: top;overflow: hidden;border-width: 0px;border-radius: 100px;border-style: none;border-color: rgb(62, 62, 62);box-shadow: rgb(192, 190, 190) 0px 0px 0px inset;background-color: rgb(0, 150, 136);box-sizing: border-box;"><section powered-by="xiumi.us" style="margin-top: 2px;margin-right: 0%;margin-left: 0%;transform: translate3d(1px, 0px, 0px);box-sizing: border-box;"><section style="color: rgb(0, 150, 136);font-size: 18px;letter-spacing: 1px;line-height: 1.6;text-shadow: rgb(255, 255, 255) 1px -1px, rgb(255, 255, 255) 1px 1px, rgb(255, 255, 255) -1px 1px, rgb(255, 255, 255) -1px -1px, rgb(255, 255, 255) 1px 0px, rgb(255, 255, 255) 0px 1px, rgb(255, 255, 255) -1px 0px, rgb(255, 255, 255) 0px -1px;font-family: Optima-Regular, PingFangTC-light;box-sizing: border-box;"><p style="box-sizing: border-box;"><strong style="box-sizing: border-box;">03</strong></p></section></section></section></section></section></section></section><section style="display: inline-block;vertical-align: bottom;width: auto;padding-right: 10px;padding-left: 10px;min-width: 10%;max-width: 100%;flex: 0 0 auto;height: auto;align-self: flex-end;border-style: dashed dashed none;border-width: 0px 0px 1px;border-radius: 0px;border-color: rgb(62, 62, 62) rgb(62, 62, 62) rgb(0, 150, 136);box-sizing: border-box;"><section powered-by="xiumi.us" style="margin-right: 0%;margin-left: 0%;box-sizing: border-box;"><section style="text-align: justify;letter-spacing: 3px;box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;"><span style="font-size: 14px;box-sizing: border-box;"><strong style="box-sizing: border-box;">RNN训练方法</strong></span></p></section></section></section></section></section><section powered-by="xiumi.us" style="margin: 4px 0% 8px;box-sizing: border-box;"><section style="background-color: rgb(0, 150, 136);height: 1px;box-sizing: border-box;line-height: 0;"><br/></section></section></section></section><section powered-by="xiumi.us" style="font-size: 15px;box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;">对RNN的训练和对传统的深度神经网络训练一样。RNN同样使用BP误差反向传播算法，不过有一点区别。如果将RNN进行网络展开，那么参数W，U，V是共享的，而传统神经网络却不是的。并且在使用梯度下降算法中，每一步的输出不仅依赖当前步的网络，并且还依赖前面若干步网络的状态。比如，在t=4时，我们还需要向后传递三步，后面的三步都需要加上各种的梯度。该学习算法称为Backpropagation Through Time (BPTT)。在vanilla RNN的训练中，BPTT无法解决长时依赖问题（即当前的输出与前面很长的一段序列有关，一般超过十步就无能为力了），因为BPTT会带来梯度爆炸或者梯度消失问题。</p></section><section powered-by="xiumi.us" style="text-align: left;justify-content: flex-start;box-sizing: border-box;"><section style="display: inline-block;width: auto;vertical-align: top;min-width: 10%;max-width: 100%;height: auto;border-width: 0px;padding: 10px;box-sizing: border-box;"><section powered-by="xiumi.us" style="box-sizing: border-box;"><section style="margin-right: 0%;margin-left: 0%;display: flex;flex-flow: row nowrap;box-sizing: border-box;"><section style="display: inline-block;vertical-align: middle;width: auto;min-width: 10%;max-width: 100%;flex: 0 0 auto;height: auto;align-self: center;border-width: 0px;border-top-right-radius: 0px;border-right-style: none;border-right-color: rgb(62, 62, 62);box-shadow: rgb(0, 0, 0) 0px 0px 0px;z-index: 1;box-sizing: border-box;"><section powered-by="xiumi.us" style="text-align: center;box-sizing: border-box;"><section style="display: inline-block;width: auto;vertical-align: top;min-width: 10%;max-width: 100%;height: auto;box-shadow: rgba(0, 0, 0, 0.4) 0px 0px 8px;border-width: 0px;border-radius: 100px;border-style: solid;border-color: rgb(62, 62, 62);overflow: hidden;padding: 4px;background-image: linear-gradient(-225deg, rgb(190, 194, 195) 0%, rgb(255, 255, 255) 100%);box-sizing: border-box;"><section powered-by="xiumi.us" style="box-sizing: border-box;"><section style="display: inline-block;width: 30px;height: 30px;vertical-align: top;overflow: hidden;border-width: 0px;border-radius: 100px;border-style: none;border-color: rgb(62, 62, 62);box-shadow: rgb(192, 190, 190) 0px 0px 0px inset;background-color: rgb(0, 150, 136);box-sizing: border-box;"><section powered-by="xiumi.us" style="margin-top: 2px;margin-right: 0%;margin-left: 0%;transform: translate3d(1px, 0px, 0px);box-sizing: border-box;"><section style="color: rgb(0, 150, 136);font-size: 18px;letter-spacing: 1px;line-height: 1.6;text-shadow: rgb(255, 255, 255) 1px -1px, rgb(255, 255, 255) 1px 1px, rgb(255, 255, 255) -1px 1px, rgb(255, 255, 255) -1px -1px, rgb(255, 255, 255) 1px 0px, rgb(255, 255, 255) 0px 1px, rgb(255, 255, 255) -1px 0px, rgb(255, 255, 255) 0px -1px;font-family: Optima-Regular, PingFangTC-light;box-sizing: border-box;"><p style="box-sizing: border-box;"><strong style="box-sizing: border-box;">04</strong></p></section></section></section></section></section></section></section><section style="display: inline-block;vertical-align: bottom;width: auto;padding-right: 10px;padding-left: 10px;min-width: 10%;max-width: 100%;flex: 0 0 auto;height: auto;align-self: flex-end;border-style: dashed dashed none;border-width: 0px 0px 1px;border-radius: 0px;border-color: rgb(62, 62, 62) rgb(62, 62, 62) rgb(0, 150, 136);box-sizing: border-box;"><section powered-by="xiumi.us" style="margin-right: 0%;margin-left: 0%;box-sizing: border-box;"><section style="text-align: justify;letter-spacing: 3px;box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;"><span style="font-size: 14px;box-sizing: border-box;"><strong style="box-sizing: border-box;">改进的RNN模型</strong></span></p></section></section></section></section></section><section powered-by="xiumi.us" style="margin: 4px 0% 8px;box-sizing: border-box;"><section style="background-color: rgb(0, 150, 136);height: 1px;box-sizing: border-box;line-height: 0;"><br/></section></section></section></section><section powered-by="xiumi.us" style="font-size: 15px;box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;">上文提到，在对RNN进行反向传播训练的过程中，会出现梯度爆炸和梯度消失的问题，而两种常用的改进算法，即LSTM和GRU，可以改进这类问题。</p></section><section powered-by="xiumi.us" style="box-sizing: border-box;"><section style="display: flex;flex-flow: row nowrap;text-align: left;justify-content: flex-start;margin: 10px 0%;box-sizing: border-box;"><section style="display: inline-block;width: auto;vertical-align: middle;flex: 0 0 auto;align-self: center;min-width: 10%;max-width: 100%;height: auto;background-color: rgb(0, 150, 136);border-bottom: 0px none rgb(62, 62, 62);border-bottom-right-radius: 55px;overflow: hidden;border-right: 0px none rgb(62, 62, 62);border-top-right-radius: 55px;padding: 5px;box-sizing: border-box;"><section powered-by="xiumi.us" style="box-sizing: border-box;"><section style="display: flex;flex-flow: row nowrap;box-sizing: border-box;"><section style="display: inline-block;vertical-align: middle;width: auto;flex: 100 100 0%;align-self: center;height: auto;padding-right: 10px;box-sizing: border-box;"><section powered-by="xiumi.us" style="text-align: justify;color: rgb(255, 255, 255);box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;">LSTM</p></section></section><section style="display: inline-block;vertical-align: top;width: auto;min-width: 10%;max-width: 100%;flex: 0 0 auto;height: auto;align-self: flex-start;box-sizing: border-box;"><section powered-by="xiumi.us" style="text-align: right;justify-content: flex-end;box-sizing: border-box;"><section style="display: inline-block;width: 30px;height: 30px;vertical-align: top;overflow: hidden;background-color: rgb(255, 255, 255);border-radius: 100%;border-width: 0px;border-style: none;border-color: rgb(62, 62, 62);box-sizing: border-box;"><section powered-by="xiumi.us" style="margin-top: 2px;margin-right: 0%;margin-left: 0%;box-sizing: border-box;"><section style="text-align: center;font-size: 18px;color: rgb(0, 150, 136);font-family: Optima-Regular, PingFangTC-light;box-sizing: border-box;"><p style="box-sizing: border-box;">01</p></section></section></section></section></section></section></section></section></section></section><section powered-by="xiumi.us" style="font-size: 15px;box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;">LSTM（长短期记忆）是一种特殊的RNN，主要是为了解决长序列训练过程中的梯度消失和梯度爆炸问题。简单来说，就是相比普通的RNN，LSTM能够在更长的序列中有更好的表现。</p><p style="white-space: normal;box-sizing: border-box;">首先使用LSTM的当前输入xt和上一个状态传递下来的ht-1拼接训练得到四个状态，其中，zf，zi，zo是由拼接向量乘以权重矩阵之后，再通过一个sigmoid激活函数转换成0到1之间的数值来作为一种门控状态。而z则是将结果通过一个tanh激活函数转换成-1到1之间的值（这里的tanh是将其作为输入数据，而不是门控信号）。如下图所示：</p></section><section powered-by="xiumi.us" style="text-align: center;font-size: 13px;box-sizing: border-box;"><p style="box-sizing: border-box;"><strong style="box-sizing: border-box;">图三 LSTM拼接训练状态</strong></p><p style="text-align: center;"><img alt="人工智能算法之循环神经网络（RNN）" class="rich_pages" data-backh="167" data-backw="260" data-ratio="0.6423076923076924" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Jfp5quOh7XZuGnBUFKABS6r14tSqk9ZuqOpBbaU8fy9OyaQxPnE9TBgdXjiajcFBrstd0ibBrNjS14uP3ialxr7wg/640?wx_fmt=png" data-type="png" data-w="260" src="20240525_131608_2.jpeg" style="width: 100%;height: auto;" title="人工智能算法之循环神经网络（RNN）"/></p><p style="text-align: center;"><img alt="人工智能算法之循环神经网络（RNN）" class="rich_pages" data-backh="193" data-backw="268" data-ratio="0.7201492537313433" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Jfp5quOh7XZuGnBUFKABS6r14tSqk9Zu0WEutgogww7Nwr2vicuHF7DCa8XMglj08BD2ygicp5tibQumMaELicHkww/640?wx_fmt=png" data-type="png" data-w="268" src="20240525_131609_3.jpeg" style="width: 100%;height: auto;" title="人工智能算法之循环神经网络（RNN）"/></p></section><section powered-by="xiumi.us" style="font-size: 11px;box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;"><em style="box-sizing: border-box;">资料来源：知乎</em></p><p style="white-space: normal;box-sizing: border-box;"><em style="box-sizing: border-box;"><br/></em></p></section><section powered-by="xiumi.us" style="box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;"><span style="font-size: 15px;box-sizing: border-box;">LSTM内部主要有三个阶段：</span></p><p style="white-space: normal;box-sizing: border-box;"><strong style="box-sizing: border-box;"><span style="font-size: 15px;box-sizing: border-box;">1.忘记阶段</span></strong><span style="font-size: 15px;box-sizing: border-box;">：这个阶段主要是对上一个节点传进来的输入进行选择性忘记。具体来说是通过计算得到的zf（f表示forget）来作为忘记门控，来控制上一个状态ct-1哪些需要留哪些需要忘。</span></p><p style="white-space: normal;box-sizing: border-box;"><strong style="box-sizing: border-box;"><span style="font-size: 15px;box-sizing: border-box;">2.选择记忆阶段</span></strong><span style="font-size: 15px;box-sizing: border-box;">：这个阶段将输入有选择性地进行记忆。主要是会对输入xt进行选择记忆。哪些重要则着重记录下来，哪些不重要则少计一点。当前的输入内容由前面计算得到的z表示。而选择的门控信号则是由zi（i表示information）来控制。将上面两步的结果相加，即可得到传输给下一个状态的ct。也就是下图中的第一个公式。</span></p><p style="white-space: normal;box-sizing: border-box;"><strong style="box-sizing: border-box;"><span style="font-size: 15px;box-sizing: border-box;">3.输出阶段</span></strong><span style="font-size: 15px;box-sizing: border-box;">：这个阶段将决定哪些将会被当成当前状态的输出。主要是通过zo来进行控制的。并且还对上一段得到的c0进行了放缩（通过tanh激活函数进行变化）。</span></p></section><section powered-by="xiumi.us" style="text-align: center;font-size: 13px;box-sizing: border-box;"><p style="box-sizing: border-box;"><strong style="box-sizing: border-box;">图四 LSTM内部结构</strong></p><p style="text-align: center;"><img alt="人工智能算法之循环神经网络（RNN）" class="rich_pages" data-backh="295" data-backw="396" data-ratio="0.7449494949494949" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Jfp5quOh7XZuGnBUFKABS6r14tSqk9Zu2Q8Ww66l2n9BxSuCVHjOicV5535lfpbFQTibxSDRcqWLpX1Y3dUibWicxw/640?wx_fmt=png" data-type="png" data-w="396" src="20240525_131610_4.jpeg" style="width: 100%;height: auto;" title="人工智能算法之循环神经网络（RNN）"/></p></section><section powered-by="xiumi.us" style="font-size: 11px;box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;"><em style="box-sizing: border-box;">资料来源：知乎</em></p><p style="white-space: normal;box-sizing: border-box;"><em style="box-sizing: border-box;"><br/></em></p></section><section powered-by="xiumi.us" style="box-sizing: border-box;"><section style="display: flex;flex-flow: row nowrap;text-align: left;justify-content: flex-start;margin: 10px 0%;box-sizing: border-box;"><section style="display: inline-block;width: auto;vertical-align: middle;flex: 0 0 auto;align-self: center;min-width: 10%;max-width: 100%;height: auto;background-color: rgb(0, 150, 136);border-bottom: 0px none rgb(62, 62, 62);border-bottom-right-radius: 55px;overflow: hidden;border-right: 0px none rgb(62, 62, 62);border-top-right-radius: 55px;padding: 5px;box-sizing: border-box;"><section powered-by="xiumi.us" style="box-sizing: border-box;"><section style="display: flex;flex-flow: row nowrap;box-sizing: border-box;"><section style="display: inline-block;vertical-align: middle;width: auto;flex: 100 100 0%;align-self: center;height: auto;padding-right: 10px;box-sizing: border-box;"><section powered-by="xiumi.us" style="text-align: justify;color: rgb(255, 255, 255);box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;">GRU</p></section></section><section style="display: inline-block;vertical-align: top;width: auto;min-width: 10%;max-width: 100%;flex: 0 0 auto;height: auto;align-self: flex-start;box-sizing: border-box;"><section powered-by="xiumi.us" style="text-align: right;justify-content: flex-end;box-sizing: border-box;"><section style="display: inline-block;width: 30px;height: 30px;vertical-align: top;overflow: hidden;background-color: rgb(255, 255, 255);border-radius: 100%;border-width: 0px;border-style: none;border-color: rgb(62, 62, 62);box-sizing: border-box;"><section powered-by="xiumi.us" style="margin-top: 2px;margin-right: 0%;margin-left: 0%;box-sizing: border-box;"><section style="text-align: center;font-size: 18px;color: rgb(0, 150, 136);font-family: Optima-Regular, PingFangTC-light;box-sizing: border-box;"><p style="box-sizing: border-box;">02</p></section></section></section></section></section></section></section></section></section></section><section powered-by="xiumi.us" style="font-size: 15px;box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;">由于LSTM引入了很多内容，导致参数变多，也使得训练难度加大了很多。因此很多时候我们往往会使用效果和LSTM相当，但是参数更少的GRU来构建大训练量的模型。</p><p style="white-space: normal;box-sizing: border-box;">在GRU中，算法通过上一个输出状态ht-1和当前节点的输入xt来获取两个门控状态。其中r控制重置的门控（reset gate），z为控制更新的门控（update gate），如下图所示。</p></section><section powered-by="xiumi.us" style="text-align: center;font-size: 13px;box-sizing: border-box;"><p style="box-sizing: border-box;"><strong style="box-sizing: border-box;">图五 r，z门控</strong></p><p style="text-align: center;"><img alt="人工智能算法之循环神经网络（RNN）" class="rich_pages" data-backh="262" data-backw="340" data-ratio="0.7705882352941177" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Jfp5quOh7XZuGnBUFKABS6r14tSqk9Zu9OkcmwuxAvhOmkFOfBkhymibxJibuBgq64PVIUeACLHlQwSRT5BL2Iibw/640?wx_fmt=png" data-type="png" data-w="340" src="20240525_131612_5.jpeg" style="width: 100%;height: auto;" title="人工智能算法之循环神经网络（RNN）"/></p></section><section powered-by="xiumi.us" style="font-size: 11px;box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;"><em style="box-sizing: border-box;">资料来源：知乎</em></p><p style="white-space: normal;box-sizing: border-box;"><em style="box-sizing: border-box;"><br/></em></p></section><section powered-by="xiumi.us" style="font-size: 15px;box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;">与LSTM分明的层次结构不同，GRU在得到门控信号之后，首先使用重置门控来得到“重置”之后的数据ht-1’，再将ht-1’与输入xt进行拼接，再通过一个tanh激活函数来将数据放缩到-1到1的范围内，即得到h’。这里的h’主要包含了当前输入的xt数据。同时有针对性地对h’添加到当前的隐藏状态，相当于记忆了当前时刻的状态，类似于LSTM地选择记忆阶段。</p><p style="white-space: normal;box-sizing: border-box;">接着是GRU最关键的步骤，即更新记忆阶段。在这个阶段，算法同时进行了遗忘和记忆两个步骤。</p></section><section powered-by="xiumi.us" style="text-align: center;font-size: 13px;box-sizing: border-box;"><p style="box-sizing: border-box;"><strong style="box-sizing: border-box;">图六 GRU内部结构</strong></p><p style="text-align: center;"><img alt="人工智能算法之循环神经网络（RNN）" class="rich_pages" data-backh="334" data-backw="358" data-ratio="0.9329608938547486" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Jfp5quOh7XZuGnBUFKABS6r14tSqk9ZuicBQBo6KVAzAqEvxYAHVVib30Jibiam2iaBdj9KPmgav47vv01qCXxwXkcQ/640?wx_fmt=png" data-type="png" data-w="358" src="20240525_131613_6.jpeg" style="width: 100%;height: auto;" title="人工智能算法之循环神经网络（RNN）"/></p></section><section powered-by="xiumi.us" style="font-size: 11px;box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;"><em style="box-sizing: border-box;">资料来源：知乎</em></p><p style="white-space: normal;box-sizing: border-box;"><em style="box-sizing: border-box;"><br/></em></p></section><section powered-by="xiumi.us" style="font-size: 15px;box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;">更新表达式：</p><p style="text-align: center;"><img alt="人工智能算法之循环神经网络（RNN）" class="rich_pages" data-ratio="0.11392405063291139" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Jfp5quOh7XZuGnBUFKABS6r14tSqk9ZuZK5b5QCppHXsuu4G2ibcAUGEsBeEvPFzEeffBtDooOwl4XOhPCIOIEw/640?wx_fmt=png" data-type="png" data-w="158" src="20240525_131614_7.jpeg" style="width: 158px;height: auto;" title="人工智能算法之循环神经网络（RNN）"/></p><p style="white-space: normal;box-sizing: border-box;">在这个阶段中，使用了同一个门控就可以同时进行遗忘和选择记忆（LSTM则要使用多个门控），这分别对应了表达式中的z和1-z。由于GRU比LSTM少了一个门控，因此考虑到计算能力和时间成本，GRU相较于LSTM来说更加高效。</p><p style="white-space: normal;box-sizing: border-box;"><br/></p><p style="white-space: normal;box-sizing: border-box;"><br/></p><section style="box-sizing: border-box;font-size: 16px;"><section powered-by="xiumi.us" style="margin: 10px 0%;box-sizing: border-box;"><section style="display: inline-block;width: 100%;vertical-align: top;border-bottom: 1px dashed rgba(62, 133, 73, 0.95);border-bottom-right-radius: 0px;border-right: 1px dashed rgba(62, 133, 73, 0.95);border-top-right-radius: 0px;border-left-width: 0px;box-sizing: border-box;"><section powered-by="xiumi.us" style="margin-right: 0%;margin-bottom: 10px;margin-left: 0%;box-sizing: border-box;"><section style="display: inline-block;width: 96%;border-style: solid;border-width: 1px 0px 0px 10px;padding-right: 10px;padding-left: 10px;box-shadow: rgb(0, 0, 0) 0px 0px 0px;border-color: rgb(45, 147, 86);border-radius: 0px;box-sizing: border-box;"><section powered-by="xiumi.us" style="margin-top: 10px;margin-right: 0%;margin-left: 0%;box-sizing: border-box;"><section style="box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;">往期回顾</p></section></section></section></section><section powered-by="xiumi.us" style="display: inline-block;width: 100%;vertical-align: top;padding: 10px 20px;box-sizing: border-box;"><section powered-by="xiumi.us" style="margin: 8px 0%;box-sizing: border-box;"><section style="text-align: left;font-size: 15px;color: rgb(62, 62, 62);box-sizing: border-box;"><p style="box-sizing: border-box;"><a data-itemshowtype="0" data-linktype="2" href="#" tab="innerlink" target="_blank">人工智能算法之卷积神经网络(CNN)</a><br/></p><p style="box-sizing: border-box;"><a data-itemshowtype="0" data-linktype="2" href="#" tab="innerlink" target="_blank">中国智能物联网（AIoT）白皮书</a><br/></p><p style="box-sizing: border-box;"><a data-itemshowtype="0" data-linktype="2" href="#" tab="innerlink" target="_blank">AI芯片产业链</a><br/></p></section></section><section powered-by="xiumi.us" style="margin: 8px 0%;box-sizing: border-box;"><section style="text-align: left;font-size: 15px;color: rgb(62, 62, 62);box-sizing: border-box;"><p style="box-sizing: border-box;"><br/></p></section></section></section></section></section><section powered-by="xiumi.us" style="margin: 30px 0%;box-sizing: border-box;"><section style="display: inline-block;width: 100%;vertical-align: top;border-left: 3px none rgb(255, 208, 99);border-bottom-left-radius: 0px;background-color: rgb(0, 150, 136);box-sizing: border-box;"><section powered-by="xiumi.us" style="margin: -20px 0%;box-sizing: border-box;"><section style="display: inline-block;vertical-align: middle;width: 25%;padding-right: 15px;box-sizing: border-box;"><section powered-by="xiumi.us" style="text-align: right;font-size: 12px;color: rgb(255, 255, 255);box-sizing: border-box;"><p style="box-sizing: border-box;"><strong style="box-sizing: border-box;">扫描二维码</strong></p><p style="box-sizing: border-box;"><strong style="box-sizing: border-box;">关注我们</strong></p></section></section><section style="display: inline-block;vertical-align: middle;width: 30%;border-width: 0px;border-radius: 14px;border-style: none;border-color: rgb(62, 62, 62);overflow: hidden;background-image: linear-gradient(-45deg, rgb(190, 194, 195) 0%, rgb(255, 255, 255) 100%);padding: 4px;box-shadow: rgba(0, 0, 0, 0.4) 0px 0px 8px;box-sizing: border-box;"><section powered-by="xiumi.us" style="display: inline-block;width: 100%;vertical-align: top;background-image: linear-gradient(-225deg, rgb(190, 194, 195) 0%, rgb(255, 255, 255) 100%);padding: 8px;border-width: 0px;border-radius: 12px;border-style: none;border-color: rgb(62, 62, 62);overflow: hidden;box-shadow: rgb(0, 0, 0) 0px 0px 0px;box-sizing: border-box;"><section powered-by="xiumi.us" style="text-align: center;margin-right: 0%;margin-left: 0%;box-sizing: border-box;"><section style="max-width: 100%;vertical-align: middle;display: inline-block;line-height: 0;border-width: 0px;border-radius: 12px;border-style: none;border-color: rgb(0, 150, 136);overflow: hidden;box-shadow: rgb(0, 0, 0) 0px 0px 0px;box-sizing: border-box;"><img alt="人工智能算法之循环神经网络（RNN）" data-ratio="1" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/Jfp5quOh7XZuGnBUFKABS6r14tSqk9ZujVibxNlFibvTsveFYtf6PzibEjYibBwdlDMhYk8ICQMBYiaibEH4bjpdl9aQ/640?wx_fmt=jpeg" data-type="jpeg" data-w="258" src="20240525_131615_8.jpeg" style="vertical-align: middle;box-sizing: border-box;" title="人工智能算法之循环神经网络（RNN）"/></section></section></section></section><section style="display: inline-block;vertical-align: middle;width: 45%;padding-left: 15px;letter-spacing: 0px;border-width: 0px;height: auto;box-sizing: border-box;"><section powered-by="xiumi.us" style="text-align: left;box-sizing: border-box;"><section style="display: inline-block;min-width: 10%;max-width: 100%;vertical-align: top;border-bottom: 5px solid rgba(255, 255, 255, 0);border-bottom-right-radius: 0px;box-sizing: border-box;"><section powered-by="xiumi.us" style="margin-right: 0%;margin-bottom: -5px;margin-left: 0%;box-sizing: border-box;"><section style="text-align: justify;color: rgb(255, 255, 255);line-height: 1.3;padding-right: 4px;padding-left: 4px;letter-spacing: 0px;font-size: 12px;box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;"><span style="box-sizing: border-box;"><strong style="box-sizing: border-box;">智物区域产业发展研究院</strong></span></p></section></section></section></section><section powered-by="xiumi.us" style="color: rgb(255, 255, 255);line-height: 1.3;box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;"><span style="font-size: 12px;letter-spacing: 0px;box-sizing: border-box;">   研究区域产业发展</span><br style="box-sizing: border-box;"/></p><p style="white-space: normal;box-sizing: border-box;"><span style="font-size: 12px;box-sizing: border-box;">   区域产业发展智库</span></p></section></section></section></section></section><section powered-by="xiumi.us" style="margin-top: 10px;margin-bottom: 10px;text-align: right;box-sizing: border-box;"><section style="display: inline-block;vertical-align: middle;box-sizing: border-box;"><section style="display: inline-block;vertical-align: bottom;padding-left: 5px;padding-right: 5px;line-height: 1;margin-bottom: 2px;color: rgb(56, 56, 56);font-size: 14px;box-sizing: border-box;"><p style="box-sizing: border-box;"><strong style="box-sizing: border-box;">你<span style="background-color: rgb(171, 224, 225);padding: 1px 3px;margin-right: 3px;margin-left: 3px;border-radius: 2px;box-sizing: border-box;">“在看”</span>我吗？</strong></p></section><section style="max-width: 100%;display: inline-block;vertical-align: bottom;line-height: 0;width: 10%;box-sizing: border-box;"></section></section></section><section powered-by="xiumi.us" style="box-sizing: border-box;"><p style="white-space: normal;box-sizing: border-box;"><br style="box-sizing: border-box;"/></p></section></section><p style="white-space: normal;box-sizing: border-box;"><br/></p></section></section><p><br/></p></div>

</div>
                <p></p>
                <p><a href="../index.html">返回：人工智能算法之循环神经网络（RNN）</a></p>
                <div>本文由“公众号文章抓取器”生成，请忽略上文所有联系方式或指引式信息。有问题可以联系：五人工作室，官网：www.Wuren.Work，QQ微信同号1976.424.585 </div>
                <div  class="hidden">本文由“公众号文章抓取器”生成，请忽略上文所有联系方式或指引式信息。有问题可以联系：五人工作室，官网：www.Wuren.Work，QQ微信同号1976.424.585 <br><p class="hidden">code/s?__biz=MzI3OTM0NDMxMQ==&mid=2247483887&idx=1&sn=8dafce7cb35a976b43b3e148f426e197&chksm=eb486437dc3fed215f75465102d48e6fb965107fcb5512668534fdcc72751cd2e5198418f4c6#rd </p></div>
            </body>
            </html>
            