


            
AI深度伪造视频，你能认出来吗？
          




有句老话叫做“眼见为实”，然而AI技术的迅猛发展正在改变这一切，大量“深度伪造”的视频和音频流入日常生活中，我们可能很快就不再知道如何判断什么是真的，什么是假的。最近“换头”软件ZAO火了，众多用户将各种影视剧中的明星脸替换成自己的头像，一时朋友圈被各路“山寨明星”占领。 其实，Zao所使用的AI换头技术并不鲜见。今年年初，一位B站博主肖先生动用Deepfakes技术，将94版《射雕》中的黄蓉由演员朱茵换成了杨幂，合成结果十分逼真，毫无违和感。 在全球范围内，被换脸的不仅有娱乐圈明星，还有硅谷的互联网大佬，和政坛的权势人物。 此前，有人通过剪辑、拼接和慢放等手段，制作了一段美国众议院议长南希·佩洛西的演讲视频。视频中的南希言辞混乱，颠三倒四，宛如深度醉酒。最后，美国国会召开了有史以来第一场有关Deepfakes技术的听证会，探讨AI换脸的正当性。 Deepfakes到底可以做到多逼真呢？华盛顿大学研究所曾利用Deepfakes技术，成功换脸美国总统奥巴马。视频中的人，无论从相貌声音，还是穿着打扮，都跟真的奥巴马几乎一致，可以轻易蒙蔽肉眼。你能看出下面两个视频，哪个是真的，哪个是AI深度伪造的吗？（答案见底部留言区）视频A视频B 什么是Deepfakes？   Deepfakes 背后的技术并非高深难懂，它来自“深度学习”和“假货”这两个词的组合。简单来说，它是一个通过机器学习技术搭建的系统：让机器学习人的面部特征，然后合成到影片中的面部。 Deepfakes搭建的系统可以通过谷歌图片搜索、网络图库、Youtube视频等途径获取的素材，利用这些素材通过TensorFlow等多个开源库，训练深度学习网络，经过反复训练后，系统就会自动替换脸部信息。 学习样本越多，生成脸谱图的还原度就会越高。这也是为什么政治家和名人往往会成为被冒充的目标，因为在线可用的视觉数据非常多。 由于Deepfakes软件可以在开源平台上使用，因此互联网上的开发者们不断完善，并在其他人的工作基础上进行改进，机器进步的速度就越快，伪造的程度就越高。 Deepfakes的后果   Deepfakes的“面部交换技术”，最初主要用于电影业。但是在之前的几十年里，要想改变视频素材，都需要时间、技术高超的艺术家和大量资金。其中一个最著名的例子是2016年的电影“星球大战外传：侠盗一号”。在电影中，电影制作人使用面部交换和视频合成技术，来重现角色Grand Moff Tarkin。电影中还创作了一部年轻版的莱娅公主。在这两种情况下，原始演员面部的模型都叠加在替身演员身上。在另外一个例子中，出于公众教育目的，项目组专门开发了视频和面部合成软件，用来展现大屠杀幸存者的证词，在博物馆中以互动全息图的方式呈现。然而，Deepfakes技术的出现改变了这场游戏。随着Deepfakes的发展和扩散，任何人都有能力制作一个令人信服的假视频，包括一些可能为了政治或其他恶意目的而“武器化”它的人。就像Photoshop一样，尽管创作者在创建Deepfakes软件时没有恶意，但这并没有阻止人们将其用于恶意目的。在国内，借由AI换脸的黑科技，已经形成了一条完整的色情产业链。100元打包200部换脸情色片，囊括国内一二线女明星，5张照片就可以帮你定制换脸视频，400元就可以购买换脸软件及教程并包教包会，成品情色视频价格从2元1部到30元46部、100元150部和100元200部不等，一般都是打包售卖…… Deepfakes还可以成为传播错误信息的有力工具。如今还没有人因为深度伪造视频，被诬陷犯罪，或被伪造死亡，但是当很难分辨出哪些视频真实存在时，会发生什么？ 还有正在困扰互联网的假新闻，视频比文字或图像更有可能让人们相信虚构的事实发生了，最糟糕的是大多数人在看到它时都无法识别它。 比如，用于政治目的的深度伪造视频，会让假的故事看起来充满“证据”，显示某些政治家承认犯错或做出无耻的陈述，一旦这种假新闻传播起来，后果难以想象。事实上，人工智能声音合成也在快速的发展，AI不仅可以生成虚假视频，还可以为人们生成语音模型。 这意味着你不需要一个人去模仿政治家，而是可以通过训练AI来模仿某位政治家的声音，仿佛他们正在发表一个令人发指的声明。  正是因为Deepfakes被人恶意使用，这项技术让很多人感到前所未有的恐慌，甚至有人质疑这种技术根本就不应该开发出来给大众使用。但技术无罪，对于这些造假的换脸视频到底如何处理？ 目前在大多数国家，没有任何法律处理此类内容，使其难以控制。而Facebook、Twitter、Instagram的做法是不会删除视频，但会告诉用户，这些视频不是真的；承诺不作恶的谷歌更为保守，其旗下Youtebe则彻底删除了这些视频。 如何对抗恶意的Deepfakes？ PS摧毁大众对图片的信任后，Deepfakes也在摧毁大众对视频的信任。没有人想在网络看到自己的面孔说出没说过的话，许多针对个人的伤害，也因为影响不够大而投诉无门。美国正在形成一支Deepfakes纠察队，不仅是学校实验室、研究中心在找寻Deepfakes的破绽，创业潮流也在兴起。 但这是一场造假AI与辨别 AI的竞赛。每篇讨论Deepfakes的论文，仿佛也在同时帮助造假技术修补漏洞，进而更上一层楼。 关上Deepfakes的潘多拉盒子，他们能做到吗？ 位于硅谷的SRI International AI中心希望“以毒攻毒”，用假影片训练算法，让算法辨识虚拟痕迹。在人们上传视频到社交网站时，平台需要重新编码影片。这是个侦测假视频的好时机。 但随着Deepfakes漏洞日渐优化，用算法打算法的难度也日益增加。辨别AI原本就是训练造假AI的一部分，两者刚好在生成对抗性网络的两端。一个是建构程序，一个是认证程序，道高一尺，魔高一丈。 由于Deepfakes的技术在于篡改资料，认证方则搜寻一切篡改资料的痕迹。一种方法是基于像素的视频侦测，视频其实是成千上万帧图片连放，细致到侦测每个像素的改变痕迹，是颇浩大的工程。 此外，假的脸部表情仍有缺陷。假脸部表情往往与其他部分不一致，计算机算法可侦测图片或影片的不一致。 举例来说，初代Deepfakes视频的人物，眨眼方式都有点奇怪。 纽约州立大学奥尔巴尼分校计算机科学副教授Siwei Lyu曾撰文表示，成年人眨眼间隔为2-10秒，一次眨眼需要十分之一到十分之四秒。这是正常影片人物应有的眨眼频率，但很多Deepfakes视频的人做不到。 由于缺乏闭眼影像资料，算法的训练并不完美，视频人物面孔总有一种“哪里不对”的不和谐感。 然而，透过闭眼的脸部影像、或使用视频串列训练，可改善眨眼间隔。假视频的质量总会提高，而研究人员需要继续找寻检测漏洞的方法。 南加大研究者Wael Abd-Almageed表示，社群网络可使用算法大规模辨识Deepfakes。为了做到自动化，研究人员首先建立一个神经网络，“学习”人类说话时如何行动的重要特征。然后，研究人员使用这些参数将假视频的堆栈帧输入AI模型，侦测随时间的不一致性。普渡大学研究人员也采用类似方法，他们认为，随着训练模型的Deepfakes资料量越来越大，模型也会更精确，更容易找出假影片。如何阻止Deepfakes从低俗娱乐发展到操纵民意，是研究者最迫切的动力之一。但愿一键辨假的速度，能追上一键换脸的速度。Deepfakes如同普罗米修斯的火种撒向大地，带来的究竟是温暖还是毁灭，无人知晓。  相关阅读假装AI，有多少人工智能是靠“人工”的“智能”？浮华热潮正在消退 人工智能还能走多远？听说AI很厉害，但最先进的AI仅相当于4岁儿童云+AI，又一次科技革命？人工智能变成“人工智障”，聊天机器人Bug频出要凉了？科大讯飞“AI同传造假”风波：机器翻译替代人工还很遥远被AI宣布“你的死期到了”是怎样一种体验？眼睁睁看着AI行业冲上百万年薪，2018年转行还来得及吗？都说自己是AI公司，你家智能客服真的智能吗？【科技云报道原创】转载请注明“科技云报道”并附本文链接




