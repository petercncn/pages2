


            
深度伪造视频的爆发：AI工具检测和防止操纵
          




深度伪造视频是由人工智能生成的视频，其数量正在爆发式增长，受害者包括普通人、儿童和名人，人数达到了数百万。为了检测和防止有害的深度伪造视频，出现了数字水印和"毒丸"等工具。监管正在努力跟上，但在个人创作和观看深度伪造视频的言论自由问题上面临挑战。施加压力，要求科技公司引入阻碍和障碍，可以帮助打击传播，但完全阻止深度伪造可能是不可能的。非自愿深度伪造视频的受害者所经历的创伤是真实的，即使内容本身是虚假的。将创作和传播定为犯罪行为是一种重要的威慑手段，尽管很难完全执行。人工智能的风险似乎是压倒性的。尽管AI提供了许多好处，但也存在着不良的使用方式。其中一个主要问题就是深度伪造视频：由AI生成的视频、图像或音频，模仿受害者说或做从未发生过的事情。深度伪造视频可以设计成将一个人的样貌叠加到真实的镜头上，也可以完全由计算机生成。Deep Trace在2019年的一项研究发现，96%的深度伪造视频是的。研究员亨利·阿杰表示，虽然这个数字可能已经发生了变化，但深度伪造视频的数量已经爆炸性增长到了数百万。大多数受害者是普通人，但儿童和名人也是被攻击的目标。虽然内容是虚假的，但对受害者来说，创伤是真实的。2021年，一名英国少女在她的深度伪造图片在Snapchat群组中被分享后自杀身亡。随着Dall-E和Stable Diffusion等AI工具的普及，技术水平较低的人更容易制作深度伪造视频。上个月，泰勒·斯威夫特的深度伪造视频在网上流传。埃隆·马斯克禁止在X上搜索她以对抗这种情况。有一些工具和方法可以帮助防止AI操纵：深度伪造检测数字水印清晰地标记由AI生成的内容，提高人们的意识，并帮助平台删除有害的伪造视频。谷歌、Meta和OpenAI计划添加视觉水印和元数据，揭示照片的历史。像Sensity这样的平台通过电子邮件提醒用户，当媒体具有AI指纹时。但即使是明显的伪造视频仍可能对受害者造成心理伤害。"毒丸"防御性工具向图像中添加不可察觉的信号，当输入到AI系统时会破坏它们。例如，Nightshade添加了混淆AI模型但对人类来说图像仍然完好无损的像素。这保护了艺术家的知识产权和个人照片。监管已有10多个州为深度伪造视频的受害者提供法律保护。最近的知名案例增加了联邦压力。美国联邦通信委员会在乔·拜登的恶作剧电话之后禁止了由AI生成的电话。一项新法案将允许受害者起诉深度伪造视频的制作者。但立法面临言论自由问题。有人认为私人制作深度伪造视频类似于个人幻想。如果不分享，是否造成了伤害？这影响了英国法律，禁止分发但不禁止制作深度伪造视频。阿杰认为，将其定为犯罪仍然很重要，以遏制好奇的制作者。政府还可以向搜索引擎、AI开发者和社交媒体平台施加压力，引入阻碍深度伪造视频的措施。在一起名人丑闻后，印度加快了立法进程，并向科技巨头施加压力以防止传播。完全消除可能是不可能的，但增加障碍有助于防止传播，阿杰表示。




