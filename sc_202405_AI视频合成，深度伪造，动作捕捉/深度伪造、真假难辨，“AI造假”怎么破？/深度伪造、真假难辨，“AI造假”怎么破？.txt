深度伪造、真假难辨，“AI造假”怎么破？

正在和你视频通话的人，真的是你熟悉的TA吗？近日，#怀疑对方AI换脸可以摁鼻子#上了热搜。网络安全专家提醒，我们可以让对方摁鼻子、摁脸，由此观察其面部是否出现形变，“真脸”“假脸”一试便知。网友纷纷表示，“这招实用”“学到了”……


近年来，生成式人工智能技术发展势头迅猛，从ChatGPT到Sora，越来越多的AI生成文稿、图片、音视频等出现在我们的生活中。
技术打开了我们的“脑洞”，丰富了大众的视听，增加了社交新玩法，受到广泛期待。但一些别有用心者利用AI深度造假，“开局一张图，内容随便编”，以此散布谣言、实施诈骗、操控舆论等，扰乱社会秩序、侵犯他人权益，令人愤慨。
 “网络世界里，现实是否将不复存在？”AI生成颠覆了我们“眼见为实”的习惯认知。在大力发展AI的同时，我们如何打击“AI造假”，让技术更加安全可控、更好为人类服务？

 
一
文生文、文生图、文生视频、图生视频……生成式人工智能技术的爆发，让我们见识了“AI作家”“AI画家”“AI摄影师”“AI导演”的惊人技能，更“聪明”的AI由此成为许多人的“贴心助手”。但与此同时，这一技术正被不法分子用来造假“搞事情”，让人防不胜防。
一跨国公司职员被骗2亿港元
比如，“AI诈骗帮凶”。“被骗2亿港元！一跨国公司职员参加多人视频会议，只有自己是真人”——最近，香港警方披露了一起多人“AI换脸”诈骗案，让人大跌眼镜。
比如，“AI假新闻”。前不久，国内多地公布网络谣言典型案例，其中多起系“AI生谣”。“某地一煤矿发生事故已致12人遇难”，这是利用AI自动生成的“新闻体”假文章；“某工业园现大火，浓烟滚滚，目击者称有爆炸声”，则是利用AI“移花接木”拼成的假视频。不法分子借此博眼球、赚流量、非法获利，造成不良社会影响。
不法分子利用AI拼接生成假视频获利
比如，“AI假名人”。今年年初，美国明星泰勒·斯威夫特的大量虚假“不雅照片”在社交平台上传播，致使其名誉受损。一些选民接到了“拜登总统”关于投票选举的自动留言电话，形成误导。
比如，“AI水军”。在一些社交平台，与我们对话的可能不是人，而是AI。只要提前设置好评论立场或风格，如直接抹黑、阴阳怪气、拉踩等，AI就能生成各式各样的评论内容，干扰舆论。

奇安信最新发布的《2024人工智能安全报告》显示，2023年，基于AI的深度伪造欺诈暴增3000%，基于AI的钓鱼邮件增长1000%。世界经济论坛发布的《2024年全球风险报告》也提醒，AI驱动的错误信息和虚假信息是全球经济面临的最大风险。



二
如今，不少人用“真假美猴王”来形容肉眼对“AI造假”的识别难度。那么，“AI造假”这个“假美猴王”有哪些特点呢？
 “伪造高手”。2023年，某世界摄影奖举行颁奖礼，出人意料的是，一位获奖的德国职业摄影师主动拒绝了授奖，因为其作品由AI创作。AI生成的作品“骗”过了评审专家的双眼，可谓真正的“以假乱真”。
德国摄影师的获奖“照片”系AI生成 图源：美国有线电视新闻网
“快枪手”。一键生成、快速生成，生成式人工智能技术大大降低了假文案、假视频的制作门槛，缩短了制作周期。不久前，某地警方破获了一起特大造谣引流网络水军案。涉事传媒公司利用AI爬取境内外短视频内容，编造敏感社会事件，在网络平台发布虚假信息，其运营的自媒体账号多达4万个，虚假帖文信息80多万篇。
“读心大师”。AI具有强大的学习能力，可以精确分析出受众需要什么、喜欢什么，从而有针对性地生产更容易让人相信的谣言。瑞士苏黎世大学的一项研究发现，当AI和人类都发布了虚假推文时，AI被识破的几率比人类低3%。与人类书写的文本相比，GPT的文本往往更加结构化，更容易被接受。
“一本正经的骗子”。研究发现，AI“造假”有时候是因为AI自己会“撒谎”。这种现象被称为AI幻觉，“指的是AI会生成貌似合理连贯，但同输入问题意图不一致、同世界知识不一致、与现实或已知数据不符合或无法验证的内容。”
AI“一本正经地胡说八道”
这种AI编造信息，“一本正经地胡说八道”的情况屡见不鲜。比如，ChatGPT在谈及葡萄牙某银行破产事件时撒谎了，而且为了证实自己，它还编造出了所谓的信源网址。
 
三
“2023年年初，生成式人工智能技术还只是个‘婴孩’，不过一年时间，竟已长成‘少年’”“必须负责任地开发和使用”……人们对“AI造假”的担忧，让AI治理成为时下热点议题。如何让生成式人工智能技术更加安全可控、更好为人类服务？

以“善治”促“善智”。如今，AI已经成为国际竞争的新焦点、经济发展的新引擎，但其不确定性又带来许多新挑战。要以人的善治，促成AI的“善智”。
比如，我国在AI治理中坚持以人为本的基本原则，确保AI的发展始终为人类服务，而不是人被机器所控制。近年来，我国出台了《关于加强科技伦理治理的意见》《互联网信息服务深度合成管理规定》《生成式人工智能服务管理暂行办法》等多项法规和政策，一方面给AI有关技术的创新发展“鼓劲儿”，一方面又给其“立规矩”“划红线”，以确保相关技术的开发和使用遵守法律法规、尊重社会公德和伦理道德。
放大“正能量”减少“副作用”。对生成式人工智能技术的提供者而言，要把握好技术与法律、技术与伦理之间的关系，坚持技术向上向善，让AI更多地造福于人。
比如，对于AI生成的内容，应采取技术措施添加标识，对于可能导致公众混淆或者误认的，更要添加显著标识。再如，用AI打击“AI造假”，AI可以捕捉图像在篡改过程中留下的细微痕迹，以此鉴别图像真伪。这种“用魔法打败魔法”的技术已经在银行、保险等领域落地应用。
《打击整治网络谣言》 图源：新华社
要“他律”更要“自律”。一些案例表明，部分用户对“AI造假”缺乏相关法律意识。比如，某地一女子利用AI编造“校园霸凌”谣言，获得平台浏览奖励几十元，但她很快被警方找到，受到行政处罚，其造谣账号也被关停，得不偿失，后悔不已。有时候，AI会不负责任地胡说八道，但使用者该负的责任一点也不能少，自律之弦要绷紧。
有人说，AI是未来生产力的“发动机”，法律是确保AI开发应用不闯红灯、不越底线的“刹车片”，而安全科技是将各种新兴科技控制在向善道路上的“方向盘”。我们不必因“AI造假”等风险挑战而毁掉“发动机”，而是要用好“刹车片”，把好“方向盘”，这样才能在通往未来的道路上行稳致远。 

作者：沐源 魏震 / 编辑：三木 / 审校：张萍
 点击下方名片关注我们 

