


            
3.Stable Diffusion模型介绍
          




什么是模型对于 AI 绘画而言，我们通过对算法程序进行训练，让机器来学习各类图片的信息特征，而在训练后沉淀下来的文件包，我们就将它称之为模型。用一句话来总结，模型就是经过训练学习后得到的程序文件。Checkpoint大模型大模型，又称底模、基础模型。常见格式为 ckpt、safetensors，一般文件大小较大，占用几个GB。而常见的大模型，又根据不同的版本，分为 SD1.5、SD2、SD2.1、SDXL。这些大模型之间是不通用的，而我们下载的各种别人炼制的大模型是在这些基础版本上调整出来的一般通过整合包下载的WEBUI会自带一些可用的大模型，模型存放于WEBUI根目录中的model/Stable-diffusion，也可以自己下载后手动放置到该目录下​Embeddings虽然 Ckpt 模型包含的数据信息量很多，但动辄几 GB 的文件包使用起来实在不够轻便。比如有的时候我们只想训练一款能体现人物特征的模型来使用，如果每次都将整个神经网络的参数进行一次完整的微调未免有太过兴师动众Embeddings 模型简单理解为封装好的提示词文件，通过将特定目标的描述信息整合在 Embeddings 中，后续我们只需一小段代码即可调用，效果要比手动输入要方便快捷上许多像我们平时头疼的避免错误画手、脸部变形等信息都可以通过调用 Embeddings 模型来解决，比如最出名的 EasyNegative 模型。​Lora模型虽然 Embeddings 模型非常轻量，但大部分情况下都只能在主模型原有能力上进行修正，有没有一种模型既能保持轻便又能存储一定的图片信息呢？这就不得不提我们大名鼎鼎的 LoRA 模型了。总结是固定目标的特征形象，这里的目标既可以是人也可以是物，可固定的特征信息就更加保罗万象了，从动作、年龄、表情、着装，到材质、视角、画风等都能复刻。Lora模型需要放在 models/Lora 文件夹。使用方法如图所示，点击一个模型以后会向提示词列表添加类似这么一个tag，  也可以直接用这个tag调用lora模型​Hypernetwork它的实际效果，我们可以将其简单理解为低配版的 LoRA，虽然超网络这名字听起来很厉害，但其实这款模型如今的风评并不出众，在国内已逐渐被 lora 所取代VAE 模型它的工作原理是将潜空间的图像信息还原为正常图片。作为 ckpt 模型的一部分，VAE 模型并不像前面几种模型用于控制图像内容，而是对主模型的图像修复。常见格式为 .pt使用方法：将其放在 models/VAE 文件夹。放置完毕后，在可以在顶栏直接找到​写实风模型 说到万模型之母，不得不提原始版的Stable Diffusion了，简称SD，是CompVis与合作团队最初发表的模型，不断更新中。最初 Stable Diffusion v1是使用512x512像素的图片训练的，因此高于此尺寸的生图品质会变差。后来Stable Diffusion v2的训练图片宽高提升到了768x768像素。网络上很多模型都基于此模型训练而来。适合画真人、动物、自然、科技、建筑的图像，亦学习过历史上许多画家的画风。Chilloutmix：写实风格的模型，适合画出2.5次元，融合日韩真人与动漫风格的图像。Deliberate：基于SD-1.5模型，适合生成精致写实风格的人物、动物、自然风景。Realistic Vision v6.0：写实风人物与动物模型动漫风模型Anything万象熔炉 v5适合画动漫图，作者宣称不需要打一堆提示词也能出漂亮的图。DreamShaper是基于SD-1.5模型，生成精细动漫人物与油画风格的模型。OrangeMix3，混合多种风格的动漫绘图模型，偏写实。Waifu Diffusion v1.4是纯粹使用Danbooru图库训练而成，适合画动漫图。模型可以从哪里下载国内绝大部分模型站都最好不要使用（出现过很多离谱操作），如有需要请使用civitai和huggingface（civitai大家一般都简称C站，C站可能会上不去，huggingface简称抱抱脸，很多时候国内的交流群都比较喜欢用简称来称呼这两个网站）https://civitai.com/https://huggingface.co/modelshttps://aitool.ai/https://tusi.art/当然也可以关注后私信我，分享给你常用的各种大模型～ ​




