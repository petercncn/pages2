


            
阿里开源视频自动化剪辑工具FunClip
          




项目简介FunClip是一款完全开源、本地部署的自动化视频剪辑工具，通过调用阿里巴巴通义实验室开源的FunASR Paraformer系列模型进行视频的语音识别，随后用户可以自由选择识别结果中的文本片段或说话人，点击裁剪按钮即可获取对应片段的视频（快速体验）。主要特点🔥FunClip集成了多种大语言模型调用方式并提供了prompt配置接口，尝试通过大语言模型进行视频裁剪~FunClip集成了阿里巴巴开源的工业级模型Paraformer-Large，是当前识别效果最优的开源中文ASR模型之一，Modelscope下载量1300w+次，并且能够一体化的准确预测时间戳。FunClip集成了SeACo-Paraformer的热词定制化功能，在ASR过程中可以指定一些实体词、人名等作为热词，提升识别效果。FunClip集成了CAM++说话人识别模型，用户可以将自动识别出的说话人ID作为裁剪目标，将某一说话人的段落裁剪出来。通过Gradio交互实现上述功能，安装简单使用方便，并且可以在服务端搭建服务通过浏览器使用。FunClip支持多段自由剪辑，并且会自动返回全视频SRT字幕、目标段落SRT字幕，使用简单方便。安装🔨Python环境安装FunClip的运行仅依赖于一个Python环境，若您是一个小白开发者，可以先了解下如何使用Python，pip等~# 克隆funclip仓库git clone https://github.com/alibaba-damo-academy/FunClip.gitcd FunClip# 安装相关Python依赖pip install -r ./requirements.txt安装imagemagick（可选）如果你希望使用自动生成字幕的视频裁剪功能，需要安装imagemagickUbuntuapt-get -y update && apt-get -y install ffmpeg imagemagicksed -i 's/none/read,write/g' /etc/ImageMagick-6/policy.xmlMacOSbrew install imagemagicksed -i 's/none/read,write/g' /usr/local/Cellar/imagemagick/7.1.1-8_1/etc/ImageMagick-7/policy.xmlWindows首先下载并安装imagemagick https://imagemagick.org/script/download.php#windows然后确定您的Python安装位置，在其中的site-packages\moviepy\config_defaults.py文件中修改IMAGEMAGICK_BINARY为imagemagick的exe路径下载你需要的字体文件，这里我们提供一个默认的黑体字体文件wget https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ClipVideo/STHeitiMedium.ttc -O font/STHeitiMedium.ttc使用FunClipA.在本地启动Gradio服务python funclip/launch.py随后在浏览器中访问localhost:7860即可看到如下图所示的界面，按如下步骤即可进行视频剪辑上传你的视频（或使用下方的视频用例）（可选）设置热词，设置文件输出路径（保存识别结果、视频等）点击识别按钮获取识别结果，或点击识别+区分说话人在语音识别基础上识别说话人ID将识别结果中的选段复制到对应位置，或者将说话人ID输入到对应为止（可选）配置剪辑参数，偏移量与字幕设置等点击“裁剪”或“裁剪+字幕”按钮使用大语言模型裁剪请参考如下教程B.通过命令行调用使用FunClip的相关功能# 步骤一：识别python funclip/videoclipper.py --stage 1 \                       --file examples/2022云栖大会_片段.mp4 \                       --output_dir ./output# ./output中生成了识别结果与srt字幕等# 步骤二：裁剪python funclip/videoclipper.py --stage 2 \                       --file examples/2022云栖大会_片段.mp4 \                       --output_dir ./output \                       --dest_text '我们把它跟乡村振兴去结合起来，利用我们的设计的能力' \                       --start_ost 0 \                       --end_ost 100 \                       --output_file './output/res.mp4'C.通过Modelscope创空间体验FunClip基于阿里巴巴通义实验室自研SeACo-Paraformer-长音频版的语音识别、端点检测、标点预测、时间戳功能、角色区分、热词定制化功能准确识别，自由复制所需段落，或者设置说话人标识，一键裁剪、添加字幕Step1: 上传视频或音频文件（或使用下方的用例体验），点击 识别 按钮Step2: 复制识别结果中所需的文字至右上方，或者右设置说话人标识，设置偏移与字幕配置（可选）Step3: 点击 裁剪 按钮或 裁剪并添加字幕 按钮获得结果受到网络传输与服务资源的限制，用于体验的视频最好大小在40mb以下 过大的视频可以尝试分离音轨使用音频剪辑，或 通过源代码将您的ClipVideo服务部近期更新🚀🔥2024/05/13 FunClip v2.0.0加入大语言模型智能裁剪功能，集成qwen系列，gpt系列等模型，提供默认prompt，您也可以探索并分享prompt的设置技巧，使用方法如下：在进行识别之后，选择大模型名称，配置你自己的apikey；点击'LLM智能段落选择'按钮，FunClip将自动组合两个prompt与视频的srt字幕；点击'LLM智能裁剪'按钮，基于前一步的大语言模型输出结果，FunClip将提取其中的时间戳进行裁剪；您可以尝试改变prompt来借助大语言模型的能力来获取您想要的结果；2024/05/09 FunClip更新至v1.1.0，包含如下更新与修复：支持配置输出文件目录，保存ASR中间结果与视频裁剪中间文件；UI升级（见下方演示图例），视频与音频裁剪功能在同一页，按钮位置调整；修复了由于FunASR接口升级引入的bug，该bug曾导致一些严重的剪辑错误；支持为每一个段落配置不同的起止时间偏移；代码优化等；2024/03/06 命令行调用方式更新与问题修复，相关功能可以正常使用。2024/02/28 FunClip升级到FunASR1.0模型调用方式，通过FunASR开源的SeACo-Paraformer模型在视频剪辑中进一步支持热词定制化功能。2024/02/28 原FunASR-APP/ClipVideo更名为FunClip。项目链接https://github.com/alibaba-damo-academy/FunCliphttps://modelscope.cn/studios/iic/funasr_app_clipvideo/summary 关注「GitHubStore」公众号扫一扫以下微信1 加入技术交流群，备注「开发语言-城市-昵称」




