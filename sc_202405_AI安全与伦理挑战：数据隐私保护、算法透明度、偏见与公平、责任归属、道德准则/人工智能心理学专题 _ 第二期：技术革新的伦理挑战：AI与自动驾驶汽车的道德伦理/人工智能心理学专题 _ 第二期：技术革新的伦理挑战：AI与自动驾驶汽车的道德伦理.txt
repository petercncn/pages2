


            
人工智能心理学专题 | 第二期：技术革新的伦理挑战：AI与自动驾驶汽车的道德伦理
          




人工智能心理学专题 | 第二期：技术革新的伦理挑战：AI与自动驾驶汽车的道德伦理主编导语：   随着人类新一轮人工智能革命浪潮的如火如荼和人工智能技术的快速迭代和迅猛发展，人类社会已经步入人工智能时代，人工智能正在渗透人类生活的方方面面。作为探索人类心智奥秘和社会行为的轴心学科，心理学正在深度参与人工智能革命浪潮。心理学家好奇的科学问题包括（但不限于）：1. 人工智能是否具备等同于人类的心智能力和多元智能？2. 在生活决策、法律决策和伦理决策中，人类偏好人类决策还是人工智能决策？3. 人工智能是否拥有自我意识、情感体验和伦理准则？4. 人类是否赋予人工智能等同于人类的道德关怀和道德地位？5. 人类对人工智能的快速迭代和迅猛发展持有何种态度？利益论、威胁论还是辩证态度？本期人工智能心理学专题精选十篇心理学与人工智能交叉融合的系列文章，旨在为读者提供更加广阔的视野、深度交叉的探索、理论层面的突破、实践应用的启示和迈向提高人类福祉的人工智能心理学。第二期：技术革新的伦理挑战：AI与自动驾驶汽车的道德伦理   在这个科技日新月异的时代，人工智能（AI）正以前所未有的速度融入我们的生活，在医疗、教育、金融和娱乐等多个领域展示了其巨大潜力，为社会发展开启了新篇章。以医疗领域为例，AI的大数据分析能力已成为疾病诊断和影像分析的强有力助手（Torresen, 2018），为无数患者提供了迅速而精准的诊断。   然而，AI的迅猛发展也带来了不少伦理和社会方面的挑战。AI的算法决策过程看似提供了一种客观公正的方式，但实际上它极有可能复制并加强了社会中已存在的偏见。例如，AI在简历筛选过程中可能无意中沿用了开发者的偏见，加剧了社会不平等的问题（Torresen, 2018）。   正因如此，如何让AI在复杂和动态的环境中作出快速而准确的决策，已经成为今天的热门问题。而在这种背景下，自动驾驶汽车的发展成为了一个引人注目的领域。因为它不仅标志着AI技术在应用方面的重大突破，更触及了伦理和安全领域的复杂议题。    自动驾驶汽车虽然能减少人为错误导致的交通事故，但它也同面临着技术难题和伦理挑战。其中，让AI能够理解和模拟人类的决策过程，并保证其在面对道德困境时能做出符合伦理的选择，是极为重要的内容。在自动驾驶汽车的设计与编码阶段，工程师必须深入考虑在复杂伦理决策情境下人类的多样性和复杂性，确保决策系统不受潜在人为偏见的影响，保障安全性和公平性。   为了探讨自动驾驶汽车的道德挑战，Frank et al.（2019）开展了人在自动驾驶汽车的道德困境中决策偏见的实验。参与者被随机分配到三个组别：行人视角、乘客视角和观察者视角；以及两种决策模式：深思熟虑和直觉。实验使用的道德困境是：一辆自动驾驶汽车在十字路口行驶，前方有一个行人和一辆自行车，汽车必须选择撞击其中之一。结果表明，个人观点和决策模式对人们在道德决策中的影响是显著的。在直觉决策条件下，参与者更倾向于牺牲乘客来保护行人的生命。而在深思熟虑的决策条件下，参与者更倾向于对乘客和行人的生命采取中立的态度。此外，个人观点也对道德决策产生了影响。在行人视角下，参与者更倾向于保护行人的生命，而在乘客视角下，参与者更倾向于保护乘客的生命。总的来说，个人观点和决策模式对人们在道德决策中的影响是显著的。   Awad（2017）的道德机器的实验也证实了这一点。他使用在线平台让参与者评估一系列道德决策，比如在紧急情况下自动驾驶汽车应该如何选择救援的对象。参与者被要求在不同的情境下选择哪个人应该被拯救，年轻人还是老年人，乘客还是行人等等。实验结果表明，人们的道德决策是复杂的，年龄、性别、社会地位文化和地理因素都会对其产生影响。   由此可见，将人的价值观、文化背景和道德观念融入AI的编程已经成为技术发展的核心议题。AI技术的进步不仅仅是技术层面的突破，更是对伦理原则的考验。我们必须深思熟虑这些技术在伦理和道德方面的影响，确保技术的发展符合人类的价值观和道德标准。AI技术的发展应该与人类伦理原则的深入探讨和相互适应并行。只有这样，我们才能确保这些技术在为社会带来便利的同时，也能够得到伦理和道德上的支持。参考文献：Awad, E. (2017). Moral machines: perception of moral judgment made by machines (Doctoral dissertation, Massachusetts Institute of Technology). http://hdl.handle.net/1721.1/112532Frank, D.-A., Chrysochou, P., Mitkidis, P., & Ariely, D. (2019). Human decision-making biases in the moral dilemmas of autonomous vehicles. Scientific Reports, 9(1), 13080. https://doi.org/10.1038/s41598-019-49411-7Torresen, J. (2018). A Review of Future and Ethical Perspectives of Robotics and AI. Frontiers in Robotics and AI, 4, 75. https://doi.org/10.3389/frobt.2017.00075作者简介：彭逸飞：硕士就读于慕尼黑工业大学教与学研究专业，本科毕业于湖南科技大学应用心理学专业。主要研究兴趣：跨文化、道德伦理、动机、情绪、AI、眼动追踪等。本文版权属于《心理新青年》编辑部，未经许可，请勿转载。若需转载，请联络《心理新青年》编辑部。




